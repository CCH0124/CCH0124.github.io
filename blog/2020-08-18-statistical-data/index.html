<!doctype html><html lang=en-us style=max-width:1000px;margin:auto><head><title>Kevin Blog</title><meta name=theme-color content><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta name=description content="Kevin learning"><meta name=author content="Kevin Chen"><meta name=generator content="aafu theme by Darshan in Hugo 0.83.0"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#252627><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=/css/bootstrap/bootstrap.min.css><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.15.2/css/all.css integrity=sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu crossorigin=anonymous><link rel=stylesheet href=https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Didact+Gothic%7CRoboto:400%7CRoboto+Mono"><link rel=stylesheet href=/css/aafu_pinkish.css><link rel=stylesheet href=/css/aafu.css><script>var themeColor=document.querySelector("meta[name=theme-color]");window.onload=()=>{themeColor.content=getComputedStyle(document.body)["background-color"];let a=document.querySelector(".accordion.active");a&&(a.nextElementSibling.style.maxHeight=a.nextElementSibling.scrollHeight+"px")},window.onresize=()=>{let a=document.querySelector(".accordion.active");a&&(a.nextElementSibling.style.maxHeight=a.nextElementSibling.scrollHeight+"px")}</script></head><body class=container><main style="min-height:calc(100vh - 60px)"><div class="d-flex flex-row row p-2"><h3 class="main-menu mr-3"><a href=https://cch0124.github.io/>Home</a></h3><h3 class="main-menu mr-3"><a href=/blog>Blog</a></h3><h3 class="main-menu mr-3"><a href=/project>Project</a></h3><h3 class="main-menu mr-3"><a href=/life>Life</a></h3><h3 class="main-menu mr-3"><a href=/kubernetes>Kubernetes</a></h3><h3 class="main-menu mr-3"><a href=/code>Coding</a></h3></div><div class=mb-3><h1 class=top-h1 style=font-size:2.75em>30 天學習歷程-day02</h1><p class=mb-1>August 18, 2020</p><p>&mdash;</p></div><div class=content><h1 id=statistical-data>Statistical Data</h1><p>透過統計方式我們可以觀察資料的趨勢或是分散程度等，以下將會介紹常用的統計方式。</p><h2 id=數據集中趨勢>數據集中趨勢</h2><h3 id=mean>Mean</h3><ul><li>一組數據中的平衡點</li><li>平均數是一組樣本和除以樣本數量</li></ul><p>另 $x_1, x_2,&mldr;, x_N$ 為 $X$ 的 $N$ 個觀測值。這些值有可稱為<strong>數據集</strong>。這些數值均值(mean)為
$$\bar{x} = \frac{\sum_{i=1}^{N} x_i}{N} = \frac{x_1+x_2+&mldr;+x_N}{N}$$</p><p>有時可以與 $w_i$ 權重相關。此反應他們所依附的對應值的意義、重要性或出現頻率。可以下計算：
$$\bar{x} = \frac{\sum_{i=1}^{N} w_i x_i}{\sum_{i=1}^{N} w_i} = \frac{w_ix_1+w_2x_2+&mldr;+w_nx_N}{w_1+w_2+&mldr;+w_N}$$</p><p>這稱為<strong>加權是算術平均值（weight arithmetic mean）<strong>或</strong>加權平均值（weighted average）</strong>。</p><p>但上面計算的均值對極端值很敏感。要避免可以使用<strong>截尾均值(trimmed mean)</strong>，丟棄高低極端值得影響。在計算平均值之前，移除最底部 2% 資料等。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
nums <span style=color:#f92672>=</span> [<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>3</span>]
<span style=color:#75715e># Numpy</span>
np<span style=color:#f92672>.</span>mean(nums) <span style=color:#75715e># 3.6</span>
<span style=color:#75715e># for</span>
sum <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
<span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> nums:
    sum <span style=color:#f92672>+=</span> i
<span style=color:#66d9ef>print</span>(sum<span style=color:#f92672>/</span>len(nums)) <span style=color:#75715e># 3.6</span>
</code></pre></div><h3 id=median>Median</h3><ul><li>樣本需要是排序</li><li>代表一個樣本或概率分佈中的一個數值，可將數值集合劃分為相等的上下兩部分</li><li>樣本為偶數個，則中位數不唯一，通常取最中間的兩個數值的平均值作為中位數</li></ul><p>對於 <em>偏斜（非對稱）</em> 數據，數據中心更好度量是<strong>中位數(median)</strong>，將較高或較低值給平均。
有序數據值的中間值。</p><p>當數據量很大時，中位數計算開銷很大，然而可以計算中位數的<strong>近似值</strong>。用內插(interpolation)計算該近似值 $$median = L_1 + (\frac{N/2+(\sum freq)<em>l}{freq</em>{median}})width$$</p><p>$L_1$ 是中位數區間下界，$N$ 是整個數據集中值的各數，$(\sum freq)<em>l$ 是低於中位數區間的所有區間的頻率，$freq</em>{median}$ 是中位數區間的頻率，$width$ 是中位數區間的寬度。</p><pre><code class="language-python=" data-lang="python=">np.median(np.sort(nums)) # 3.5
</code></pre><h3 id=mode>Mode</h3><ul><li>樣本中出現最多次的數值</li><li>其中有可能為多個數</li></ul><p>眾數(mode) 是集合中出現最頻繁的值。因此，可對定性和定量屬性確定眾數。可能高頻率對應多個不同值，導致多個眾數，可分成</p><ul><li>一個眾數稱為單峰(unimodel)</li><li>兩個眾數稱為雙峰(bimodal)</li><li>三個眾數稱為三峰(trimodal)</li></ul><p>具有兩個或更多的資料集稱為<strong>多峰(multimodal)</strong>。</p><p>對適度偏斜(非對稱)的單峰資料，可得 $mean-mode \approx 3\times(mean-median)$，該平均值和中位數可以近似估計眾數。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> scipy <span style=color:#f92672>import</span> stats
stats<span style=color:#f92672>.</span>mode(nums) <span style=color:#75715e># ModeResult(mode=array([4]), count=array([3]))</span>
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Value:&#34;</span>, stats<span style=color:#f92672>.</span>mode(nums)[<span style=color:#ae81ff>0</span>])
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Count:&#34;</span>, stats<span style=color:#f92672>.</span>mode(nums)[<span style=color:#ae81ff>1</span>])
<span style=color:#75715e>#Value: [4]</span>
<span style=color:#75715e>#Count: [3]</span>
</code></pre></div><h2 id=資料分散程度>資料分散程度</h2><h3 id=range>Range</h3><ul><li><p>全距 $R$，可稱為<em>極差</em></p></li><li><p>用來表示統計資料中的變異量數</p></li><li><p>最大值與最小值的相減結果</p></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
nums <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>80</span>, size<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
<span style=color:#66d9ef>print</span>(nums)
<span style=color:#75715e># [70 41 70 68 75 55 32  5  0 11 44 17 15 25 52 58 57 45 25 57]</span>
</code></pre></div><pre><code class="language-python=" data-lang="python=">np.ptp(nums) # 75
print(max(nums)-min(nums)) # 75
</code></pre><h3 id=mid-range>Mid-range</h3><ul><li>中列數(midrange) 可以用來評估數值數據的中心趨勢。是數據集的最大和最小值的平均值。</li><li>在具有對稱的數據分布的單峰頻率曲線中，均值、中位數、和眾數都是相同的中心值，下圖</li></ul><p><img src=https://i.imgur.com/ZEQ8eXW.png alt> from &ldquo;Data Mining. Concepts and Techniques, 3rd Edition&rdquo;</p><h3 id=quartile>Quartile</h3><p>分位數是資料分布上以固定區間取出的點，以下圖來說 <code>Q1</code>、<code>Q2</code> 和 <code>Q3</code>，這些資料點稱作分位數。而二分位數為則代表為<em>中位數(medain)</em>，將資料從中間頗一半。100 分位數則將資料切分 100 個大小相等的相連集合。</p><p><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/800px-Boxplot_vs_PDF.svg.png alt> from wiki</p><p>在上圖中，<code>Q1</code> 和 <code>Q3</code> 的之間的距離，是測量分散程度的方式。該距離稱為<em>四分位間距(interquartile, IQR)</em>，數學定義為 $IQR = Q_3 - Q_1$</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
nums <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>80</span>, size<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
<span style=color:#66d9ef>print</span>(nums)
nums<span style=color:#f92672>.</span>sort()
<span style=color:#66d9ef>print</span>(nums)
<span style=color:#66d9ef>print</span>(np<span style=color:#f92672>.</span>percentile(nums, (<span style=color:#ae81ff>25</span>))) 
<span style=color:#66d9ef>print</span>(np<span style=color:#f92672>.</span>percentile(nums, (<span style=color:#ae81ff>50</span>))) 
<span style=color:#66d9ef>print</span>(np<span style=color:#f92672>.</span>percentile(nums, (<span style=color:#ae81ff>75</span>)))
</code></pre></div><p>在視覺化章節將會使用圖的方式作呈現。</p><h5 id=outlier>outlier</h5><p>挑出在 <code>Q3</code> 上方 $1.5 \times IQR$ 資料值和 <code>Q1</code> 下方 $1.5 \times IQR$ 資料值，如上圖顯示。這邊先以此抽象方式進行簡易描述，後續的離群值章節會進行詳細介紹。</p><h3 id=five-number-summary>five-number summary</h3><p>它包含了中位數、四分位數的 <code>Q1</code> 和 <code>Q3</code>和最大與最小的觀察值。相比四分位數它多了最高和最低值的資訊。</p><h3 id=boxplot>boxplot</h3><p>是一種以視覺化顯示資料分布的方式，它涵括了<em>five-number summary</em>。從上圖的第一個方形形狀的圖呈現。</p><h3 id=variance-and-stander-deviation>variance and stander Deviation</h3><p>低標準差表示數據觀測趨向於非常靠近均值，高的話則散布在一個大的範圍中。</p><p>數值屬性 $X$ 的 $N$ 個觀測值 $x_1, x_2, &mldr;, x_N$ 的變異數(variance)：
$$\sigma^2 = \frac{1}{N}\sum_{i=1}^{N}(x_i-\bar{x})^2 = (\frac{1}{N}\sum_{i=1}^{n}x_i^2)^2- \bar{x}^2$$</p><p>$\bar{x}$觀測的均值。觀測值的標準差(standar deviation) $\sigma$ 是變異數 $\sigma^2$ 的平方根。</p><p>例：我們得到$\bar{x}=58000$ 美元，決定此資料集的變異數和標準差。設置 $N=12$：$$\sigma^2=\frac{1}{12}\sum_{i=1}^{12}(30^2+36^2+47^2+&mldr;+110^2)-58^2 \approx 379.17$$
$$\sigma \approx \sqrt{379.17} \approx 19.14$$</p><p>標準差$\sigma$ 性質</p><ul><li><p>$\sigma$ 度量關於均值的發散，僅當平均值選為中心量測時才被考慮使用</p></li><li><p>僅當不存在發散時，即當所有的觀測值都具有相同值時，$\sigma=0$；否則大於 0</p></li></ul><p>一個觀察值不大可能與平均值的距離有數倍的標準差，以 Chebyshev&rsquo;s Inequalit 解釋，至少 $(1-1/k^2)\times100%$ 的觀察值與平均值的距離不會超過 $k$ 倍的標準差。表準差是數據集發散得很好指示器。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>print</span>(nums)
<span style=color:#66d9ef>print</span>(np<span style=color:#f92672>.</span>var(nums))
<span style=color:#66d9ef>print</span>(np<span style=color:#f92672>.</span>std(nums))
<span style=color:#75715e>#[ 4 12 24 28 31 38 43 46 47 51 56 56 59 61 63 64 68 72 76 78]</span>
<span style=color:#75715e>#409.0275</span>
<span style=color:#75715e>#20.224428298471132</span>
</code></pre></div><h2 id=參考資料>參考資料</h2><ul><li>Data Mining. Concepts and Techniques, 3rd Edition</li></ul></div><div class="d-flex flex-row justify-content-around"><h3 class="mb-1 mt-1 text-left mr-4"><a href=/blog/2020-08-17-know-data/ title="30 天學習歷程-day01"><i class="nav-menu fas fa-chevron-circle-left"></i></a></h3><h3 class="mb-1 mt-1 text-left ml-4"><a href=/blog/2020-08-19-chart/ title="30 天學習歷程-day03"><i class="nav-menu fas fa-chevron-circle-right"></i></a></h3></div></main><footer class="mt-2 mb-4 text-center"><span class=markdownify>short copyright message</span>
<span>&#183;
<i><a href=https://github.com/darshanbaral/aafu>aafu</a></i>
by
<a href=https://www.darshanbaral.com/>darshan</a></span></footer></body></html>