<!doctype html><html lang=en-us style=max-width:1000px;margin:auto><head><title>Kevin Blog</title><meta name=theme-color content><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta name=description content="Kevin learning"><meta name=author content="Kevin Chen"><meta name=generator content="aafu theme by Darshan in Hugo 0.83.0"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#252627><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=/css/bootstrap/bootstrap.min.css><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.15.2/css/all.css integrity=sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu crossorigin=anonymous><link rel=stylesheet href=https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Didact+Gothic%7CRoboto:400%7CRoboto+Mono"><link rel=stylesheet href=/css/aafu_pinkish.css><link rel=stylesheet href=/css/aafu.css><script>var themeColor=document.querySelector("meta[name=theme-color]");window.onload=()=>{themeColor.content=getComputedStyle(document.body)["background-color"];let a=document.querySelector(".accordion.active");a&&(a.nextElementSibling.style.maxHeight=a.nextElementSibling.scrollHeight+"px")},window.onresize=()=>{let a=document.querySelector(".accordion.active");a&&(a.nextElementSibling.style.maxHeight=a.nextElementSibling.scrollHeight+"px")}</script></head><body class=container><main style="min-height:calc(100vh - 60px)"><div class="d-flex flex-row row p-2"><h3 class="main-menu mr-3"><a href=https://cch0124.github.io/>Home</a></h3><h3 class="main-menu mr-3"><a href=/blog>Blog</a></h3><h3 class="main-menu mr-3"><a href=/project>Project</a></h3><h3 class="main-menu mr-3"><a href=/life>Life</a></h3><h3 class="main-menu mr-3"><a href=/kubernetes>Kubernetes</a></h3><h3 class="main-menu mr-3"><a href=/code>Coding</a></h3></div><div class=mb-3><h1 class=top-h1 style=font-size:2.75em>ELK</h1><p class=mb-1>January 1, 0001</p><p>&mdash;</p></div><div class=content><h1 id=elk>ELK</h1><p>ELK 是指 ElasticSearch 、 Logstash 和 Kibana 三個 open-source 的集合套件，這三個軟體可以組成一套日誌(log)分析架構。</p><p>如今資料量動輒 &ldquo;T&rdquo; 或幾個 &ldquo;P&rdquo; 等級的數據，正常的文字編輯器或數據處理軟體等工具往往都難以應對，但對原始的大數據進行分析，能提高對數據的洞察力。ELK 可以對大量Log 的數據處理，如索引、分析，當對這大量進行良好的控管，將可以依照這些數據得到一些有用的資訊。</p><h2 id=log>Log</h2><p>我是應用在 Log 的蒐集上因此小提一下 Log。</p><p>Log 就是系統或設備在連線和運作時所產生的記錄，藉由 Log 的蒐集和分析，讓 IT 人員能夠監控系統的運作狀態，判斷可能發生的事件，以及分析資料存取行為和使用者的活動。</p><p>網路是否遭到惡意的嘗試入侵？
系統和網路運作是否有異常情況發生？
IT 人員只要對 Log 進行監控，就可以判斷可能的問題，或著狀況不清楚時，透過 Log 的查詢分析，可在較短時間內找出原因。</p><h2 id=架構>架構</h2><p><img src=https://i.imgur.com/jM8xjRv.png alt></p><h2 id=核心架構介紹>核心架構介紹</h2><h3 id=elasticsearch>Elasticsearch</h3><ul><li>全文檢索的搜索引擎</li><li>擴展性高</li><li>分散式系統的功能</li><li>索引方式管理維護數據</li><li>透過 API 取得相關數據的查詢、聚合等</li></ul><h3 id=logstash>Logstash</h3><ul><li>分析數據的入口點</li><li>支持很多的 Input、Output 數據套件</li><li>其中一種是將數據傳入至 Elasticsearch</li><li>蒐集原始數據</li><li>修改（過濾）數據，並將其數據轉換成有意義的資訊</li><li>完成數據格式化和重新組織數據</li></ul><h4 id=資料進入-logstash-流程>資料進入 logstash 流程</h4><p><img src=https://i.imgur.com/GdAxDbg.png alt></p><ul><li>input<ul><li>file</li><li>TCP</li><li>UDP</li><li>syslog</li><li>beat</li><li>等等</li></ul></li><li>filter<ul><li>grok</li><li>mutate</li><li>drop</li><li>等等</li></ul></li><li>output<ul><li>Elasticsearch</li><li>google_bigquery</li><li>等等</li></ul></li></ul><p>其中 Data Source 可以是 beat 或讀檔等方式傳入 Logstash，在 filter 部分可以處裡傳入的數據，最橫在把資訊傳至 Elasticsearch。</p><h3 id=kibana>Kibana</h3><ul><li>圖表的可是視化</li></ul><p><img src=https://i.imgur.com/ZY2NWm8.png alt></p><h4 id=gui>GUI</h4><ul><li>黑框<ul><li>Discover：用以檢視各索引下的記錄內容及總記錄筆數</li><li>Visualize：將搜尋出的數據以長條圖、圓餅圖、表格等方式呈現</li><li>Dashboard：將以儲存的搜尋結果或已完成的圖表組合成一份快速報表</li><li>Timelion：時序性的監看 query</li><li>Dev Tools：提供一個在 kibana 直接呼叫 elasticsearch 的方式</li><li>Managment：設定 kibana 對應的 elasticsearch index patterns，管理已經儲存好的搜尋結果物件、視覺化結果物件，及進階資料過濾設定</li></ul></li><li>紅框<ul><li>Index：要搜索的 index pattern（Management 所設定的 index patterns create ）</li></ul></li><li>咖啡框<ul><li>Avaliable Fields：搜索 index 下所包含的屬性(也就是我們在 logstash 切出來的部分)</li></ul></li><li>紫框<ul><li>Timestamp：資料時間，可用於特定時間區間資料量觀察</li></ul></li><li>藍框<ul><li>source：顯示我們接收到的 log 資訊</li></ul></li><li>綠框<ul><li>搜尋條件：預設 &ldquo;*&rdquo; 搜尋 index 下所有紀錄</li></ul></li></ul><h2 id=實作>實作</h2><h3 id=環境>環境</h3><ul><li>ubuntu<ul><li>Memory<ul><li>2G</li></ul></li><li>Docker</li><li>Docker-compose</li></ul></li></ul><h3 id=安裝環境>安裝環境</h3><h5 id=docker>Docker</h5><pre><code class="language-shell=" data-lang="shell=">$ sudo apt-get update
$ sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual
$ sudo apt-get update
$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo apt-key fingerprint 0EBFCD88
$ sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;
$ sudo apt-get update
$ sudo apt-get install docker-ce
</code></pre><h5 id=docker-compose>Docker-compose</h5><pre><code class="language-shell=" data-lang="shell=">$ sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
$ sudo chmod +x /usr/local/bin/docker-compose
</code></pre><h3 id=定義-elk-docker-compose>定義 ELK Docker-compose</h3><pre><code class="language-shell=" data-lang="shell=">version: '3'

services:

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: elasticsearch
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - &quot;9200:9200&quot;
      - &quot;9300:9300&quot;
    environment:
      ES_JAVA_OPTS: &quot;-Xmx1024m -Xms1024m&quot;
    networks:
      - elk

  logstash:
    build:
      context: logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/DataSet:/usr/share/logstash/DataSet:ro
    ports:
      - &quot;5001:5001&quot;
      - &quot;9600:9600&quot;
    environment:
      LS_JAVA_OPTS: &quot;-Xmx256m -Xms256m&quot;
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: kibana
    volumes:
      - ./kibana/config/:/usr/share/kibana/config:ro
    ports:
      - &quot;5601:5601&quot;
    networks:
      - elk
    depends_on:
      - elasticsearch

networks:
  elk:
    driver: bridge

</code></pre><p>關於 docker-compose 可參考 <a href=https://github.com/CCH0124/docker-elk>本人 Docker-elk</a>，會更上述的 docker-compose 不一樣，本人有新增其它服務。</p><blockquote><p>$ELK_VERSION 是從 .env 定義。可參考<a href=https://docs.docker.com/compose/environment-variables/>environment-variables</a></p></blockquote><h4 id=run>Run</h4><p>進入 docker-compose.yml 檔案該層目錄執行以下。否則需要使用 -f 來指定 docker-compose.yml 位置。</p><pre><code class="language-shell=" data-lang="shell=">$ sudo docker-compose up -d --build
</code></pre><h4 id=elk-port>ELK Port</h4><ul><li>5001：Logstash TCP input</li><li>9200：Elasticsearch HTTP</li><li>9300：Elasticsearch TCP transport</li><li>5601：Kibana</li></ul><h4 id=kibana-瀏覽>Kibana 瀏覽</h4><pre><code class="language-shell=" data-lang="shell=">http://localhost:5601
</code></pre><p><img src=https://i.imgur.com/BSNRA0A.png alt></p><h4 id=測試-logstash-tcp-input>測試 logstash TCP input</h4><pre><code class="language-shell=" data-lang="shell=">$ nc localhost 5001 &lt; a.txt
</code></pre><p>檢查 kibana 上是否有索引出現</p><p><img src=https://i.imgur.com/9lbBhaz.png alt></p><p>接著建立索引，按下 &ldquo;Next step&rdquo;</p><p><img src=https://i.imgur.com/kNMOOiD.png alt></p><p>選擇時間戳，按下 &ldquo;Create index pattern&rdquo;</p><p><img src=https://i.imgur.com/M2jH1fU.png alt></p><p>點選 Discover 即可看見，藉由 logstash 傳到 elasticsearch，kibana 再從 elastcsearch 抓出資料顯示。</p><p><img src=https://i.imgur.com/pIvnNSN.png alt></p><h2 id=結論>結論</h2><p>以上建立好基本上資料傳遞都會成功，之後會介紹 <code>logstahs</code> 讀檔以及一些 beat 的應用。目前還會研究 Elasticsearch 的叢集和 logstash 結合 redis 軟體這些叫細節的規劃。</p><p>其實 ELK 這開源的軟體，我是透過電算老師介紹，當初我是利用 <code>rsyslog</code> 來進行 log 蒐集，後來發現覺得好不人性化。
因此，就像恩人請求辦法，最後也認識了 ELK 三個開源的軟體。</p></div><div class="d-flex flex-row justify-content-around"><h3 class="mb-1 mt-1 text-left mr-4"><i class="nav-menu-disabled fas fa-chevron-circle-left"></i></h3><h3 class="mb-1 mt-1 text-left ml-4"><a href=/project/2017-06-27-scanner-port-java/ title="scanner port"><i class="nav-menu fas fa-chevron-circle-right"></i></a></h3></div></main><footer class="mt-2 mb-4 text-center"><span class=markdownify>short copyright message</span>
<span>&#183;
<i><a href=https://github.com/darshanbaral/aafu>aafu</a></i>
by
<a href=https://www.darshanbaral.com/>darshan</a></span></footer></body></html>