<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>school on</title><link>https://cch0124.github.io/tags/school/</link><description>Recent content in school on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 12 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://cch0124.github.io/tags/school/index.xml" rel="self" type="application/rss+xml"/><item><title>學習紀錄</title><link>https://cch0124.github.io/project/2020-09-07-person-history/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-09-07-person-history/</guid><description>自我學習紀錄 機器學習 資料屬性 統計資料 統計資料圖表觀察 資料的相異度與相似度 資料前處裡 資料清理應用 線性迴歸 數學 什麼是分類 什麼是集群 實作 Keras DDos Detection k-means DBSCAN Activation 介紹與實作 Tensorflow function 操作 keras 神經網路建立 全連接層觀察 梯度 損失函數 keras DNN實作- mnist 為例 keras CNN實作- cifar10 為例 自訂義 Layer Kubernetes Kubernetes 學習紀錄 自我學習 GCP 和機器學習與 Kubernetes 應用 Machine Learning APIs Introduction to APIs in Google Extract, Analyze, and Translate Text from Images with the Cloud ML APIs Classify Text into Categories with the Natural Language API Detect Labels, Faces, and Landmarks in Images with the Cloud Vision API Entity and Sentiment Analysis with the Natural Language API Awwvision: Cloud Vision API from a Kubernetes Cluster Baseline Data, ML, AI AI Platform Dataprep Dataproc Video Intelligence Reinforcement Learning Kubernetes in Google Cloud Introduction to Docker Kubernetes Engine Orchestrating the Cloud with Kubernetes Managing Deployments Using Kubernetes Engine Continuous Delivery with Jenkins in Kubernetes Engine Kubernetes Solutions Using Kubernetes Engine to Deploy Apps with Regional Persistent Disks NGINX Ingress Controller on Google Kubernetes Engine Distributed Load Testing Using Kubernetes Running a MongoDB Database in Kubernetes with StatefulSets Coding Spring boot CRUD 員工管理系統 spring-boot 容器以及其它運用 使用 Dockerfile 製作容器 導入 jaeger 進行 API traceing JAVA JAVA JAVA - UVa JAVA - Network 放視大賞 - OTP 隨機密碼 Database Database Shell shell - hackerrank shell - LeetCode shell - codeware shell 自己練習寫小工具 Golang Golang 資料結構實作 運維與網路 ELK wireshark 軟體使用 分析應用-01 分析應用-02 分析應用-03 Namespace 模擬 Docker Ansible Jenkins firewall Vagrant logging-efk monitor terraform tracing - jaeger 網路筆記 靜態路由 ARP DHCP PPP RIP 與子網路切割 ACL HSRP telnet SSH NAT Static NAT Dynamic VLAN VLAN router-on-a-stick 實習 交換器 image 遺失 Apache 操作 DHCP 操作 ELK logstash 問題解決 ESXi 備份至 NAS rsyslog 研究 學校 作業 PortScanner - python JAVA 實作矩陣運算 Android 計算機 社團 Flutter flutter-BMI flutter-calculator Card Flutter 學習筆記 實驗室 NFS rsync UPS</description></item><item><title>30 天學習歷程-day11</title><link>https://cch0124.github.io/blog/2020-08-29-feature-selection/</link><pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-29-feature-selection/</guid><description>特徵選取是指在開發一個機器學習模型時，減少輸入特徵數量的過程。這過程不但能減少計算上的成本，有時還能因為特徵選取減少了聲噪的影響因而建構出一個良好的模型。特徵選擇可分為以下
Unsupervised 移除多餘的特徵 Correlation Supervised 移除無關連特徵 Wrapper RFE Filter 依照特徵集合和目標的關係選擇特徵集合 Statistical 方法 SelectKBest SelectPercentil Feature Importance 方法 Intrinsic 訓練過程中執行自動特徵選取的演算法 Decision Tree Dimensionality Reduction 將數據投影到低維度的特徵空間中 統計的特徵選取方法 通常在輸入和輸出變量之間使用 correlation 統計作為過濾器特徵選擇的基礎。統計量測選擇高度依賴於可變數據類型，如下
數值 Integer Floating 分類 Boolean Ordinal Nominal 從數據類型來看的話數值是屬於 Regression 問題，分類是 Classification 問題。通常過濾器特徵選擇中使用的統計測量與目標變數一次計算一個輸入變數。因此，它們被稱為單變量統計(univariate statistical)測量。</description></item><item><title>30 天學習歷程-day10</title><link>https://cch0124.github.io/blog/2020-08-28-clustering/</link><pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-28-clustering/</guid><description>分群(clustering) 是將一堆資料物件聚類成數個群集，讓同一群擊內的資料物件有很高的相似性，而不同群集間則有不相似的特性。在判別資料上的相似性會依照資料特徵進行衡量，通常可能會是量測距離等。
群集分析是什麼 就是將觀測的資料切分不同子集合的動作，每一個子集合都是一個群集。在百百種的分群演算法中，每種形成群集的效果都是不一樣，這些的演算法很適合挖掘未知的資訊。群集分析可以用來挖掘資料內部的分布，觀察每個群集的特徵，並進行下一步地分析動作。當然也可用作於資料前處理步驟，像是資料特性、屬性子集合選取或分類法等。而分群相較於分類，它能夠自動的找到群組。
集群分析方法 分割式分群法 找出互斥的球形群集 以距離為基礎 使用 mean 與 medoid 來代表群集中心點 對於中小型資料集很有效率 演算法有，k-means、k-medoids 等
階層式分群法 透過階層分解方式來分群 不能修正錯誤的合併或分割 可以結合微分群技術或考慮資料物件間的關聯性 演算法有，BIRCH、Chameleon 等
密度式分群法 找到任意形狀的群集 群集為空間中的資料物件密集的區域，不同群集則被低密度區域分隔 群集密度 每個資料物件得鄰近區域內包含至少最小數量的資料點 可以過濾離群值 演算法有，DBSCAN、OPTICS、DENCLUE 等</description></item><item><title>30 天學習歷程-day09</title><link>https://cch0124.github.io/blog/2020-08-27-what-classification/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-27-what-classification/</guid><description>以棒球員捕手為例，當他面對一位打者時，需要判斷說該打者對於什麼球種是安全的，那些球種是有風險的；醫療方面可能是分析乳癌的病患資料，並在幾種特定解決方法中，該給於怎樣的治療。這些例子中，資料分析方法就是分類(classification)。假設是預測棒球雙方的比數，該資料分析任務就是數值預測，迴歸分析(regression analysis)是最常用來數值預測的統計方法。
要進行資料分類，其程序大致為兩步驟，學習步驟此階段會建立模型；分類步驟此階段會利用模型來預測給定資料的類別標籤。學習步驟中會給定資料集合中的資訊，藉由分類演算法分析資料集合中一組樣本和其對應的類別標籤建立一個分類器。一個值組 $X$ 為 $n$ 維度的特徵向量，$X = (x_1, x_2, &amp;hellip;, x_3)$，其每個 $X$ 會對應一個類別，該類別可由類別標籤屬性來定義。假設一個樣本對應的標籤已經被定義好，該學習步驟可稱為監督式學習(supervised learning)，這與**非監督式學習(unsupervised learning)**不同，樣本無對應的標籤，需透過學習才知道，常見的方式就是使用分群(clustering)。以之前寫過的簡單線性迴歸來說，我們會希望透過映射函數來預測給定的資料樣本 $X$ 對應的類別標籤 $y$，就是找一個函數來分割資料的類別。
分類步驟會使用模型來進行分類，然而其正確率是多少 ? 在計算該值時不應該拿訓練資料進行評估，因分類器會傾向於過擬合(overfit) 訓練資料，就是說學習過程中，有些異常的資料會被過度學習，而該異常資料並不會出現在一般的資料集中。我們應當使用測試資料來進行正確率的評分。</description></item><item><title>30 天學習歷程-day08</title><link>https://cch0124.github.io/blog/2020-08-26-math/</link><pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-26-math/</guid><description>二項式定理、指數、對數、三角函數 二項是定理 參考 參考 排列組合 排列
由 $n$ 個不同物品取 $k$ 個出來排列，因此最後的排列順序不同，及視為不同的排列 組合
由 $n$ 個不同物品取 $k$ 個出來但不排列，因此只要組成元素相同，及視為相同組合，無關順序排列 ABC、ACB、BAC、CAB、BCA、CBA 這 $3!$ 種排列可看成是 A、B、C 的組合 組合數可用 $\frac{n!}{(n-k)!k!}$ 或 $C^n_k$ 表示 二項分佈計算獨立事件的機率分佈 事件的成功機率與獨立性 拜訪 10 次簽下 $k$ 建的機率一般式 $0.36$ 每次拜訪成功機率，
$P(x=k) = \tbinom{10}{k} \centerdot 0.36^k \centerdot (1-0.36)^{10-k}$
拜訪 10 次簽下 2 件的機率 $P(x=2) = \tbinom{10}{2} \centerdot 0.36^2 \centerdot (1-0.36)^{10-2} = \frac{10!}{(10-2)!2!} \centerdot 0.</description></item><item><title>30 天學習歷程-day07</title><link>https://cch0124.github.io/blog/2020-08-25-simple-linear-regression/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-25-simple-linear-regression/</guid><description>回歸模型（線性或非線性）被廣泛應用於數值預測，比如薪水，銷售額等等。如果說自變數（independent variable）是時間，那麼我們是在預測未來的數值；反之我們的模型在預測當前未知的數值。
簡單線性回歸，由自變量 $X$ 來預測因變量 $Y$ 的方法，假設這兩個變量是相關的線性，可嘗試尋找依據特徵($x$)的線性函數來擬合並預測($y$)。
from wiki
上圖中，紅線可以用 $y=ax+b$ 求得，且該紅線是能代表該資料的一條線，其 $a$ 為斜率；$b$ 為y截距。$y$ 為應變數 ，$x$ 為自變數。然而為了找到最佳擬合的線，會使最小平方法，該方法盡可能的讓預測值與實際值的誤差為最小。其公式如下，並對應下圖，$y_i$ 為實際值；$y_p$ 為預測值。
$$min{SUM(y_i-y_p)^2}$$
當誤差越大表示無法反映現實情況。我們以下使用 keras 和 sklearn 進行實驗。
程式碼 sklearn from tensorflow.keras.datasets import boston_housing (x_train, y_train), (x_test, y_test) = boston_housing.load_data() # 正規化 mean_feature_train = x_train.mean(axis=0) std_feature_train = x_train.std(axis=0) mean_feature_test = x_test.mean(axis=0) std_feature_test = x_test.std(axis=0) x_train = (x_train-mean_feature_train)/std_feature_train x_test = (x_test-mean_feature_test)/std_feature_test # 導入線性回歸模型 from sklearn.linear_model import LinearRegression regression = LinearRegression() regression = regression.</description></item><item><title>30 天學習歷程-day06</title><link>https://cch0124.github.io/blog/2020-08-24-data-clean/</link><pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-24-data-clean/</guid><description>Data cleaning 將使用 pandas 工具和 CICDDOS 數據集進行資料清理的練習。下面會學習到 pandas 的使用。
###　Drop Miss Value
import pandas as pd import numpy as np ddos = pd.read_csv(&amp;#34;D:\\DataSet\\CICDDOS2019\\01-12\\CSV\\DrDoS_LDAP.csv&amp;#34;) missing_values_count = ddos.isnull().sum() # 檢查缺失值 missing_values_count[20:25] ############################## #Bwd Packet Length Std 0 #Flow Bytes/s 12 # Flow Packets/s 0 # Flow IAT Mean 0 # Flow IAT Std 0 #dtype: int64 ##############################3 # Flow Bytes/s 有 12 個缺失值 ddos.shape # (2181542, 88) # 計算缺失值比例 total_miss_values = missing_values_count.</description></item><item><title>30 天學習歷程-day05</title><link>https://cch0124.github.io/blog/2020-08-21-data-pre-processing/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-21-data-pre-processing/</guid><description>在現今資料報炸時代，資料容易受到遺漏值或不一致性影響。這樣的影響會導致數據的品質降低，以至於對探勘結果會有不好的影響。因此資料前處裡是一個很重要的步驟，這將影響著數據研究結果。當今有許多資料前處裡的技術，像是資料清理、資料整合、降維和資料轉換等等。
為何需要前處裡 簡單來說就是要當前資料有價值的去被應用。
資料品質由許多要素組成：
正確性 刻意輸入不正確值或設備故障 人為不小心錯誤輸入 完整性 客戶填寫的資料非所有都填寫 某些資訊可能沒有其它欄位資訊 一致性 格式不一樣等 時效性 資料的某些訊息需要在某個時間才會被輸入 可信度 資料有多少程度被使用者信賴 可解讀性 資料能否被使用者所解讀 然而前三項是現今大型資料庫或倉儲時常遇到的問題。
資料前處裡任務 資料清理 清除資料中雜訊，修復不一致性。
遺漏值 忽略該值值組 人工補遺漏值 使用一個長數值代替遺漏值 使用屬性的平均值或中位數等來填補遺漏值 使用同一類別的樣本平均值或中位數等來填補遺漏值 使用迴歸或決策樹等決定該遺漏值 避免遺漏值的方法最好是定義好規則。
雜訊資料 分箱法 對資料做排序，並指定分箱個數，在使用平均值或邊界方法來平滑數據。
迴歸 找出能夠切分資料點的線獲曲面。
離群值分析 藉由分群。
資料整合 從不同來源的資料合並成連貫一致的資料庫。可能不同資料庫輸入同一性質的值，但欄位名稱不一致，或者輸入值不一樣。然而有些資訊也許從多個欄位來取得，這在做整合時，同時也減少資料的冗長。
而資料冗於性可透過卡方檢定或相關係數與共變異數等檢測。</description></item><item><title>30 天學習歷程-day04</title><link>https://cch0124.github.io/blog/2020-08-20-data-similarity-dissimilarity/</link><pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-20-data-similarity-dissimilarity/</guid><description>資料的相異性與相似性 在群集、離群值與最近鄰居等演算法應用中，需要比較兩個物件並評估兩物件之間的相似、相異性。
群集是指資料物件的集合，同一群集內的資料物件是彼此相似，不同群集間則是相異。離群值是辨識出那些物件與其它資料物件有著高度相異並將其認定為離群值。最近鄰居是對一個資料物件指定類別標籤，根據它與分類模型中其他物件的相似度決定。
資料矩陣和相異度矩陣 這邊的特徵向量將以二維或多維度屬性組成。
資料矩陣 使用 $n$ 筆物件乘上 $p$ 個屬性，來儲存 $n$ 筆資料物件。也稱屬性結構。
$\begin{bmatrix} x_{11} &amp;amp; &amp;hellip; &amp;amp; x_{1f} &amp;amp; &amp;hellip; &amp;amp; x_{1p} \
&amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \
x_{i1} &amp;amp; &amp;hellip; &amp;amp; x_{if} &amp;amp; &amp;hellip; &amp;amp; x_{ip} \
&amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \
x_{n1} &amp;amp; &amp;hellip; &amp;amp; x_{nf} &amp;amp; &amp;hellip; &amp;amp; x_{np} \
\end{bmatrix}$
相異度矩陣 儲存 $n$ 筆物件集合中，每一對物件的鄰近值，通常用一個 $n \times n$ 矩陣來表示。</description></item><item><title>30 天學習歷程-day03</title><link>https://cch0124.github.io/blog/2020-08-19-chart/</link><pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-19-chart/</guid><description>Data Visualization 透過直方圖或分位數圖等能有效的對一個特徵進行觀察，而兩個特徵可使用散佈圖，本篇文章將介紹一些用 python 工具進行視覺化的方法。
Quantile Plot 對於給定的特徵，會顯示所有資料，並透過此呈現觀察數據的不尋常處或行為。最後在標示分位數已進行分布的觀察。
Quantile-Quantile Plot 能夠檢視從一個變數分布到另一個變數分布時是否有偏移現象。
Histogram 直方圖是對某一個特徵摘要其資料分布，然而該長條的高度代表該特徵出現的頻率。
price_count = {40: 275, 43: 300, 47:250, 74: 360, 75: 515, 78: 540, 115:320, 117:270, 120:350} sum_60 = 0 sum_80 = 0 sum_100 = 0 sum_120 = 0 for key, values in price_count.items(): # key 為價格，values 產品銷售數量 if key &amp;gt; 40 and key &amp;lt; 60: sum_60 += price_count.get(key) if key &amp;gt;= 60 and key &amp;lt; 80: sum_80 += price_count.</description></item><item><title>30 天學習歷程-day02</title><link>https://cch0124.github.io/blog/2020-08-18-statistical-data/</link><pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-18-statistical-data/</guid><description>Statistical Data 透過統計方式我們可以觀察資料的趨勢或是分散程度等，以下將會介紹常用的統計方式。
數據集中趨勢 Mean 一組數據中的平衡點 平均數是一組樣本和除以樣本數量 另 $x_1, x_2,&amp;hellip;, x_N$ 為 $X$ 的 $N$ 個觀測值。這些值有可稱為數據集。這些數值均值(mean)為 $$\bar{x} = \frac{\sum_{i=1}^{N} x_i}{N} = \frac{x_1+x_2+&amp;hellip;+x_N}{N}$$
有時可以與 $w_i$ 權重相關。此反應他們所依附的對應值的意義、重要性或出現頻率。可以下計算： $$\bar{x} = \frac{\sum_{i=1}^{N} w_i x_i}{\sum_{i=1}^{N} w_i} = \frac{w_ix_1+w_2x_2+&amp;hellip;+w_nx_N}{w_1+w_2+&amp;hellip;+w_N}$$
這稱為加權是算術平均值（weight arithmetic mean）或加權平均值（weighted average）。
但上面計算的均值對極端值很敏感。要避免可以使用截尾均值(trimmed mean)，丟棄高低極端值得影響。在計算平均值之前，移除最底部 2% 資料等。
import numpy as np nums = [1,2,3,4,4,4,5,8,2,3] # Numpy np.mean(nums) # 3.6 # for sum = 0 for i in nums: sum += i print(sum/len(nums)) # 3.6 Median 樣本需要是排序 代表一個樣本或概率分佈中的一個數值，可將數值集合劃分為相等的上下兩部分 樣本為偶數個，則中位數不唯一，通常取最中間的兩個數值的平均值作為中位數 對於 偏斜（非對稱） 數據，數據中心更好度量是中位數(median)，將較高或較低值給平均。 有序數據值的中間值。</description></item><item><title>30 天學習歷程-day01</title><link>https://cch0124.github.io/blog/2020-08-17-know-data/</link><pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-17-know-data/</guid><description>了解你的資料 在這兩年的碩士班中，我將利用 30 天將我學習到的知識進行分享。如果有錯誤歡迎指教。
有許多的資料都可以進行資料探勘，如：串流資料、時間序列資料、文字資料等。而透過資料探勘方式我們可以從該資料提取知識，也就是從資料中找到有意義的知識。在進行資料探勘時，資料的處裡也是相對重要，資料處裡過程有許多流程如下
Data Cleaning 刪除聲噪和刪除不一致數據 Data integration 多種數據源可以組合一起 Data Selection 從資料庫中提取與分析任務相關的數據 Data transformation 透過匯總或聚集操作，把數據變換和統一成適合挖掘形式 Data mining 使用智能方法提取數據模式 Pattern evaluation 數據某種興趣度度量，識別代表知識的真正有趣模式 Knowledge presentation 使用可視化和知識表示技術，向用戶提供挖掘知識 from &amp;ldquo;Data Mining. Concepts and Techniques, 3rd Edition&amp;rdquo;
第一天要講的主題是了解你的資料。當不了解資料，做探勘的意義就不大，其被找出來的知識將會讓人疑惑 ?
一個資料的集合是由許多資料實體組成，以網路流量來說，流量可能被儲存至資料庫或是 Hadoop 等數據儲存方案，當中的實體可能是一個 TCP 流量、網路流量等。再以儲存方式來看，一列為一個實體，一欄為一個屬性。
屬性 屬性簡單來說就是代表資料實體的特徵或變數等。一個資料實體的屬性集合，可稱它為特徵向量，該特徵向量描述了該實體。
接下來的介紹將會參考&amp;quot;Data Mining. Concepts and Techniques, 3rd Edition&amp;quot;。</description></item><item><title>NFS</title><link>https://cch0124.github.io/project/2020-04-27-nfs/</link><pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-04-27-nfs/</guid><description>NFS 是經由 LAN 或 WAN 存取遠端檔案。它的共用是基於 Server 和 Client 關係。因此設定 NFS 時需要有網路位置和共享路徑。
Env 學校實驗室A系統 ubuntu 12.04 公網 學校實驗室B另一台主機 公網 Server Install sudo apt-get install nfs-kernel-server share dir setting // 學校實驗A室備份都放置 /home1/....../backup/NFS // share_dir client_ip(env setting) $ sudo vi /etc/exports share_dir 實驗室B_IP(rw,sync,no_root_squash,insecure,no_subtree_check) $ sudo chown nobody:nogroup share_dir $ sudo service nfs-kernel-server restart client_ip 就是實驗室B_IP，因為只限制該B實驗室存取，如果使用 * 則表示所有都可存取。
Option rw read and write operations sync write any change to the disc before applying it no_subtree_check: prevent subtree checking no_root_squash insecure Client Install sudo apt-get install nfs-common Mount directory of NFS $ sudo mount [nfs_server_ip]:[server_share_dir] [client_dir] 參考資料 mount 問題參考</description></item><item><title>掛載雲端硬碟至本機</title><link>https://cch0124.github.io/blog/2019-02-23-rai-dirver/</link><pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-02-23-rai-dirver/</guid><description>RaiDrive RaiDrive 是一款免費的軟體。可以將雲端硬碟 Google Drive、OneDrive、Dropbox 等 SaaS 服務透過此軟體將雲端硬碟映射成本機端的硬碟。操作方式就跟本機上的硬碟一樣，這樣減少了開瀏覽器登入這些 SaaS 服務才能操作，相當方便。相對於電腦上硬碟容量不夠大的使用者，透過此方式將檔案（影片、文件）直接放入此映射出來的硬碟。
使用 點選 Storage 的 Google Drive，Drive 可編輯名稱，點選 OK 後會跳至網頁選擇登錄的使用者，即可完成。</description></item><item><title>ups 應用</title><link>https://cch0124.github.io/project/2018-12-24-apc-ups/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-12-24-apc-ups/</guid><description>APC UPS 環境 Back-UPS Pro 700 ubuntu 12 安裝套件 在 ubuntu 安裝 ups 套件，讓 ups 能控制系統
$ sudo apt-get -y install apcupsd ... Please check your configuration ISCONFIGURED in /etc/default/apcupsd 配置檔 /etc/apcupsd$ tree . ├── apccontrol ├── apcupsd.conf ├── changeme ├── commfailure ├── commok ├── hosts.conf ├── killpower ├── multimon.conf ├── offbattery ├── onbattery └── ups-monitor 0 directories, 11 files /etc/apcupsd$ sudo vi apcupsd.conf UPSCABLE usb # 定義將 UPS 連接到 computer 的電纜類型。 UPSTYPE usb DEVICE # 啟用自動檢測，不使用串行電纜交換信號 SCRIPTDIR /etc/apcupsd # apccontrol和事件腳本所在的目錄。 UPSNAME UPS_700 在 apcupsd 包電源故障的情況下，通知給商用電源的用戶，當商用電源未恢復時，損失如果電池耗盡，或指定的超時時間段已經過去，它已達到指定的電池充電速率任一，或已經達到剩餘電池壽命（通過基於內部UPS計算電力消耗速率來確定）。如果滿足任何這些關閉條件，請執行關閉。</description></item><item><title>前人沒留下資料，需要通靈</title><link>https://cch0124.github.io/blog/2018-12-10-forget-password/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-12-10-forget-password/</guid><description>unix 忘記密碼 在開機時，按下 Esc。開啟 GRUB 開機選單 按下鍵盤上的「e」鍵 會看一個參數編輯的視窗 找有 linux /boot/vmlinuz-X.XX.X 在最後一行加上 single 參數 編輯好參數之後，按下 Ctrl + x 或是 F10 開機，接著就會進入單機模式。 在單機模式之下，使用 passwd 更改一般使用者（或 root）的密碼 最後執行 reboot 重新開機，就可以用新的密碼登入了。 Ref gtwang</description></item><item><title>新增網站</title><link>https://cch0124.github.io/blog/2018-11-23-new-web/</link><pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-11-23-new-web/</guid><description>事由 每年系統會增加一個期刊，於是我照著之前先人的 SOP 走，但群組設定部分好像有小差錯。
更改群組名稱 $ cat /etc/group | grep iihmsp sudo:x:27:mykuo,itachi,jni,iihmsp19 www-data:x:33:ychuang,jni,jihmsp,iihmsp19 iihmsp14:x:1004: iihmsp15:x:1005: iihmsp11:x:1010: iihmsp16:x:1035: iihmsp17:x:1040: iihmsp2019:x:1052: itachi@ubuntu:/home/home1$ sudo groupmod -n iihmsp2019 iihmsp19 groupmod: group 'iihmsp19' does not exist itachi@ubuntu:/home/home1$ sudo groupmod -n iihmsp19 iihmsp2019 itachi@ubuntu:/home/home1$ cat /etc/group | grep iihmsp sudo:x:27:mykuo,itachi,jni,iihmsp19 www-data:x:33:ychuang,jni,jihmsp,iihmsp19 iihmsp14:x:1004: iihmsp15:x:1005: iihmsp11:x:1010: iihmsp16:x:1035: iihmsp17:x:1040: iihmsp19:x:1052:</description></item><item><title>scanner port</title><link>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</link><pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</guid><description>import java.io.IOException; import java.net.ServerSocket; public class PortScanner{ public void scan(){ for(int i=1; i &amp;lt; 65535 ; i++ ){//port 是 0 - 65535 try{ ServerSocket ss = new ServerSocket(i);// ServerSocket(int port) 建構 }catch(IOException ex){// port 被占用則拋出例外 System.out.println(&amp;#34;Port: &amp;#34;+ i + &amp;#34; Occupied&amp;#34;); } } } public static void main(String[] args) { PortScanner pserver = new PortScanner(); pserver.scan(); } } // 在 TCP 協定中，埠號 0 是被保留的，不可使用。在 UDP 協定中，來源埠號是可以選擇要不要填上，如果設為 0，則代表沒有來源埠號。</description></item></channel></rss>