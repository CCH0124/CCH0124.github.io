<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>meanshift on</title><link>https://cch0124.github.io/tags/meanshift/</link><description>Recent content in meanshift on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 03 Jan 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://cch0124.github.io/tags/meanshift/index.xml" rel="self" type="application/rss+xml"/><item><title>ML-3-meanshift</title><link>https://cch0124.github.io/blog/2020-01-03-meanshift.md/</link><pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-01-03-meanshift.md/</guid><description>What is meanshift 資料集的密度為一個隨核密度分佈，能夠在此資料集中找到局部極值，即為一個 kernel density estimation（它不需要預先知道樣本數據的概率密度分佈函數，完全能夠對樣本點的計算），因此將資料分群。
Example import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.cluster import MeanShift, estimate_bandwidth from sklearn import datasets from sklearn import preprocessing #create datasets # iris = datasets.load_iris() # X = iris.data[:, :4] url = &amp;#34;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&amp;#34; data = pd.read_csv(url) le = preprocessing.LabelEncoder() data[&amp;#39;species&amp;#39;] = le.fit_transform(data.iloc[:,-1]) X = data.iloc[:, 0:4].to_numpy() y = data.iloc[:,-1].to_numpy() plt.scatter(X[:, 0], X[:, 1], c=&amp;#34;yellow&amp;#34;, marker=&amp;#39;o&amp;#39;, label=&amp;#39;see&amp;#39;) plt.</description></item></channel></rss>