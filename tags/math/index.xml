<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>math on</title><link>https://cch0124.github.io/tags/math/</link><description>Recent content in math on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 28 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://cch0124.github.io/tags/math/index.xml" rel="self" type="application/rss+xml"/><item><title>30 天學習歷程-day10</title><link>https://cch0124.github.io/blog/2020-08-28-clustering/</link><pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-28-clustering/</guid><description>分群(clustering) 是將一堆資料物件聚類成數個群集，讓同一群擊內的資料物件有很高的相似性，而不同群集間則有不相似的特性。在判別資料上的相似性會依照資料特徵進行衡量，通常可能會是量測距離等。
群集分析是什麼 就是將觀測的資料切分不同子集合的動作，每一個子集合都是一個群集。在百百種的分群演算法中，每種形成群集的效果都是不一樣，這些的演算法很適合挖掘未知的資訊。群集分析可以用來挖掘資料內部的分布，觀察每個群集的特徵，並進行下一步地分析動作。當然也可用作於資料前處理步驟，像是資料特性、屬性子集合選取或分類法等。而分群相較於分類，它能夠自動的找到群組。
集群分析方法 分割式分群法 找出互斥的球形群集 以距離為基礎 使用 mean 與 medoid 來代表群集中心點 對於中小型資料集很有效率 演算法有，k-means、k-medoids 等
階層式分群法 透過階層分解方式來分群 不能修正錯誤的合併或分割 可以結合微分群技術或考慮資料物件間的關聯性 演算法有，BIRCH、Chameleon 等
密度式分群法 找到任意形狀的群集 群集為空間中的資料物件密集的區域，不同群集則被低密度區域分隔 群集密度 每個資料物件得鄰近區域內包含至少最小數量的資料點 可以過濾離群值 演算法有，DBSCAN、OPTICS、DENCLUE 等</description></item><item><title>30 天學習歷程-day09</title><link>https://cch0124.github.io/blog/2020-08-27-what-classification/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-27-what-classification/</guid><description>以棒球員捕手為例，當他面對一位打者時，需要判斷說該打者對於什麼球種是安全的，那些球種是有風險的；醫療方面可能是分析乳癌的病患資料，並在幾種特定解決方法中，該給於怎樣的治療。這些例子中，資料分析方法就是分類(classification)。假設是預測棒球雙方的比數，該資料分析任務就是數值預測，迴歸分析(regression analysis)是最常用來數值預測的統計方法。
要進行資料分類，其程序大致為兩步驟，學習步驟此階段會建立模型；分類步驟此階段會利用模型來預測給定資料的類別標籤。學習步驟中會給定資料集合中的資訊，藉由分類演算法分析資料集合中一組樣本和其對應的類別標籤建立一個分類器。一個值組 $X$ 為 $n$ 維度的特徵向量，$X = (x_1, x_2, &amp;hellip;, x_3)$，其每個 $X$ 會對應一個類別，該類別可由類別標籤屬性來定義。假設一個樣本對應的標籤已經被定義好，該學習步驟可稱為監督式學習(supervised learning)，這與**非監督式學習(unsupervised learning)**不同，樣本無對應的標籤，需透過學習才知道，常見的方式就是使用分群(clustering)。以之前寫過的簡單線性迴歸來說，我們會希望透過映射函數來預測給定的資料樣本 $X$ 對應的類別標籤 $y$，就是找一個函數來分割資料的類別。
分類步驟會使用模型來進行分類，然而其正確率是多少 ? 在計算該值時不應該拿訓練資料進行評估，因分類器會傾向於過擬合(overfit) 訓練資料，就是說學習過程中，有些異常的資料會被過度學習，而該異常資料並不會出現在一般的資料集中。我們應當使用測試資料來進行正確率的評分。</description></item><item><title>30 天學習歷程-day08</title><link>https://cch0124.github.io/blog/2020-08-26-math/</link><pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-26-math/</guid><description>二項式定理、指數、對數、三角函數 二項是定理 參考 參考 排列組合 排列
由 $n$ 個不同物品取 $k$ 個出來排列，因此最後的排列順序不同，及視為不同的排列 組合
由 $n$ 個不同物品取 $k$ 個出來但不排列，因此只要組成元素相同，及視為相同組合，無關順序排列 ABC、ACB、BAC、CAB、BCA、CBA 這 $3!$ 種排列可看成是 A、B、C 的組合 組合數可用 $\frac{n!}{(n-k)!k!}$ 或 $C^n_k$ 表示 二項分佈計算獨立事件的機率分佈 事件的成功機率與獨立性 拜訪 10 次簽下 $k$ 建的機率一般式 $0.36$ 每次拜訪成功機率，
$P(x=k) = \tbinom{10}{k} \centerdot 0.36^k \centerdot (1-0.36)^{10-k}$
拜訪 10 次簽下 2 件的機率 $P(x=2) = \tbinom{10}{2} \centerdot 0.36^2 \centerdot (1-0.36)^{10-2} = \frac{10!}{(10-2)!2!} \centerdot 0.</description></item></channel></rss>